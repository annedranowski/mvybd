%!TEX program = lualatex
% 
\documentclass{article} % [draft] TODO: use this at the end to check for overfills 
\usepackage{basic}
\usepackage{emoji}
\usepackage{float}
% TODO: The matrix is lower triangular and the lower-triangular matrix is
% \setemojifont{Apple Color Emoji}
% Working title: 
\title{How to compute the fusion product of MV cycles in type $A$}
\author{Roger Bai, Anne Dranowski, Joel Kamnitzer} 
% \date{October 2020}
\date{\today}

\begin{document}

\maketitle
\tableofcontents

\section{Todolist}
\begin{itemize}
    \item Remove the TOC 
    \item Edit the intro 
    \item We are using the word [geometric] fusion just for the central fibre, we also have arithmetic fusion (aka multiplication in $\CC[N]$), and BD family: $X\geofu Y, b(X) \arfu b(Y), X \bdfamc Y\supset X\bdfamo Y$
    \item Which MVy paper to cite? 
    \item Super repetitive about lambdas and mus 
    \item Formatting could be bit better, e.g.\ some stuff goes outside the margin
    \item Fix section titles and other organizational seasoning  
    \item Fix numbering so that theorems, defs etc share a counter and are restarted by section 
    \item tableau of weight/filling? box of weight/filling? I prefer weight but don't mind filling 
    \item Recalling intersection multiplicity, checking that the definitions allow passing to open sets
\end{itemize}

\section{Introduction}
\label{s:intro}
% 
%Throughout this paper (unless indicated otherwise) the base field is $\CC$, but it does not have to be?  

The geometric Satake equivalence of Mirkovic-Vilonen \cite{mirkovic2007geometric} provided an equivalence of categories between the category of spherical perverse sheaves in the affine Grassmannian of a reductive group $ G $ and the category of representations of its Langlands dual group $G^\vee$.  This foundational result provides a powerful tool to study representation theory using geometry.  In particular, under this equivalence, the Mirkovic-Vilonen cycles in the affine Grassmannian of $ G $ index bases for irreducible representations of $ G^\vee $.  In this paper we work with $ G =GL_m$ and identify $ G^\vee = GL_m$ as well.

% The Mirkovi\'c--Vybornov isomorphism
In \cite{mirkovic2007quiver} (see also the recent sequel \cite{mirkovic2019comparison}) Mirkovi\'c and Vybornov provide a geometric version of symmetric and skew Howe $(\GL_m,\GL_N)$ dualities by relating Kazhdan--Lusztig slices in the affine Grassmannian of $\GL_m$ to slices in $N\times N$ nilpotent orbits on the one hand 
% conjugacy classes of nilpotent matrices 
and to Nakajima quiver varieties on the other hand.   This extends to an isomorphism between families of slices in the Beilinson--Drinfeld and families of matrices with two eigenvalues.  Via this equivalence, the Mirkovic-Vilonen cycles are identified with certain varieties of matrices, called generalized orbital varieties (see \cite{dthesis}).
%This paper generalizes the first of these relations (an isomorphism) to families of slices in the Beilinson--Drinfeld Grassmannian. \jcom{I changed this because MVy did consider the BD Grassmannian as well.}


Essential to \cite{mirkovic2007geometric}, the Beilinson-Drinfeld Grassmannian is used to define a fusion product on the category of spherical perverse sheaves on the affine Grassmannian.  In \cite{anderson2003polytope}, Anderson used the BD Grassmannian to define a fusion of Mirkovic-Vilonen cycles.  He conjectured that this fusion product matches the muliplication in the coordinate ring of the unipotent subgroup $ N \subset GL_m$.  This conjecture was proven in \cite{baumann2019mirkovic}, where it was also established that these MV cycles give a basis for $ \CC[N]$. 
% 
%To quote from \cite{mirkovic2007geometric}:
%\begin{quotation}
%    However, we make crucial use of an idea of Drinfeld, going back to around 1990. He discovered an elegant way of obtaining the commutativity constraint by interpreting the convolution product of sheaves as a ``fusion'' product.
%\end{quotation}
%

Unfortunately, performing computing the fusion product of MV cycles using the BD Grassmannian is quite difficult, both computationally and conceptually.  A few such computations were done by Anderson-Kogan in \cite{anderson2006algebra} in a somewhat ad-hoc fashion.  

The purpose of this paper is to give a conceptually elementary way to compute this product by transferring it to a fusion product of generalized orbital varieties.  Our main result is the following.

\begin{theorem}
    Let $ Z, Z' $ be MV cycles.  The structure constants for the multiplication of $ b_Z b_{Z'}$ in $\CC[N]$ are equal to the intersection multiplicities in the fusion of the generalized orbital varieties corresponding to $ Z, Z'$.
\end{theorem}
% 
\jcom{I wanted to state a precise theorem, but it is not so easy without introducing a lot of notation.}

%One should care about the fusion product on bases \emoji{imp} \emoji{grin} \emoji{worried} \emoji{monocle-face} \emoji{skull} if one is interested in positivity!

{\color{blue}
\acom{To quote from BFZ for a concise definition: Cluster algebras are a class of commutative rings defined axiomatically in terms of a distinguished family of generators called cluster variables. Say also what is a seed, what is a mutation, what is a cluster, what is a cluster monomial, and finally for the stubbornly ignorant clarify that 'the cluster monomials' refers to cluster monomials for all possible clusters!}

$\CC[N]$ is a cluster algebra as shown in \cite[\S 4.3]{geiss2007initial} using \cite[Theorem~2.10]{berenstein2005cluster3}, and one of the main motivations for this paper is using fusion to check that certain cluster monomials are contained in the MV basis.
% that are associated to exchange relations in $\CC[N]$ with its cluster algebra structure. 

\acom{Background on cluster:}
In \cite{lusztig2000semicanonical}, Lusztig gives a geometric construction of a $\CC$-basis of $\cU\n$ the universal enveloping algebra of the Lie algebra of $N$, called the semicanonical basis. This becomes the dual semicanonical basis of the graded dual of $\cU\n$ which is isomorphic (as a Hopf algebra) to $\CC[N]$. 
Geiss, Leclerc \& Schroer prove that certain cluster monomials are contained in Lusztig's (dual) semicanonical basis \cite[Theorem~2.8(3)]{geiss2006rigid}.

In the appendix to \cite{baumann2019mirkovic} the second and third author along with Morton-Ferguson check that the MV basis differs from the dual semicanonical basis (at the Kashiwara--Saito counterexample). 
Yet, the two bases have enough in common (c.f.\ BKT,...?), that we have the following conjecture.

\begin{conjecture}
    The dual semicanonical basis and the MV basis overlap on the cluster monomials. In particular, the cluster monomials are contained in the MV basis. 
\end{conjecture}

We note that both of these bases are \new{biperfect} bases of $\CC[N]$ and in type $A_n$ with $n\le 3$ there is a unique biperfect basis of $\CC[N]$. }

Anderson and Kogan conjectured in \cite{anderson2006algebra} \acom{or earlier?} that those MV polynomials which are cluster monomials for a Fomin--Zelevinsky cluster algebra structure on $\CC[N]$ are naturally expressible as determinants\dots
% and they conjectured a formula for many of them.

It's not clear how this work helps with/relates to AK/their conjectures.

The generalized \mvy is interesting in its own right. \acom{is it?}

Computing fusion still hard but at least boiled down to linear algebra. Cf.\ fusion product as it appears in \cite{beilinson1991quantization,feigin2generalized,mirkovic2007geometric,anderson2006algebra,bezrukavnikov2005equivariant}.

Interesting combinatorics? Presumably it is related to Feigin and Loktev's generalized Kostka polynomials? Though Joel says that the product on SSYT that we are witnessing is unlikely to have a combinatorial description. 

Exchange relations only work on cluster modules where one is a mutation of the other (i.e.\ those corresponding to cluster monomials which are related by mutation). Of course this gives me everything. Up to $A_4$ as in type $A_5$ there exist indecomposable modules which are not cluster, so exchange relations do not apply. 

The hope (conjecture) is that this paper gives a way to compute on such modules. Cf.\ counterexample satisfying $\barD(c_Y) = \barD(b_Z) + 2\barD(b)$, where $b$ is a cluster monomial belonging to both bases and $c_Y$ is the square of a cluster monomial ($b'$ say) belonging to both bases. The $\barD$ equation suggests that $(b')^2 = b_Z + 2b$. We can try to check this using Roger's script. Such calculations bring us closer to answering two questions. First, how forgetful is $\barD$. Second, on the level of modules, are the terms appearing in the fusion product determined by $\Ext^1$ of the factors. By Roger's thesis this is true if the factors are cluster modules related by a mutation. 

% No; $x*y=\sum z\Rightarrow y = \frac 1 x \sum z$. 

Representation theory? 

\section{Players}
\label{s:players}
\subsection{Rings and discs}
\label{ss:rings}
Set $\cO = \cO_0 = \CC\xt$ and $\cK = \cK_0 = \CC\xT$.
% TODO: I rearranged this sentence, because starting it with 'for any other' presupposes we have introduced s 
%  For any other 
We will also consider $\cO_s = \CC\xt[t-s]$ and its fraction field $\cK_s=\CC\xT[t-s]$, for any 
$ s \in \CC\setminus\{0\} $, as well as $ \Oinf = \CC\xt[t^{-1}] $ and $\Kinf = \CC\xT[t^{-1}]$. For any point $ s \in \PP = \PP^1$, 
% TODO: Identifying $s\in\CC$ and the line $s\in\PP$ containing it right?
$ \cO_s$ is the completion of the local ring $ \mathcal O_{\PP, s} $ and thus the formal spectrum of $ \cO_s$ is the formal neighbourhood $ D_s$ of $ s $ (also called the formal disc centered at $ s$).  Similarly the formal spectrum of the field $\cK_s$ is the deleted formal neighbourhood (or punctured disc), denoted $ D_s^\times$.

Note that for $ s \in \CC $, we have an obvious isomorphisms  $\cO_s \cong \cO$ and $\cK_s\cong\cK$ taking $ t-s $ to $ t$. % ok technically the point s is in P and the coordinate s is valued in C 
% 
\subsection{Groups}
\label{ss:groups}
% 
Let $H $ be an algebraic group over $ \CC $.  We will be interested in $ H(R)$ where $ R $ is a $\CC$-algebra, for example $R = \CC[t], \cO_s$, etc.  
% 
% \acom{random question, I know $H(R)$ is supposed to mean functor of points of the scheme $H$ but can it also be viewed as a base change from $\CC$ to $\RR$?}
% \jcom{Usually $ H_R$ is the notation used for the base change, so using $ H(R)$ here is a bit of an abuse, but it is common and harmless.}
% 
Note that evaluation at $ t = s$ provides a group homomorphism $ H(\cO_s) \rightarrow H$.  We denote the kernel of this map by $ H_1(\cO_s)$, often called the  first congruence subgroup.  We will be particularly interested in this construction in the case $ s = \infty$, which gives us the group $ H_1(\Oinf)$.
% \acom{Add $G_1$}
%\acom{TODO: Algebraic groups over rings, i.e.\ the meaning of $G(K)$. The affine space of $m\times m$ matrices which we denote $ M_m$. The first congruence subgroup $G_1$ and why we take $\Oinf$ points instead of $\CC[t]$ points as some of the lit does.}

Throughout the paper, we fix $ m \in \NN$.  We let $G = \GL_m$ and let $T\subset G$ be the maximal torus of diagonal matrices. 
% are there other possibilities?? :S 
We identify $\ZZ^m$ with the coweight lattice of $G$ and say that a coweight 
% The coweight lattice of $ G $ is $ \ZZ^m = \Hom(\AA^\times,T)$.
% TODO: Thank you - resolved!
% \acom{This identification assumes we are taking $\CC$ points of $G$ right? i.e.\ it's really $P(T(\CC)) = \Hom(\AA^\times,T(\CC))$ that's $\cong \ZZ^m$ and for instance $P(T(\CC[x]/(x^2))$ will give sth else?} 
% \jcom{No, the coweight lattice is the set of homomorphisms of algebraic groups from $ \mathbb G_m$ to $ GL_m$.  It is independent of the ring/field of definition.}
% 
% The \new{dominant coweights} of $ G $ are the set of $ \lambda = (\lambda_1, \dots, \lambda_m) \in \ZZ^m $ such that $ \lambda_1 \ge \cdots \ge \lambda_m$. 
% 
% A coweight $ \mu = (\mu_1, \dots, \mu_m) \in \ZZ^m$ is called \new{effective} if $ \mu_j \ge 0 $ for all $ j$.
% 
$\nu = (\nu_1,\dots,\nu_m)$ is \new{dominant} if $\nu_1\ge\cdots\ge\nu_m$ and \new{effective} if $\nu_j\ge 0$ for all $j$.
% We also need the notion of effective dominant coweight, 
% \acom{can we conflate or should we be precise and say coweight?} \jcom{Corrected, let's stick to coweights.}
%which means those $ \lambda $ as above with $ \lambda_m \ge 0$.  
% \acom{1. No boldface on this new term. Proceed with selective boldfacing? 2. Since we sometimes need $\Peff$ which contains $P_{++} = \Peff\cap\Pdom$, how about just using the notation $\Peff,\Pdom$ instead of $P_+, P_{++}$ for a change?}
% \jcom{I added the definition of effective coweight.  I actually don't think that we need any special notation $ P, P_+, P_{dom}$ etc !  Later we can just write ``$ \lambda \in \ZZ^m$ a dominant or effective coweight'' etc}
% TODO: it's settled then, no special notation fro coweights!
% 
If $\nu\in\ZZ^m$ is both effective and dominant then it is a partition of size $|\nu| = \nu_1 + \cdots + \nu_m\in\NN$.
%We write $P_+$ for the set of dominant coweights, and $P_{++}$ for the set of effective dominant coweights. 
% 
% nicematrix test
% $\begin{bNiceArray}{ccc|c}[margin]
%     \Block{3-3}<\Large>{A} & & & 0 \\
%     & \hspace*{1cm} & & \Vdots \\
%     & & & 0 \\
%     \hline
%     0 & \Cdots& 0 & 0
%     \end{bNiceArray}$
% 
% $\begin{pNiceMatrix}
%     \frac12 & -\frac12 \\
%     \frac13 & \frac14 \\
%     \end{pNiceMatrix}$
% 
% Set $\AA = \AA^1_x$ (the subscript denoting the chosen local coordinate) and fix $s\in \AA - \{0\}$. 
% 
% Given a coweight $\mu \in \ZZ^m$ and a point $ s\in \CC$, we define $ (t-s)^\mu$ to be the diagonal matrix 
Given $s\in\CC$ we define $(t-s)^\nu$ to be the diagonal matrix 
% with entries $ (t-s)^{\mu_1}, \dots, (t-s)^{\mu_m}$
% \[
%     \begin{pNiceMatrix}[nullify-dots,xdots/line-style=loosely dotted]
%         (t-s)^{\mu_1} & 0             & \Cdots & 0 \\
%         0             & (t-s)^{\mu_2} & \Ddots & \Vdots \\
%         % 0 & b & a & \Ddots & & \\
%         \Vdots              & \Ddots        & \Ddots & 0 \\
%         % \Vdots & & & & \\
%         0             & \Cdots        &   0    & (t-s)^{\mu_m}
%     \end{pNiceMatrix}
% \]
\[
\begin{bmatrix}
    (t-s)^{\nu_1} \\
    & (t-s)^{\nu_2} \\ 
    & & \ddots \\
    & & & (t-s)^{\nu_m}
\end{bmatrix} 
\]
which we can view in 
% $\GL_m(K) $ 
$G(K)$ for any ring $ K $ containing $(t-s)^{-1}$ and $\CC[t]$. For example, $(t-s)^\nu\in G(K)$ for $ K = \Ks$ or $\CC(t)$. % A: Think R sb K; changed it 

% Resolved
% \acom{We will also sometimes write $(t-s)^\mu$ for its image in $G(K)/G(R)$ and we hope it will be clear? Only we haven't introduced this space yet.}
% \jcom{I think that we do this infrequently enough that it is not a problem and there is no need to mention it here.}
% Resolved
% 2. Change notation $\mu = (\mu_1,\dots,\mu_m)$ since we also have $\mu = \mu_1 + \mu_2$. We could do $\mu = \mu' + \mu''$ or $\mu = a + b$? The notation $\mu^{(i)}$ is already taken to mean sth. Ofc all can be changed. Can also do $\mu = {}_{1}\mu + {}_{2}\mu$. \emoji{sweat-smile}}

We will also be interested in the affine space $ M_m$ of $m\times m$ matrices.  Note that for any $ \CC$-algebra $ R $, 
% $\GL_m(R) $ 
$G(R)$ consists of those matrices $ g \in M_m(R) $ whose determinant is invertible in $ R$. Thus for example $ (t-s)^\mu\in M_m(\CC[t])$ for all effective $ \mu \in \ZZ^m$ but 
% $ t^\lambda \in \GL_m(\CC[t]) $ 
$(t-s)^\mu\in G(\CC[t])$ if and only if $ \mu = 0 $.
% 

% \acom{Maybe add that it's the same for $G(\cO)$. Also, we are using the notation $G(R)$ in one paragraph and defining it in the next. Maybe introduced $M_m$ first?}
% \jcom{I don't consider that to be the definition of $ G(R)$.  The definition is the invertible $ m \times m$ matrices with coefficients in $ R $.  So I think that everything is fine.}

\subsection{Lattices}
\label{ss:lat}
We will use the lattice model for the affine Grassmannian, so it is useful to recall the following definition. Let $ R \subset K$ be two $\CC$-algebras (usually, but not always, $K$ will be a field). 
% \acom{When is $K$ not a field?}). Let $ m \in \mathbb N$ \acom{we have already fixed $m$?} and; e.g. K = C[t,t^{-1}] is not a field!!! 
Consider $ K^m $ as a $K$-module. 
% \acom{left or right, doesn't matter? I think we are in a situation where they are the same, i.e.\ our rings are commutative.} 
By restriction $ K^m$ can be viewed as an $R$-module.  An \new{$R$-lattice} in $K^m$ 
% \acom{what is $M$? should be $K^m$?}; bc Joel was thinking about arbitrary free modules 
is an $R$-submodule $ L \subset K^m$ 
% such that $ L $ 
which is a free $R$-module of rank $ m $ and satisfies $ L \otimes_R K = K^m $. Equivalently, $ L = \Sp_R(v_1, \dots, v_m)$ where $v_1, \dots, v_m$ are free generators of $K^m$. 
% 
\begin{comment}
\jcom{Maybe need that both $K$ and $R$ are integral domains and have the same field of fractions?} 
\acom{Roger has proved that what is written is ok.}
\rcom{Here's my argument: If $L \subset K^m$ is a free rank $m$ $R$-module and $L \otimes K = K^m$, then it's clear we that $L$ is generated by $m$ generators $v_1,\dots,v_m$ over $R$. Since $L\otimes K = K^m$, these also generate $K^m$ over $K$. Then we have a surjective map $K^m \twoheadrightarrow K^m$ given by sending a basis of $K^m$ to the generators $v_1,\dots,v_m$. Since any surjective endomorphism of finite $K$-modules is injective, the $v_1,\dots,v_m$ form a basis. I think the only thing that is needed is that the rings are commutative.}
\jcom{Great.}
\end{comment} 

% The trivial lattice is 
% No more: L_0(R) = 
$ R^m \subset K^m $ is called the standard lattice. 
% We will abuse notation and denote $L_0(R)$ simply $L_0$ in the hope that the ring $R$ will be understood from the context. 
The group $\GL_m(K) $ acts transitively on the set of $R$-lattices in $K^m$, thus giving a bijection between 
% the set of such lattices 
this set and $\GL_m(K)/\GL_m(R)$, since $ \GL_m(R) $ is the stabilizer of the standard lattice. 
%\acom{For example, we will frequently make use of the lattice $L_\lambda$ corresponding to the point $t^\lambda\in\Gr$ given $\lambda\in P$. If $e_1,\dots,e_m$ denote the standard basis elements of 
% $L_0(\cO)$ then 
%$\cO^m$ then 
%$$ 
%L_\lambda = \Sp_\cO(t^{\lambda_1}e_1, \dots, t^{\lambda_m}e_m)\,. 
%$$}


We will be particularly interested in $\CC[t]$-lattices in $ \CC(t)^m$. 
% TODO: 
% \acom{Wait, I thought $\CC(t)$ is used in the Ran space version of the BD Gr.}
Given such a lattice $ L $ and a point $ a \in \CC$, the \new{specialization} of $ L $ at $ a $ is the lattice in $\cK_a^m$ defined as $ L(a) := L \otimes_{\CC[t]} \cO_a $. 
If $L(a) = \cO_a^m$ then $L$ is said to be \new{trivial at $a$}. 
% We say that $ L $ is trivial at $ a $ if $ L(a) = \cO_a^m$. 
% \acom{Do we want to employ the notation $\cO_a$ and $\cK_a$ here?}
For example, the lattice $(t-s)^{-1}\CC[t] \subset \CC(t)$ is trivial at any $a\ne s$, since $ t-s $ is invertible in $ \cO_a$. 
% \acom{it is a little bit uneven to have notation for $\cO^m$ but not for $\cO_a^m$?}

% \acom{Should we also mention our interest in $\cO$-lattices in $\cK^m$?}
% \jcom{I don't think that it is necessary.  I just put the part about $ \CC(t)$ to set up the notation for this specialization.}

% \jcom{I wasn't sure of the notation to use here, but I wanted something which didn't conflict with $ L_0$.}

% \acom{I think that MVy use this notation also: }

% \acom{We are using fixed $m$ in the definitions here.}
% \jcom{Added sentence fixing $m $ above.}

\subsection{Affine Grassmannians} 
\label{ss:affgrs}
% To map thick Gr to C is to map a lattice to the points where it isn't trivialzable; doesn't make sense to ask for poles 
% G(C(t))/G(C[t]) for example lives over the Ran space, finitely many eigenvalues; positive part of thick contains this guy as image 
%Set $\AA = \AA^1$ viewed as the subset $\PP\setminus \{\infty\}$ of $\PP$. Let $\Vtriv$ denote the trivial rank $ m $ vector bundle. 
% 
We now define various versions of the affine Grassmannian which will play important roles in this paper. 
% 
Each definition is made group-theoretically and then restated as a moduli space of vector bundles and as a moduli space of lattices.
% 
We also sketch how to pass between descriptions.  

In these definitions, $ \Vtriv$ denote the trivial rank $ m $ vector bundle. 

%\acom{Can we review what exactly is meant by ``terms''? I think that we have (1) a coset space, (2) a moduli space, and (3) a torsor? ``Geometrically'', they are all the same?}

%\jcom{Yes, that is true.  But what is the problem?  It is nice to describe spaces in different ways.  Technically, none of our definitions are ``precise'', since we only describe the $ \CC$-points.  We should describe each one a functor, if we wanted to be completely precise.  And then we would have three isomorphic functors.  But let's not do this.}

% \acom{Oh, I meant could we review for my own benefit. But I do think it is also nice, for readability, to use (slightly) different words to describe the different descriptions. Hence my suggestions following Def.\ 1.}

% \jcom{I made some changes}

\begin{definition}
\label{def:gr}
     The \new{ordinary affine Grassmannian} $\Gr = G(\cK)/G(\cO)$.
\end{definition}    
It is the moduli space of vector bundles with trivializations,
%\acom{Can we introduce the first of these restatements as ``As a moduli space it is the set of..''}
$$
\Gr = 
    \left\{ 
        (V, \varphi) : \text{$V$ is a rank $m$ vector bundle on $ D_0 $, $\varphi : V \xrightarrow{\sim} \Vtriv $ on $ D_0^\times $} 
    \right\} \,. 
$$
It is also a moduli space of lattices, 
% \acom{And this one as ``As a $G$-space..''}
$$ 
\Gr = 
    \left\{ L \subset \cK^m : \text{ $L$ is a $\cO$-lattice} \right\}\,.
$$
% 
We obtain a lattice from a pair $ (V,\varphi) $ by setting $ L = \Gamma(D_0, V)$ which is embedded into $ \cK^m = \Gamma(D_0^\times, \Vtriv)$ using $ \varphi$.  
On the other hand, to get a lattice from the group-theoretic description $ G(\cK) / G(\cO) $ we set $ L = g \cO^m$ for $ g \in G(\cK)$.
% 
\begin{definition}
\label{def:grs}
 For any $ s \in \CC $, 
    the \new{ordinary affine Grassmannian} $\Gr_s = G(\cK_s)/G(\cO_s)$ \new{at} $ s $. 
\end{definition}    
As above, we have modular and lattice descriptions:
\begin{gather*}
\Gr_s = 
    \left\{ (
        V, \varphi) : \text{$V$ is a rank $m$ vector bundle on $ D_s $, $\varphi : V \xrightarrow{\sim} \Vtriv $ on $ D^\times_s $} 
    \right\}\,, \\
\Gr_s = 
    \left\{ 
        L \subset \cK_s^m : \text{ $L$ is a $\cO_s$-lattice} 
    \right\} \,. 
\end{gather*}
% 
% TODO:
% consider decorating lattice, modular, group-theoretic descriptions? 
% paper too short for it, ok. 
% but it's a little weird how we do 
% $$ X = A \\ X = Y $$ 
% Hmm.. maybe it's alright
% I was going to suggest we do $$ X = A \\ = B $$ instead 
% 
\begin{definition}
\label{def:grth}
The \new{thick affine Grassmannian} $\Grth = G(\Kinf)/G(\CC[t])$.
\end{definition}
Again, we have the following modular and lattice descriptions:
\begin{gather*}
\Grth = 
    \left\{ 
        (V, \varphi) : \text{$V$ is a rank $m$ vector bundle on $ \PP $, $\varphi : V \xrightarrow{\sim} \Vtriv $ on $ D_\infty $ } 
    \right\}\,, \\
\Grth = 
    \left\{ 
        L : L \subset  \Kinf^m \text{ is a $\CC[t]$-lattice} 
    \right\}\,.
    % \CC\xT[t^{-1}]^m 
\end{gather*}
% \jcom{Maybe write $\Kinf$ for $ \CC\xT[t^{-1}] $?  Also maybe change the ``thick'' notation''.} \acom{Since $\sf th$ is also the first two letters of ``thin''?} \jcom{That's a good point!  Maybe we could use some kind of bold  Gr (``thick'' letters) or maybe that would be too confusing.} \acom{Ok, it's tentative.}
% 
\begin{definition} 
\label{def:bdgr}
The two point \new{Beilinson--Drinfeld Grassmannian} $$\pi : \Grbd\to \AA$$ with one point fixed at 0, and the second point $s\in\AA$ varying.
\end{definition}
% 
It is described in modular terms by 
$$
\Grbd = 
    \left\{ 
        (V,\varphi,s) : V\text{ is a rank $m$ vector bundle on }\PP, \varphi : V \xrightarrow{\sim} \Vtriv \text{ on } \PP \setminus \{0, s\}  
    \right\}\,. 
$$
% 
The fibre of $\Grbd \to \AA$ over $ s \in \AA $ will be denoted $ \Gr_{0,s} $ and is given by
% \rcom{why do we have the $s\ne 0$ restriction here} \jcom{it would work when $ s = 0$, but it looks a bit strange there.}
% 
$$ 
    G(\CC[t, t^{-1}, (t-s)^{-1}]/G(\CC[t])\,. % := \pi^{-1}(s) 
$$
% \acom{What is the modular description of the fibre?} \jcom{That is written above (just fix $ s$).}
% 
% \acom{0 in notation is kinda redundant? But we can't take it away because we already have a $\Gr_s$ and it is something else?}
% \jcom{Yes, that is one reason.  But also, there was a comment of yours before in the file, saying that you sometimes got confused that one point was fixed at 0, so this is a good notation to remind us (and the reader).  For the same reason, maybe we should write $ \Gr_{0, \AA}$ instead of $ \Gr_\AA$.}
% \acom{lol}
We also have the lattice descriptions:
% 
\begin{gather*}
\Grbd = 
    \left\{ 
        (L,s) : L \subset  \CC(t)^m\text{ is a $\CC[t]$-lattice trivial at any }a \ne 0, s 
    \right\}\,, \\
% , $L$ is 
\Gr_{0,s} = 
    \left\{ 
        L : L \subset  \CC[t,t^{-1},(t-s)^{-1}]^m \text{ is a $\CC[t]$-lattice} 
    \right\}\,.
\end{gather*}
% 
\begin{definition} 
\label{def:grplus}
The \new{positive part} of $\Gr $, resp.\ $\Grth$, is defined by 
\begin{gather*}
    \Gr^+ = \left(M_m(\cO) \cap G(\cK)\right) / G(\cO)\,,\,\, % \\
    % \text{ and }      
    \text{resp.\ } {\Grth}^+ = \left(M_m(\CC[t]) \cap G(\Kinf)\right) / G(\CC[t])\,. 
\end{gather*}
\end{definition}
% 
In modular terms, $\Gr^+$ (resp.\ ${\Grth}^+$) is the set of those $ (V, \varphi)$ where $ \varphi : V \rightarrow \Vtriv $ extends to an inclusion of coherent sheaves over $ D_0 $ (resp.\ over $ \PP$).

In lattice terms, $ \Gr^+$ (resp.\ ${\Grth}^+$) contains those lattices $L$ which are contained in $\cO^m$ (resp.\ $\CC[t]^m$).
% TODO: can we? 
% \acom{Maybe we can do without parentheses here.}
% \acom{previously called ``trivial''} \jcom{I changed it so that $ R^m $ is called the standard lattice.  But I would like to leave the terminology ``trivial at $ a$'' is that ok, or should we write ``standard at $a$''.} 
% \acom{Oh, I don't know.. is trivialized at $a$? is standardized at $a$? Maybe standard at $a$ is better.. Man I never thought about this interchangeable lingo.} 
% lattice $ L_0(\cO)$ (resp. $L_0(\CC[t])$). % , i.e. $ L \subseteq L_0$.
% 
\subsection{Relations between different affine Grassmannians}
\label{ss:relsbtwgrs}
% 
These different versions of the affine Grassmannian are related as follows.  
% 
\begin{proposition}
    \label{pr:bd-th}
    There is a map $\Grbd \rightarrow \Grth $ defined in the following equivalent ways:
    \begin{enumerate}
        \item in modular terms as $$(V,\varphi,s)\mapsto (V, \varphi \big|_{D_\infty}) \, ;$$
        \item in the fibres over $ s \in \AA$ as the inclusion $$
        G(\CC[t, t^{-1}, (t-s)^{-1}])/ G(\CC[t]) \rightarrow G(\Kinf)/G(\CC[t])\,;$$
        \item in terms of lattices as $$(L,s)\mapsto L\,,$$ using the inclusion $\CC[t, t^{-1}, (t-s)^{-1}]^m \rightarrow \Kinf^m$ on ambient spaces. 
    \end{enumerate}
\end{proposition}
% 

The following result is the factorization property of the Beilinson--Drinfeld Grassmannian (see \cite[Prop. 3.13]{zhu2016introduction}).
\begin{proposition}
    \label{pr:polyno-taylor}
    The fibres $ \Gr_{0,s}$ of $ \Grbd \rightarrow \AA$ can be described as % are given as follows
    \begin{equation*}
    % \label{eq:grbdgrs}
    \Gr_{0,s} \cong 
        \begin{cases} 
            \Gr \times \Gr_s & s \ne 0 \\
            \Gr              & s = 0\,.
        \end{cases}
    \end{equation*}
    In the modular realization, this isomorphism is given by restricting the vector bundle and trivialization.
    
    Suppose that $ s \ne 0 $. In the lattice realization, this is given by forming the specializations 
    $$
        L \mapsto (L(0), L(s))\,.
    $$
    Note that if $ L = g \CC[t]^m$ for $ g \in G([t,t^{-1}, (t-s)^{-1}])$, then 
    $$
        (L(0), L(s)) = (g \cO^m, g\cO^m_s)\,. 
    $$
    In the $ s = 0 $ case, the isomorphism is described in the same way, except that we just need to form $ L(0)$.
\end{proposition}


%\begin{proposition}
 %   \label{pr:grs-gr} 
    
    There is an isomorphism $ \Gr_s \cong \Gr $ coming from the isomorphism $ \Ks \cong \cK$. 
    % 
    Combining with the \Cref{pr:polyno-taylor}, we obtain an isomorphism
    $$
    \theta_s : \Gr_{0,s} \rightarrow \Gr \times \Gr 
    $$
%\end{proposition}

% \begin{enumerate}
    % TODO: I think it makes more sense to put the first point at the end; it just relates (fibres of) the BD Gr to the ordinary Gr
    % \item There is an isomorphism $ \Gr_s \cong \Gr $ coming from the isomorphism $ \Ks \cong \cK$.
\begin{comment}
    \item \label{it:bd-th}
    %We have a map from the two point Beilinson--Drinfeld affine Grassmannian to the thick affine Grassmannian $ \Grbd \rightarrow \Grth $.
    % $$ \Grbd \rightarrow \Grth $$ 
    We define a map $ \Grbd \rightarrow \Grth $ by 
    % \acom{Don't we also want to restrict $V$} 
    % Joel says nope, restriction of vector bundle corresponds to specialization of lattice; here the map is inclusion  
    $$
        (V,\varphi,s)\mapsto (V, \varphi \big|_{D_\infty})\,.
    $$
    % 
    % It is given in modular terms by restricting the trivialization to $ D_\infty$. \acom{Does it mean $(V,\varphi,s)\mapsto (V\big|_{D_\infty},\varphi\big|_{D_\infty})$}
    In group-theoretic terms, on the fibre over $ s $, this is the inclusion
    $$
        G(\CC[t, t^{-1}, (t-s)^{-1}])/ G(\CC[t]) \rightarrow G(\Kinf)/G(\CC[t])\,. 
    $$
    % \acom{Permission to update notation and replace $\CC\xT[t^{-1}]$ by $\Kinf$ as per your suggestion Joel?}
    % \jcom{Permission granted!}
    % \acom{replaced}
    % 
    Finally, it is given in lattice terms on the fibre over $s$ as the identity on the lattice $(L,s)\mapsto L$ and using the inclusion $\CC[t, t^{-1}, (t-s)^{-1}]^m \rightarrow \Kinf^m$ on the ambient spaces.
\end{comment}
\begin{comment}
    \item \label{it:polyno-taylor}
    The fibres $ \Gr_{0,s}$ of $ \Grbd \rightarrow \AA$ can be described as % are given as follows
    \begin{equation*}
    % \label{eq:grbdgrs}
    \Gr_{0,s} \cong 
        \begin{cases} 
            \Gr \times \Gr_s & s \ne 0 \\
            \Gr              & s = 0\,.
        \end{cases}
    \end{equation*}
    This isomorphism is given in the modular realization by restricting the vector bundle and trivialization.    
    
    Suppose that $ s \ne 0 $.  In the lattice realization, this is given by forming the specializations 
    $$
        L \mapsto (L(0), L(s))\,.
    $$
    Note that if $ L = g \CC[t]^m$ for $ g \in G([t,t^{-1}, (t-s)^{-1}])$, then 
    $$
        (L(0), L(s)) = (g \cO^m, g\cO^m_s)\,. 
    $$
    % 
    % \jcom{I restated this again.  I think that it is simpler and more clear like this.  And I think that this is the fact that we end up using later.}
    % 
    % in the $ s \ne 0 $ case.
    % \jcom{Maybe we should introduce some notation for this isomorphism.}
    % \acom{Ok. Question: how is the isomorphism given at $s=0$?}
    % \acom{Ok. TODO. Also write this in group theoretic terms. Probably $[g] \mapsto ([g],[g])$ is ok. Since $g\CC[t]\otimes_{\CC[t]}\cO_s \cong g\cO_s $ for some reason, where $g\in\CC[t,t^{-1},(t-s)^{-1}]$ can be viewed as $g\in\cK_s$.}
    % 
    %    Finally, in group-theoretic terms, it is given (on representatives) by $g\mapsto (g,g)$. \acom{Reinstated the map. Choosing to supress the coset in our notation makes it potentially ambiguous. Maybe we can say inclusion $\times$ inclusion? In any case we should say something. Else, what are we referring to when we say ``This is compatible'' in the next line?}
    %    This is compatible with the lattice description since for $ g \in G(\CC[t, t^{-1}, (t-s)^{-1}]) $, we have
    %    $$
    %    \left( g \CC[t]^m \right) \otimes_{\CC[t]} \cO \cong g \cO^m
    %    $$
    %    and similarly for $ L(s)$.
    % 
    In the $ s = 0 $ case, the isomorphism is described in the same way, except that we just need to form $ L(0)$.
\end{comment}
\begin{comment}
    \item \label{it:grs-gr} There is an isomorphism $ \Gr_s \cong \Gr $ coming from the isomorphism $ \Ks \cong \cK$. 
    
    Combining with the above point, we obtain an isomorphism
    $$
    \tau_s : \Gr_{0,s} \rightarrow \Gr \times \Gr 
    $$
    % 
    %    \jcom{I tried to answer your question, but didn't explain it well.  When $ s = 0$, the map is the same except that $ L(0) = L(s) $ , so we only need $L(0)$.}
\end{comment}
% \end{enumerate}

% \jcom{I moved the ``composition'' of 2 and 3 into 3 and named it $ \tau_s$, since we will use it later quite a bit.  I'm not that happy with the layout of this section, so feel free to reorganize it (maybe into Propositions?)}

% \acom{Begun. Not sure if it is what you had in mind.}
% \jcom{I reorganized a bit.  This last point is not really much of a result, so removed the ``proposition'' label.}
% \acom{Ok}

\subsection{The fusion construction}
\label{ss:fuscon}
% \jcom{We should probably be consistent with $ \AA$ vs $\CC$.  I'm happy with either.}
% \acom{Do you mean that if we go with $\AA$ we should change $\AA^\times$ as well? Also, would you agree that the distinction is the topology? So $\AA$ is better if we were using ``generic'' to describe $s\ne 0$, which we are not.}
% \jcom{Yes, either we should write $ \AA, \AA^\times $ or $ \CC, \AA^\times$.  There is no distinction.  Always in this paper, we work with the Zariski topology whether we write $ \AA $ or $ \CC$.}
% \acom{Ok, let's be fancy and write $\AA$. (So if someone writes $s\to 0$ you don't think of it as $s$ approaches $0$ in the metric topology, but really as the limit of ideals $(s)\supset (s^2)\supset \cdots$ which, I hope, is the zero ideal?) Tentatively remapped our command for $\mathbb C$ to give $\AA$. It looks really funny to use it as notation for a field/conflate field and scheme---is there really no distinction? Surely $\AA = \spec \AA[t]$ is not great practice?}
% \jcom{I think that it would be more typical to use $ \CC $ for the field and use $ \AA$ for the affine line.  I changed $ \CC $ back to $\CC$.}


The following construction will be very important in this paper.  

Let $ \Gr_{0, \AA^\times} $ denote the preimage of $\Ax = \AA \setminus \{0\}$ under the map $\Gr_{0,\AA} \rightarrow \AA $.  
% 
%Composing the isomorphisms relating $\Grbd$ to $\Gr_s$ and $\Gr_s$ to $\Gr$, (\cref{it:polyno-taylor,it:grs-gr} of \cref{ss:relsbtwgrs} preceding), we obtain an isomorphism $ \Gr_{0,s} \cong \Gr \times \Gr$.
% TODO: cf https://tex.stackexchange.com/questions/256849/cleveref-change-behaviour-of-cref-to-use-the-abbreviated-form
% 
The isomorphisms $ \theta_s $ defined above glue together to a projection map
\begin{equation}
\label{eq:mvitau}
    \theta : \Gr_{0, \AA^\times} \rightarrow \Gr \times \Gr \, .
\end{equation}
(This $\theta$ matches the map $ \tau $ of \cite{mirkovic2007geometric}, except that we are working over $ \{0 \} \times \AA^\times$ instead of the complement of the diagonal in $ \AA^2 $.)
%  TODO: outstanding
% \acom{Question for Joel: What is the benefit of working with diagonals? Letting two points vary? What is an example of a structure that you can't see letting just one point vary as we do.}

Let $ X_1, X_2 \subset \Gr$ be two subschemes, and consider the subscheme 
$$ 
    X_1 \bdfamo X_2 := \theta^{-1}(X_1 \times X_2) \subset \Gr_{0, \AA^\times} 
$$
called the \new{open family} of $X_1$ and $X_2$. 
% 
% \jcom{I changed this a bit in order to match Mirkovi\'c--Vilonen better.}
% \acom{We say ``we define the subscheme..'' but what is there to define? Should it say ``we consider'' maybe?}
Given a point $ s \in \Ax$, we write $ X_1 \bdfamf X_2  $ for the fibre of $ X_1 \bdfamo X_2 $ over $s$. The map $ \theta_s$ identifies $ X_1 \bdfamf X_2 \subset \Gr_{0,s}$ with $ X_1 \times X_2 \subset \Gr \times \Gr$.

% TODO: outstanding 
% \acom{Well you might not want but I think it would be good to tell the reader why we use the notation $\AA^\times$ for $\AA\setminus 0$ in $\AA$ or why we use the notation $\AA$ at all.. E.g.\ do we know what happens for $\GL_m(k)$ over some other base field $k$.}

We define $ X_1 \ast_{\AA} X_2 $ to be the scheme-theoretic closure of $  X_1 \ast_{\Cx} X_2 $ in $ \Grbd $. By construction, this is a flat family over $ \AA$.

The fibre $ X_1 \geofu X_2$ of $ X_1 \ast_{\AA} X_2 $ over $0$ is a subscheme of $ \Gr_{0,0} $, but regarded as a subscheme of $ \Gr $ using {the isomorphism} $\Gr_{0,0} \cong \Gr $.  We call this subscheme the (geometric) \new{fusion} of $ X_1 $ and $ X_2$.

% \jcom{I rewrote this to introduce the $ X_1 \ast_s X_2 $ notation that we need for later.  In doing so, $ X_1 \circ X_2 $ became obsolete, since we now have $ X_1 \ast_0 X_2$, but if you like we could just define $X_1 \circ X_2 = X_1 \ast_0 X_2 $.}
% 
% Next, we consider the projection $ \pi: \Grbd \rightarrow \AA $, and define 
% $ X_1 \circ X_2 = (X_1 \ast_\AA X_2) \cap \pi^{-1}(0) \subset \Gr_{0,0} $, 
% \begin{equation*}
    % \label{deservesdisplay}
%    X_1 \circ X_2 = (X_1 \ast_\AA X_2) \cap \pi^{-1}(0) 
% \end{equation*}
% which we call the \new{fusion} of $ X_1 $ and $X_2$. It is contained in $\Gr_{0,0}$ but regarded as a subscheme of $ \Gr $ using {the isomorphism} $\Gr_{0,0} \cong \Gr $.  
% 
% By construction, 
% \acom{technically, there were two given above, so *these* constructions?} 
% $X_1 \ast_{\AA} X_2 $ is a flat family over $\AA$ whose fibre away from $0$ is $X_1 \times X_2$ and whose fibre over $ 0$ is $ X_1 \circ X_2$. 

% \acom{Ah, sorry --- so do we introduce a even more general notion of $\ast_\AA$ for arbitrary flat families? Looking at Eisenbud's geoemtry of schemes (where flat iff tor-free actually shows up as Exercise II-33!) there does not seem to be anything quite like $\ast_\AA$ or $\circ$ defined.}

% \jcom{I'm not sure how a general notion would be defined.  In our case, we are using the special fact that the general fibre is a product.}

% \acom{I mean exactly in the case of this special fact, which is not special to the BD Gr.}

% Cf. https://math.stackexchange.com/questions/1681680/flat-family-limit-of-intersection-vs-intersection-of-limits
% 
% 
% Begin OLD
%\acom{Question abt general fact: why is scheme-theoretic closure of product flat?} \jcom{See Hartshorne Proposition III.9.8.  I just taught this on the last day of my algebraic geometry class!} \acom{Cool! That Proposition is a bit more general too..}
% 
% \acom{Repeat question: what is this iso? Roger says maybe it's in MV?}
% \jcom{Now answered above.}
% 
%\jcom{I thought that it would be good to introduce this operation now, since we will use it often in the paper and it is the most convenient way to define $\Gr^{\lambda_1, \lambda_2}$. I don't know what notation we should use.}
% 
%\acom{Roger and I have been using $\ast$ to denote fusion. Do we need a notation for the scheme-theoretic closure of $X_1\times X_2\times\AA^\times$? If not then I like $X_1\ast X_2 = \overline{X_1 \times X_2 \times \AA^\times}\cap \pi^{-1}(0)$.}
%\jcom{I think that we will need notations for both things, but I'm happy to use $ \ast$ for the central fibre and use something else for the whole family.} \acom{Ok, I have changed it to notation from Roger's thesis/AK. Only now I am confused as to what is being called fusion---why do we not take the top dimensional subscheme?}
%\jcom{I guess that there are two things that one could mean by fusion of MV cycles.  This scheme $ X_1 \circ X_2$ or the expression which appear in Theorem 7.11 of mvbasis, which is a linear combination of the top-dimensional components of this scheme with multiplicites.  In the general context of this section ($X_1, X_2$ are not necessarily MV cycles), then I guess it is best to talk about the subscheme.  Maybe we can call the expression appearing Theorem 7.11 the ``numerical fusion'' of MV cycles.  By the way, somewhere in this paper we should explain Theorem 7.11 and say that this gives us motivation to study fusion of MV cycles.}
%\acom{Sure! It is quoted at the end, in \Cref{s:denouement} as an application. Addendum: for the numerical fusion I suggest simply $[Z_1][Z_2]$. This is what I will use in my talk. }
% END OLD
% 
\subsection{Some subvarieties of affine Grassmannians}
\label{ss:subgrs}
\acom{Recall the positive root cone, as well as the dominance order on coweights.}

Going forward, we fix a pair of arbitrary effective dominant coweights $\lambda', \lambda'' $ of sizes $N',N''$ and a pair of (not necessarily dominant) effective coweights $\mu',\mu''$ also of sizes $N',N''$ such that $\mu = \mu' + \mu''$ is dominant. 
Let $ \lambda = \lambda' + \lambda'' $ and $ N = N'+N''$.
% 
% Coweights define elements in the various affine Grassmannians which we consider. Warning: We will write only coset representatives for elements of the various Grassmannians; we hope that it is evident which right cosets they represent. 
% the right cosets which they represent are clear from the context.

% We consider the following subschemes of the affine Grassmannians.
Using $\lambda,\lambda',\lambda''$ and $\mu,\mu',\mu''$ we define the subschemes of $\Gr$, $\Grth$, and $\Grbd$ which will be considered, give some properties, and say how they are related.  
% 
\begin{definition}
\label{def:sphschub}
    The \new{spherical Schubert cell} $\Gr^\lambda = G(\cO) t^\lambda$ and its closure 
    $ \overline\Gr^\lambda = \bigcup_{\gamma \le \lambda} \Gr^{\gamma} $ 
    a \new{spherical Schubert variety}.  
\end{definition}
    % \acom{do we prefer $\overline{\Gr}^\lambda$ to $\overline{\Gr^\lambda}$? I am for the former! Though it is less accurate??} \jcom{I'm not sure which is better.  I was ``testing'' it out.}
    % 
\begin{definition}
\label{def:sphfus}
    The \new{family of two spherical Schubert varieties} $\overline{\Gr}^{\lambda', \lambda''}_{0, \AA} = \overline{\Gr}^{\lambda'} \bdfamc \overline{\Gr}^{\lambda''} $.
    % $$ 
    %     \overline{\Gr}^{\lambda', \lambda''}_{0, \AA} = \overline{\Gr}^{\lambda'} \ast_\AA \overline{\Gr}^{\lambda''} \rightarrow \AA \,.
    % $$
\end{definition}
% \jcom{It used to say ``fusion'' of two spherical Schubert varieties, but we are using the word fusion just for the central fibre, so we need a different name.} 
% \acom{Family is good. We should put BD on p. 4.}
% \acom{I guess that it is good to have the notation here, in place of $\overline{\overline\Gr^{\lambda'}\times\overline\Gr^{\lambda''}\times\AA^\times}$..}
%\acom{should we also subsript this family with $0,\AA$?}
%By construction the fibre $ \overline{\Gr}_{0,s}^{\lambda', \lambda''} $ of $\overline{\Gr}^{\lambda', \lambda''}_{0, \AA}$ for $ s \ne 0 $ is $ \overline{\Gr}^{\lambda'} \times \overline{\Gr}^{\lambda''}$.  
% By \cite[Proposition 3.1.14]{zhu2016introduction},
% Zhu's theorem (\jcom{need ref} \acom{pretty sure it's }), 
% the fibre over $ 0 $ is $ \overline{\Gr}^{\lambda' + \lambda''}$.
By a Theorem of Zhu, $ \overline{\Gr}^{\lambda'} \geofu \overline{\Gr}^{\lambda''} $ is reduced and equal to $ \overline{\Gr}^{\lambda' + \lambda''}$ \cite[Proposition 3.1.14]{zhu2016introduction}.
% Suppose that $ s \ne 0$.  
If $s\ne0$, then in the fibre $\overline{\Gr}_{0,s}^{\lambda', \lambda''}$ we have the open locus $ \Gr_{0,s}^{\lambda', \lambda''} =  \Gr^{\lambda'} \bdfamf \Gr^{\lambda''} $ a $ G(\CC[t])$-orbit
% .  The lattice description of $ \Gr_{0,s}^{\lambda', \lambda''}$ 
whose lattice description is given in \Cref{le:Grl1l2} below.
% \acom{Why $G(\CC[t])$. Because we are on the left side!}
% \acom{Sorry I keep changing (abbreviating) ``By a theorem of Zhu'', but is the citation not sufficient?}
% \jcom{I like to say a person's name when I cite their work!}
% \acom{Ok}
% 
Because we consider effective dominant coweights, the spherical Schubert varieties and their fusions lie in the positive part of the (thick) affine Grassmannian.
% 
\begin{lemma}
\label{le:sphfusispos}
    The map $ \Gr_{0, \AA} \rightarrow \Grth$ restricts to a map $ \overline{\Gr}^{\lambda', \lambda''}_{0, \AA} \rightarrow \Grth^+$.
\end{lemma}
\begin{proof}
    Let $ s \ne 0 $. Since $ \lambda', \lambda'' $ are effective, $ t^{\lambda'}, (t-s)^{\lambda''} \in \Grth^+ $.  Since $\Grth^+$ is closed and invariant under the action of $ G(\CC[t])$,  $ \overline{\Gr}_{0,s}^{\lambda', \lambda''} \subset \Grth^+$.
    
    For the $ s = 0$ fibre, a similar reasoning applies (or we can simply conclude by taking closure).
\end{proof}
% TODO: yes the answer is yes, note to self
% \acom{Does $M_m(\CC[t])\cap G\xT[t^{-1}] = \{g\in M(\CC[t]):\det g\in\CC[t]\setminus0\}$?}

% \acom{why ``and so''? bc orbits are connected?}
% \jcom{I turned this into a Lemma.}

%As above, since $ \lambda', \lambda'' $ are effective, the map $ \acom{What is ``as above''? Also, we have only described the open loci in fibres over $s\ne0$.}

% Now fix two effective (possibly non-dominant) coweights $ \mu', \mu''$ of sizes $N',N''$ such that $ \mu = \mu' + \mu'' $ is dominant. 
% (We do not require $ \mu', \mu'' $ to be dominant.) 
% Using $ \mu, \mu', \mu''$, we define the following subschemes.

\begin{definition}
\label{def:klslice}
    The \new{Kazhdan--Lusztig slice} $\cW_\mu = G_1(\Oinf) t^\mu \subset \Grth $.  
\end{definition}
% 

In modular terms, $\cW_\mu$ corresponds to the locus of those $ (V, \varphi)$ such that $ V $ is isomorphic to the trivial vector bundle on $ \PP$ and such that $ \varphi$ preserves the {Harder--Narasimhan filtration of $V$ at $ \infty$}. The lattice description of $ \cW_\mu \cap \Grth_+$ is given in Lemma \ref{le:Wmu} below. 
% 

\acom{Comment why the above doesn't make sense for $\mu$ not dominant?}
\jcom{It does make sense when $ \mu $ is not dominant.  The reason for restricting to dominant $ \mu $ is so that $ S^\mu \subset \cW^\mu$.  I agree that we should mention this, but I'm not sure where.}

% \acom{First lattice description that doesn't come for free?}
% 
% \acom{que est-ce?} \jcom{It's not very relevant for this paper.  Here is an explanation: every vector bundle on $\PP$ (or maybe any curve) has a special filtration called the HN--filtration; it is a partial flag of subbundles of type determined by $ \mu$.  We require that $ \varphi$ takes this filtration to the standard partial flag at the fibre over $ \infty$.  Maybe ``preserves'' is not the best word above.}
% A: Ok thanks!
% 
\begin{definition} 
\label{def:inftyorbit}
    The \new{semi-infinite orbit} $ S^\mu = N_-(\cK)t^\mu \subset \Gr $
\end{definition}
\acom{and its closure?}
\jcom{I don't think that we use the closure in this paper, do we?}
\begin{definition} 
\label{def:inftyorbitfam}
    The \new{family of two semi-infinite orbits} 
 $S^{\mu', \mu''}_{0,\AA} \subset \Grbd$
 which we define to have fibres $ S^{\mu', \mu''}_{0,s} \cong S^{\mu'}\times S^{\mu''} $ for $ s \ne 0$ and fibre $ S^{\mu}$ over $ s = 0 $.
\end{definition}
Note that since $ S^{\mu}$ is not closed, it is not true that $S^{\mu', \mu''}_{0,\AA} = S^{\mu'} \ast_\AA S^{\mu''}$.
% 
%\acom{Commented out fusion part for now. Unsure about defining it as the family whose 0 fibre is $S^{\mu' + \mu''}$ and whose generic fibre is $S^{\mu'}\times S^{\mu''}$ up to $\tau$. Baumann--Riche consider the attracting set of $C_\mu = \sqcup_{\mu' + \mu'' = \mu } m(\tilde C_{\mu',\mu''})$ where $\tilde C_{\mu',\mu''}$ is a connected component of fixed points in $\Grbd\tilde\times\Grbd$. Maybe we can consider the attracting set of just one of these?}
% 
If $ s \ne 0 $, then the fibre $S^{\mu', \mu''}_{0,s} $ is given by

\acom{Don't we want this to be the definition?}
$$
% S^{\mu', \mu''}_{0,s} = 
    N_-(\CC[t, t^{-1}, (t-s)^{-1}])t^{\mu'} (t-s)^{\mu''} G(\CC[t])\subset G(\CC[t,t^{-1}, (t-s)^{-1}]) / G(\CC[t]) \,. % \G(\CC[t])
$$
See \cite[Section~5.2]{baumann2020bases} for further details.

% TODO: resolve
% \jcom{Maybe we should introduce the $ L_{\mu', \mu''} $ notation, but I'm not sure it is necessary.}
%On the other hand, if $ s = 0$, then the fibre $S^{\mu', \mu''}_{0,0} $ equals $ S^{\mu' + \mu''}$. 
% TODO: resolve
% \acom{changed $\mu$ to $\mu' + \mu''$ since we wrote it out for $\overline{\Gr}_{0,\AA}^{\lambda', \lambda''} $}
% 


\section{Matrices}
\label{s:mats}
% 
\subsection{Adjoint orbits and their deformations}
\label{ss:familiesofadjointorbits}
% 
We now consider some subvarieties of the space of $ N\times N$ matrices, again using the coweights $ \lambda, \lambda', \lambda'', \mu, \mu', \mu''$ fixed in the previous section. 
Recall that $\lambda, \mu $ are partitions of $ N$.

Given a point $ s \in \AA$ we write $ J_{s,\lambda}$ for the Jordan form matrix with eigenvalue $ s$ and Jordan blocks of sizes $ \lambda_1, \dots, \lambda_m$.
    
\begin{definition}
\label{def:Olam}
The nilpotent (adjoint) orbit $ \OO^\lambda \subset M_N(\CC)$ of matrices conjugate to $ J_{0,\lambda}$. These matrices and the linear operators they represent will be said to have Jordan type $\lambda$.
\end{definition}  
% 
% Temporarily commenting out, don't use
% Its closure is $ \overline{\OO}^\lambda = \bigcup_{\gamma \le \lambda} \OO^{\gamma}$.
% 
\begin{definition}
\label{def:Olamlam}
    For $ s \in \CC, s \ne 0$, the (adjoint) orbit $ \OO^{\lambda', \lambda''}_{0,s}$ of matrices conjugate to $ J_{0,\lambda'} \oplus J_{s,\lambda''}$.
    These matrices and the linear operators they represent will be said to have Jordan type $((0,\lambda'), (s,\lambda''))$.
\end{definition}  
% 

%A linear operator $ T : V \rightarrow V $ on an $N$-dimensional vector space $V$ is said to have Jordan type $((0,\lambda'), (s,\lambda''))$ if its matrix representatives lie in $ \OO^{\lambda', \lambda''}_{0,s}$.
% \acom{secret definition; add `a matrix is likewise said to have Jordan type...if it lies in'?}
% \jcom{Is that better?}
% \acom{Yay.}
% 

% The closure $ \overline{\OO}^{\lambda', \lambda''}_{0,s}$ is $\bigcup_{\gamma' \le \lambda', \gamma'' \le \lambda''} \OO^{\gamma', \gamma''}_{0,s}$.     
% \jcom{Do we need this?}
     
We recall that these orbits have closures which are given by rank conditions.  
More precisely, we have
$$
    \overline{\OO}^\lambda = \{ A \in M_N(\CC) : \rk A^c \le N - \#\text{~boxes in first $c$ columns of }\lambda \}
$$
and
\begin{equation} 
\label{eq:ranks}
\begin{split}
    % 
    \overline{\OO}^{\lambda', \lambda''}_{0,s} = \{ A \in M_N(\CC) : \rk A^i &\le N - 
    \#\text{~boxes in first $c$ columns of }\lambda' \\
    \rk (A-s)^c &\le N - \#\text{~boxes in first $c$ columns of }\lambda'' \}\,. 
\end{split}
\end{equation}
%  

The following fact seems to be well-known but we could not find this exact statement in the literature.
\begin{proposition} 
    \label{prop:adjoint}
    There exists a flat family $\overline{\OO}^{\lambda', \lambda''}_{0,\AA} \rightarrow \AA$ whose fibre over $s \in \AA$ is reduced and given by $\overline{\OO}^{\lambda', \lambda''}_{0,s}$ if $s \ne 0 $ and $\overline{\OO}^\lambda $ if $ s = 0$.
\end{proposition}
% 
In order to prove this proposition, we will need to recall some results from Eisenbud--Saltman \cite{eisenbud1989rank}. 
% 

Let $ r $ be a decreasing, concave, non-negative function of $\NN$ with $r(0) = N$ called a \new{rank function}.  Let $k $ be maximal such that $ r(k) \ne 0 $.
% \jcom{I don't know if it is really necessary to introduce this $ k$.  Later it will be the number of columns of $ \lambda$, but we could just regard $ \lambda$ to have some columns of size 0.} \acom{And make it $N$? Was $k = m$ replaced because $m$ is already used?} \jcom{Yes and yes} \acom{I like the idea of making it $N$}
% 
Let $ W$ be a subspace of $ \AA^k$. Eisenbud and Saltman define and study the flat family $ X_{r,W} \rightarrow W$ whose fibres are reduced and defined by rank conditions. We will now describe these fibres. 
% departing slightly from the notation of \cite{eisenbud1989rank}.

Let $ z \in \AA^k$ be a point. Some of the coordinates of $z$ may be equal so we introduce the following data to keep track of these equalities. There exist a sequence of integers $k_\bullet = (k_0,\dots,k_\ell)$ such that $ 0=k_0< k_1< \dots < k_\ell = k $, a sequence of points $s_\bullet = (s_1, \dots, s_\ell )\in\AA^\ell$ such that $s_a\ne s_b$ for any $a\ne b$, and a permutation  $ p $ of $ \{1, \dots, k\}$ such that 
$$ 
    s_a = z_{p(k_{a-1}+1)} = z_{p(k_{a-1} + 2)} =  \cdots = z_{p(k_a)}
$$ 
for each $a = 1,\dots,\ell$. 
Given the choice of $ s_\bullet$ we require that $ p $ is of minimal length. 
Then, given $z$, the data $k_\bullet, s_\bullet, p$ is unique up to a permutation of $ \{1, \dots, \ell\}$.
% 
%\jcom{Eisenbud--Saltman don't introduce this $ s_j$ notation, but I find it helpful.}
% 
%\acom{Agreed. Maybe we mention that the point of $p$ is to group the repeated eigenvalues? It wouldn't be the most obvious thing we point out.}
%\jcom{That is what I was trying to say with ``introduce some data \dots''  Maybe it could be more clear.  I also clarified the uniqueness.}
%\acom{Oh, sorry, I see it. Maybe because it was the start of a new paragraph I didn't connect `data' and `ranks' at first glance.}

Next for $ a = 1, \dots \ell $ and $ c = 1, \dots, k_{j+1} - k_j$, we define
$$
    % r_{z,j}(i):= N - r(p(m_j)) + r(p(m_j + i)) 
    r_{z,a}(c):= N + \sum_{d = 1}^c r(p(k_a + d)) - r(p(k_a + d) - 1)  \, . 
$$
% \jcom{This is the same as what ES denote $r(i,j)$ except the roles of $ i, j$ swapped.  We could swap them back.}
% \acom{I don't think that there is any need to swap back. But maybe we could use $c$ (for column) isntead of $i$, since we use $i$ in the same context quite a bit to denote a letter in the alphabet $\{1,\dots,m\}$.} 
% \jcom{Sure, that is a good idea.}
% \acom{Ok, switched some letters. Think $d$ is good as `delta'.}
%\jcom{I fixed it now.  I didn't want to use ES's $a_i$.} 
%\acom{\emoji{+1}}

% 
By \cite[Corollary 2.2]{eisenbud1989rank}, the fibre of the flat family $ X_{r,W} $ over $ z$ is given by
\begin{equation} 
    \label{eq:ESfibre}
    X_{r,z} = \{ A \in M_N(\CC) :\rk (A-s_a)^c\le r_{z,a}(c) \text{ for all } c , a \text{ as above}\}.
\end{equation}
% 
We will now apply these ideas to prove our \Cref{prop:adjoint}.
% 
\begin{proof}
% 
%\begin{lemma}
%    \label{lem:es}
%    Let $\lambda = \lambda' + \lambda''$ be partitions. There exists a permutation of the columns of $\lambda$ such that the first $\lambda'_1$ columns are precisely the columns of $\lambda'$ and the last $\lambda''_1$ columns are precisely the columns of $\lambda''$. 
%\end{lemma}
%Recall that $\lambda' + \lambda'' = \lambda$ is a partition of $N$. 
% 
Define 
$$
    r(c) = N - \#\text{~boxes in first $c$ columns of }\lambda\,.
$$
It is easy to see that this is a rank function, with $ k = \lambda_1$, the number of columns of $ \lambda$.
%\begin{lemma}
%   The function $r$
%    defined by $r(j) = N - \#\text{~boxes in first $j$ columns of }\lambda$ 
%is a rank function. 
%\end{lemma}

Since $\lambda = \lambda' + \lambda''$, there exists a permutation $ p $ of $ \{1, \dots, k\}$ (the columns of $ \lambda$) such that $ p(1), \dots, p(k_1) $ are the columns of $ \lambda'$ and $ p(k_1+1), \dots, p(k)$ are the columns of $ \lambda''$. Here $ k_1 = \lambda'_1$ the number of columns of $ \lambda'$.

For $ s \in \AA$, we define $ z(s) \in \AA^k$ by 
\[
\begin{cases}
    z(s)_{p(c)} = 0 &  c = 1, \dots, k_1 \\
    z(s)_{p(c)} = s &  c = k_1 + 1, \dots, k\,.
\end{cases}    
\]
% $ z(s)_{p(j)} = 0 $ for $ j = 1, \dots, k_1 $ and $ z(s)_{p(j)} = s $ for $ j = k_1 + 1, \dots, k$.

For $ s \ne 0$, we see that the equalities in $ z(s) $ give rise to the data of 
\(\ell =2\), \(k_\bullet = (0,\lambda_1')\), \(s_\bullet = (0,s)\) and the permutation $p$.
% $ \ell = 2$, $k_1$, $s_1 = 0$, $s_2 = s$, and the permutation $p $.
We also see that
\begin{equation} 
\label{eq:rcols}
    \begin{split}
            r_{z(s), 1}(c) &=  N - \#\text{~boxes in first $c$ columns of }\lambda' \\
            r_{z(s), 2}(c) &=  N - \#\text{~boxes in first $c$ columns of }\lambda'' \,. 
    \end{split}
\end{equation}
On the other hand, for $z(0)$, we get that $ \ell = 1$ and that 
% \acom{This was $r = 1$ but I think it should be $\ell = 1$.} \jcom{Yes, you are correct.}
\begin{equation} 
\label{eq:rcol2}
    r_{z(0),1}(c) = 
    r(c) = N - \#\text{~boxes in first $c$ columns of }\lambda\,. 
\end{equation}
%\jcom{Someone should check that I chose the notation correctly to make this work out.}
% 
%\acom{What do we mean by equalities in $z(s)$ reproduce $p$? I thought $z(s)$ was defined by $p$. Also, $r_{z(s),1}(i) = N- r(p(k_1)) + r(p(k_1 + i)) = N - (N-\#\text{boxes in first }p(k_1)\text{ cols} + \cdots)\ne $~\Cref{eq:rcols}. We want to apply $p$ to $\{1,\dots,i\}$ and not just $i$. I guess we could clarify/declare that $r(p(i)) = N - \#$ boxes in columns $p(1),\dots,p(i)$. For a minute I thought it was actually fine, but what we have is: $r_{z(s),j}(i) = N - (\#\text{boxes in cols }1,\dots,p(k_j + i) - \#\text{boxes in cols }1,\dots,p(k_j))$ and what we want is $\dots (\#\text{boxes in cols }p(1),\dots,p(k_j + i) - \#\text{boxes in cols }p(1),\dots,p(k_j + i))$ right?}
% 
%\jcom{I fixed the definition of $ r_{z,j}(i)$, so now it is correct, I believe.  I changed the wording of ``reproduce''. I'm trying to say that $ p$ is used to define $ z(s)$ and the we get $ p $ back from $ z(s)$ as the permutation coming from the equalities.}
%\acom{\emoji{+1}}
% 
Let $ W = \{ z(s) : s \in \CC \}$. Combining \Cref{eq:ranks,eq:ESfibre,eq:rcols,eq:rcol2},
% (\ref{eq:ranks}), (\ref{eq:ESfibre}), (\ref{eq:rcols}), (\ref{eq:rcols2}) 
we see that the Eisenbud--Saltman family $ X_{r, W} \rightarrow W $ gives our family $ \overline{\OO}^{\lambda', \lambda''}_{0, \AA}$.
\end{proof}
% 
% 
% The family of adjoint orbits $  whose fibre over $ s \ne 0 $ is $ \overline{\OO}^{\lambda', \lambda''}_{0,s}$ and whose \acom{Claim:} fibre over 0 is $\overline{\OO}^\lambda$ (a consequence of Eisenbud and Salten's characterization of ``rank varieties'' as proved in \Cref{cor:es}). \acom{TODO: make into definition to be x-referenced in proof of description of fibres}
% 
% \jcom{We should justify why the 0 fibre is correct scheme-theoretically.} 
%\acom{does it follow because ``$s$ divides $\det g$'' is a closed condition 
%in $\AA_s\times \AA_{\det}$? 
%so the set of $A$ which are conjugate to
%$J_{0,\lambda'} \oplus J_{s,\lambda''}$
%by a matrix whose determinant is divisible by $s$ is also closed?}
%\jcom{I didn't follow your argument. One approach would be to write down the generators for the ideal of $\overline{\OO}^{\lambda', \lambda''}_{0,s} $ and then set $ s =0$.  For example, take $ \lambda' = (1) = \lambda'' $ (I know it is a small example!), then the ideal is generated by $ tr(A) = s$, $det(A) = 0$, so when we take $ s =0$, we get just $ tr(A) = 0, det(A) = 0$.  I am hoping that we can find a reference for this result somewhere.}
%\acom{I thought that the point would be to show that a dense subset of matrices which are conjugate to $J_{0,\lambda'}\oplus J_{s,\lambda''}$ limit to matrices which are conjugate to $J_\lambda$. In particular, that the conjugating matrix remains invertible in the $s\to0$ limit.}
% 
% TODO: delete commented out remark and subcomment!
% \begin{remark}
\begin{comment}
Base case $m = 1$: by a slight abuse of notation let $\lambda', \lambda_2 \in \NN$. Claim: $J=J_{0,\lambda'} \oplus J_{s,\lambda_2}$ is conjugate to 

% $\begin{pNiceArray}{CC|CC}[first-row,last-row=5,first-col,last-col,nullify-dots]
% & C_1 & \Cdots & & C_4 & \\
% L_1 & a_{11} & a_{12} & a_{13} & a_{14} & L_1 \\
% \Vdots & a_{21} & a_{22} & a_{23} & a_{24} & \Vdots \\
% \hline
% & a_{31} & a_{32} & a_{33} & a_{34} & \\
% L_4 & a_{41} & a_{42} & a_{43} & a_{44} & L_4 \\
% & C_1 & \Cdots & & C_4 &
% \end{pNiceArray}$
\[
A = \begin{bNiceArray}{ccc|ccc}[columns-width = auto,first-row,last-col,code-for-first-row = \color{blue}\scriptstyle\rotate,code-for-last-col = \color{blue}\scriptstyle,nullify-dots,xdots/line-style=loosely dotted]
1 & \Cdots & \lambda_1 & \lambda_1 + 1 & \Cdots & \lambda_1 + \lambda_2 \\
0 & 1 & 0 & 0 & 0 & 0 & 1\\
0 & \Ddots & 1 & 0 & 0 & 0 & \Vdots \\
0 & 0 & 0 & 1 & 0 & 0 & \lambda_1 \\
\hline
    & & & s & 1 & 0 & \lambda_1 + 1 \\
    & & & 0 & \Ddots & 1 & \Vdots \\
    & & & 0 & 0 & s & \lambda_1 + \lambda_2 
\end{bNiceArray} 
\]
\end{comment}
% Denote by $R_i$ the $i$th row of $J$ 
%Let $g = E_{\lambda_2}\cdots E_1$ be the product of elementary matrices $E_i$ which correspond to the elementary row operations 
%$$R_{\lambda_1 + i - 1} \leftarrow R_{\lambda_1 + i-1} + \frac 1s R_{\lambda_1 + i}$$ 
%for $i = 1,\dots,\lambda_2$. Then $gJg^{-1} = A$. For the next part we introduce the notation $A_{\lambda_1+\lambda_2}$ for this matrix $A$. 
% 
%Now let $\lambda_1,\lambda_2$ be arbitrary. Clearly $J_{0,\lambda_1} \oplus J_{0,\lambda_2}$ is conjugate to 
%$$\bigoplus_{i=1}^m (J_{\lambda_{1,i}}\oplus J_{\lambda_{2,i}})\,.$$ 
%Moreover each block $J_{\lambda_{1,i}}\oplus J_{\lambda_{2,i}}$ is conjugate to $A_{\lambda_{1,i}+\lambda_{2,i}}$. Altogether $J_{0,\lambda_1} \oplus J_{0,\lambda_2}$ is conjugate to $\bigoplus_{i = 1}^m A_{\lambda_{1,i}+\lambda_{2,i}}$ and this latter matrix specializes to the Jordan normal form $J_{0,\lambda_1 + \lambda_2}$ at $s=0$.
% 
% By Tanisaki $A\in \OO^\lambda$ iff the coefficients of $z^m$ in $k\times k$ minors of $zI - A$ for any $m\le p_\lambda(k) - 1$ and for any $k = 1\dots |\lambda|$ vanish. Here $p_\lambda(k) = \lambda_{n-k+1} + \cdots + b_n$ and $k = 1,\dots,n$. So $p_\lambda(k) = \#$ boxes in the last $k$ rows of $\lambda$.
% 
% In particular this result describes the ideal $I_i$ of $N_i\times N_i$ matrices $A_i$ such that $A_i - \delta_{i,2}s$ is conjugate to $J_{\delta_{i,2} s, \lambda_i}$ for $i = 1,2$. Let $A_1,A_2$ be such a pair of matrices. Clearly $A_1 \oplus A_2$ is conjugate to $J_{0,\lambda_1} \oplus J_{s,\lambda_2}$. Let $g$ be such that $g(J_{0,\lambda_1} \oplus J_{s,\lambda_2})g^{-1} = \bigoplus_{i = 1}^m A_{\lambda_{1,i}+\lambda_{2,i}}$. 
% 
% If we apply the change of basis $g$ to the ideal $I=I_1 + I_2$ and set $s = 0$ (if possible) do we recover the ideal of $\OO^{\lambda_1 + \lambda_2}$? Let $A^g = g(A_1 \oplus A_2) g^{-1}$...
% \end{remark}
% 
\subsection{The Mirkovi\'c--Vybornov slice}
\label{ss:mvyslice} 
% 
% Fix the ``$\mu$-numeration'' \((e^1_1,\ldots,e^{\mu_1}_1,\ldots,e^1_m,\ldots,e^{\mu_m}_m)\) of the standard basis of $\CC^N$. 
% \acom{I don't suppose we need this basis now that we're just describing $\TT_\mu$ in words.}
% 
% \begin{definition}
Recall that $\mu=(\mu_1,\dots,\mu_m)$ is a partition of $N$. The \new{Mirkovi\'c--Vybornov slice} $\TT_\mu$ is the affine space of $N\times N$ matrices of the form
% defined as the set of $A\in M_N(\CC)$ such that 
% \[
%     \begin{aligned}
%         &\text{for all } 1 \le a,s\le m\,,
%         \text{for all } 1\le b\le \mu_a\,, 1\le t\le \mu_s\,, \\
%         &\text{if } 1\le t < \mu_s \text{ or } t = \mu_s < b \le \mu_a \\
%         &\text{then } e^t_s\cdot (A-J_\mu) e^b_a = 0 \,.
%     \end{aligned}    
% \]
% \end{definition}
% \jcom{I'm not a huge fan of this description, but I don't know how to write it better.}
% 
% \acom{Agree. Happy to just have the in-words description.}
% 
% In words, $A$ 
% a $\mu$ Jordan form matrix plus 
$J_{0,\mu} + x$ where $x$ is a $\mu\times\mu$ block matrix with possibly nonzero entries $A_{ij}^1,\dots,A_{ij}^{\min(\mu_i,\mu_j)}$ in the first $\min(\mu_i,\mu_j)$ columns of the last row of each $\mu_i\times\mu_j$ block. 
% $\dim \TT_\mu = N^2 - \dim \OO_\mu$. 

By example, if 
% $\mu=(3,2,2,1)$, 
$\mu = (3,2)$ then $A\in\TT_\mu$ looks like 
\[
    \left[
        \begin{BMAT}(e){ccc;cc}{ccc;cc} 
        0 & 1 & 0 & 0 & 0\\
        0 & 0 & 1 & 0 & 0\\
        A_{11}^1 & A_{11}^2 & A_{11}^3 & A_{12}^1 & A_{12}^2\\
        0 & 0 & 0 & 0 & 1\\
        A_{21}^1 & A_{21}^2 & 0 & A_{22}^1 & A_{22}^2
        \end{BMAT}\right] 
    % TODO: REDO 
    % \left[
    %     \begin{BMAT}(e){ccc;cc;c;c}{ccc;cc;c;c}
    %         & 1 & & & & & \\
    %         &  & 1 & & & & \\
    %     A_{11}^1 & A_{11}^2 & A_{11}^3 & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{14}^1 \\
    %         &  & &  & 1 & & \\
    %         A_{21}^1 & A_{21}^2 & & A_{22}^1 & A_{22}^2 & A_{23}^1 & A_{24}^1 \\
    %         A_{31}^1 & & & A_{32}^1 & & A_{33}^1 & A_{34}^1 \\
    %         A_{41}^1 & & & A_{42}^1 & & A_{43}^1 & A_{43}^1
    % \end{BMAT}
    % \right] % \,. 
\]
for some $A_{ij}^k\in\CC$. 
% \[
%     \left[\begin{BMAT}(e){c;cc;cc;ccc}{c;cc;cc;ccc} 
%         0 & A_0 & A_1 & A_2 & A_3 & A_4 & A_5 & A_6\\
%         0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\
%         0 & 0 & 0 & A_7 & A_8 & A_9 & A_{10} & A_{11}\\
%         0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
%         0 & 0 & 0 & 0 & 0 & A_{12} & A_{13} & A_{14}\\
%         0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\
%         0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
%         0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
%         \end{BMAT}\right]
% \]
% 

To $ A \in \TT_\mu$ we will associate the $m\times m$ matrix of polynomials 
% $ g(A) = \left( g(A)_{ij} \right)$ 
$g(A)$ in $ M_m(\CC[t]) $ whose $(i,j)$th entry is defined as follows.
\begin{equation}
    \label{eq:mvyofa}
    g(A)_{ij} = 
\begin{cases} t^{\mu_i} - \sum_{k=1}^{\mu_i} A^k_{ji} t^{k-1} & i = j\,, \\
    % A^k_{ji} t^{k-1} & i = j \\
        % \text{ if $ i = j$} \\
        - \sum_{k=1}^{\mu_i} A^k_{ji} t^{k-1} & i \ne j\,. 
    %  \text{ if $ i \ne j$ }
\end{cases}
\end{equation}
% $A^k_{ji}$ denotes the $k$th entry from the left of the last row of the $\mu_j\times\mu_i$ block of $A$. 
% 

Continuing with the $\mu=(3,2)$ example, 
\[
    % A = \left[
    %     \begin{BMAT}(e){ccc;cc}{ccc;cc} 
    %     0 & 1 & 0 & 0 & 0\\
    %     0 & 0 & 1 & 0 & 0\\
    %     A_{11}^1 & A_{11}^2 & A_{11}^3 & A_{12}^1 & A_{12}^2\\
    %     0 & 0 & 0 & 0 & 1\\
    %     A_{21}^1 & A_{21}^2 & 0 & A_{22}^1 & A_{22}^2
    %     \end{BMAT}\right]    
    % \Longrightarrow 
        g(A) = 
        \left[\begin{array}{rr}
            t^{3} - A_{11}^3 t^2 - A_{11}^2 t - A_{11}^1 & -A_{21}^2t - A_{21}^1  \\
            -A_{12}^2 t - A_{12}^1 & t^{2} - A_{22}^2 t - A_{22}^1
        \end{array}
        \right]\,. 
    % TODO: REDO
\]
% For example, the $A$ above will define 
% \acom{the transpose of! TODO. Had script?}
% \[
% \begin{bmatrix}
%     t^3 - A_{11}^1 - A_{11}^2 t - A_{11}^3 t^2 & - A_{12}^1 - A_{12}^2 t & -A_{13}^1 & -A_{14}^1 \\
%     & t^2 \\
%     & & t \\
%     & & & t 
% \end{bmatrix}    
% \]
% 
% \jcom{I moved the definition here since it will be useful for defining the upper triangular stuff.}
% \acom{Ok.}
% 

In other words, the $ \mu_i\times\mu_j$ block of $ A $ is used to produce a polynomial which is inserted in the $(j,i)$ entry of the $m\times m$ matrix $ g(A)$. 

In $\TT_\mu$ we will be interested in a certain family of block upper-triangular matrices.
\begin{definition} The \new{upper-triangular} \mvy slice $\UU^{\mu', \mu''}_{0,\AA}\rightarrow \AA $ is defined by
$$
\UU^{\mu', \mu''}_{0,\AA} := \{ (A,s) \in \TT_\mu \times \AA : g(A)_{ii} = t^{\mu'_{i}} (t-s)^{\mu''_{i}}, g(A)_{ij} = 0 \text{ for $ j < i $ }\}\,. 
$$
\end{definition}
So a matrix in $\UU^{\mu', \mu''}_{0,\AA}$ is weakly block upper-triangular and its diagonal blocks are given by the companion matrices for the polynomials $\{t^{\mu'_{i}} (t-s)^{\mu''_{i}} : i=1,\dots,m\}$.

For example, elements of $ \UU_{0,s}^{(1,1,0),(2,1,1)}$ look like 
% 
\[
    \left[
        \begin{BMAT}(e){ccc;cc;c}{ccc;cc;c} 
        0 & 1 & 0 & 0 & 0 & 0\\
        0 & 0 & 1 & 0 & 0 & 0\\
        0 & -s^2 & 2s & A_{12}^1 & A_{12}^2 & A_{13}^1 \\
        0 & 0 & 0 & 0 & 1 & 0\\
        0 & 0 & 0 & 0 & s & A_{23}^1\\
        0 & 0 & 0 & 0 & 0 & s
        \end{BMAT}
    \right] \,.   
% TODO: REDO
\]
% 
Note that the fibre $  \UU^{\mu', \mu''}_{0,0}$ is the same as the intersection $ \TT_\mu \cap \mathfrak n $, where $ \mathfrak n $ denotes the set of strictly upper-triangular matrices.  

%\acom{Mention that any other decomposition $\nu' + \nu''$ of $\mu' + \mu''$ will give a slice $\UU^{\nu',\nu''}_{0,\AA}$ with the same zero fibre.}

% \acom{These $\UU$'s should also have attr descriptions. What are they?}
% \jcom{I don't think that it is very interesting. Just take a diagonal matrix, constant on each block.  Then $\UU$ will be the attracting set of the block diagonal matrix for this action.}
% A: Ok
    
% \jcom{Instead of $\TT^+$ maybe a different letter would be best? I'm moved all $\lambda, \mu$ to upper indices for consistency (except for $ \cW_\mu, \TT_\mu$) and also to let us put $ s $ or $ \AA$ in the lower index.  I haven't been very consistent about $ \AA $ vs $ \CC$.  Which do you prefer?}
% 
% \acom{Maybe $\UU$ for a different letter? And, I guess we do not need $\AA$ but it is a nice letter to have around. It also serves to distinguish the $\CC$ over which $R,K$ are defined from the $\AA$ over which $\Grbd$ is defined?}
% \jcom{Sure $\UU$ is good.}
% \acom{And, sorry, ignore my other comment; it's the same $\CC$ (or $\AA$) nothing to distinguish.}
% 
% TODO: place this better? 
% \acom{The following is a rough note.} 
\begin{comment}
\subsubsection{Detour of rank varieties}
% \begin{theorem}(\cite{eisenbud1989rank})
    % \label{thm:es}
Let $r$ be a decreasing concave non-negative integral function with $r(0) = N$. Such a function is called a rank function. Eisenbud and Saltment associate to a rank function the vareity of $N\times N$ matrices 
% The relevant result from Eisenbud--Saltman seems to be that 
$$X_r = X_{r,0} = \{A:\rk A^i \le r(i) \}$$ 
and show that it is the flat limit of a certain family 
% $$X_{r,\lambda} = \{A : \rk (A-\lambda_i)^j\le r(i,j)\}$$
$$X_{r,z} = \{A : \rk (A-z_i)^j\le r(i,j)\}$$
with $r(i,j)$ determined by $r(i)$.  
% \end{theorem}

\acom{Don't know how much of this setup to recall but here are the parts that will appear in the quoted theorem.}
% 
More precisely, they show that 
\begin{enumerate}
    \item $X_r$ is a normal variety
    \item $X_r$ is Gorenstein with rational singularities
    \item $X_r$ fits into a flat family over $\AA^m$ of normal varieties whose fibre over a point $(z_1,\dots,z_m)$ such that the $z_i$ are all distinct is 
\end{enumerate}
\[
. 
\]
They construct a simultaneous resolution of singularities and use the resolution of $X_r$ to describe the tangent space to $X_r$ at a point corresponding to an endomorphism $A$ such that $\rk A^i = r_i$ for all $i$. As an application of the tangent space computation they show that the general fiber of this family can be written as the scheme-theoretic intersection of varieties like $X_r$. 

To construct the resolution, they take $m$ to be the largest number such that $r(m) \ne r(m+1)$
and consider the affine space $\AA^m$ with coordinates $(x_1,\dots, x_m)$. Given $W\subset \AA^m$ a linear subvariety, 
% TODO: clarify that linear subvariety means to them a (translate of subvectorspace)
they introduce $\mathcal X_{r,W}\subset\End(V) \times W \times F_r$ where $F_r$ is the (paritial) flag variety $F_r = \{(V = V_0 \supset V_1 \supset \cdots \supset V_m \supset 0 ) : \dim V_i = r(i)\}$. 
% 
$\mathcal X_{r,W}\subset\End(V) \times W \times F$ is defined to be the subvariety of triples $(A,\vec z,\{V_i\})$ such that $(A-z_i) V_{i-1} \subset V_i$ for $z_i = x_i(\vec z)$ and $i = 1,\dots,m$. 
The (reduced image of) projection of $\mathcal X_{r,W}$ down to $\End(V) \times W$ is denoted $X_{r,W}$ and it is a closed affine subvariety. 
% 
\begin{theorem}
    (\cite[Theorem~2.1 iii)]{eisenbud1989rank})
    $X_{r,W}$ is the restriction of $X_{r,\AA^m}$ to $W$ and as such it is flat over $W$. 
\end{theorem}

This result is applied to study the fibers of the family $X_{r,\AA^m}$ over points $\vec z \in \AA^m$ for $z_i$ not necessarily distinct. The coordinates $z_i$ of $\vec z$ are partitioned by equality with the help of a permutation $p$ of $\{1,\dots,m\}$ such that 
\begin{align*}
    z_{p(1)} &= \cdots = z_{p(m_1)} , \\
    z_{p(m_1 + 1)} &= \cdots = z_{p(m_2)} , \\ 
    \dots \\
    z_{p(m_s + 1)} &= \cdots = z_{p(m_s + 1)}
\end{align*}
and $p$ preserves the order within each interval $m_i + 1,\dots,m_{i+1}$. \acom{Not sure what this means. Order of coordinates?} With this notation in place Eisenbud and Saltman define the numbers

% 
\begin{corollary}
    \label{cor:es}
    The family $\OO^{\lambda',\lambda''}_{0,\AA}$ defined above has zero fibre $\OO^\lambda$. 
\end{corollary}\begin{gather*}
    r(i,j):= \dim V - a_{p(m_i + 1)} - \cdots - a_{p(m_i + j )} \\
    \qquad \qquad \qquad \qquad \qquad \text{ for } i = 1,\dots,s \text{ and } j = 1,\dots , m_{i + 1 } - m_i 
\end{gather*}
where $a_i = r(i-1) - r(i)$.
It is through the $r(i,j)$ that the rank function $r$ determines the Jordan types of the generalized eigenspaces of the vector of (generalized) eigenvalues $\vec z$. 
\begin{proposition}
    (\cite[Corollary~2.2]{eisenbud1989rank})
    \label{prop:es}
    The scheme-theoretic fibre of $X_{r,W}$ over $\vec z\in W$ is 
    \[
        X_{r,\vec z} = \{A \in \End(V) : \rk (A-z_i)^j\le r(i,j) \text{ for all } i , j \}\,. 
    \]
\end{proposition}
% 
The only work we have to do to apply \Cref{prop:es} is to determine the rank function that will allow us to realize $\OO^\lambda$ as a rank variety, and the family $\OO^{\lambda',\lambda''}_{0,\AA}$ as a deformation of it. 
%  
\begin{lemma}
    \label{lem:es}
    Let $\lambda = \lambda' + \lambda''$ be partitions. There exists a permutation of the columns of $\lambda$ such that the first $\lambda'_1$ columns are precisely the columns of $\lambda'$ and the last $\lambda''_1$ columns are precisely the columns of $\lambda''$. 
\end{lemma}
Recall that $\lambda' + \lambda'' = \lambda$ is a partition of $N$. 
% Let $m_i = \lambda_{i,1}$ ($i = 1,2$), $m = m_1 + m_2$, and define
Let $m = \lambda_1' + \lambda_2'$ and define 
$$r(j) = N - \#\text{~boxes in first $j$ columns of }\lambda$$
on $j = 1,\dots,m$. 
\begin{lemma}
   The function $r$
%    defined by $r(j) = N - \#\text{~boxes in first $j$ columns of }\lambda$ 
is a rank function. 
\end{lemma}

The case that we are interested in is the case of two generalized eigenvalues, i.e.\ $\vec z = (z_1,z_2) = (0,s)$. 
\acom{Does order matter?} 
% Let me change notation so that $\lambda_i$ are shapes and 
We begin by considering the open loci where the rank conditions are strict. 

Note that $r(j-1) - r(j) = : a_j$ is the length of the $j$th column of $\lambda$. 
% As in \cite{eisenbud1989rank} we will denote this quantity $a_j$. 
% 
% 
Next, take $p$ to be a permutation of the (lengths of) columns $a_j$ of $\lambda$ such that $a_{p(1)},\dots,a_{p(\lambda_1')}$ are the (lengths of) columns of $\lambda'$ and $a_{p(\lambda_1' + 1)},\dots, a_{p(m)}$ are the (lengths of) columns of $\lambda''$. 
Then the functions 
$$
\begin{aligned}
r(1,j) &= N - a_{p(1)} - \cdots - a_{p(j)} \\
% \text{ and } 
r(2,j) &= N - a_{p(\lambda_1' + 1)} - \cdots - a_{p(\lambda_1' + j)}
\end{aligned}
$$
are such that 
\begin{align*}
    \OO^{\lambda',\lambda''}_{0,s} = X_{r,(0,s)} = \{A:\rk A^j &= r(1,j) \text{ for } i = 1,\dots, \lambda_1' \\ \text{ and } \rk (A-s)^j &= r(2,j) \text{ for } i = \lambda_1' + 1 ,\dots, m \}
\end{align*}
and according to \cite[Theorem 2.1(iii)]{eisenbud1989rank} the family $X_{r,(0,s)}$ is flat over $W = \{x_1 = \cdots = x_{\lambda_1'} = 0 , x_{\lambda_1'} = \cdots = x_m\}$ (a linear subvariety of $\AA^m$) with zero fibre $X_{r,(0,0)} = \OO^\lambda$ as desired. \acom{Do you need to permute the indices defining $W$?}
% $X_{r,\AA^m}$ is flat over $\AA^m$ with zero fibre $X_{r,0} = \OO^\lambda$ as desired. I guess we need to carefully choose the $W \subset \AA^m$ defining our family, which is smaller than the family $X_{r,\AA^m}$. Well, $W$ is just cut out by $0 = x_1 = x_2 = \cdots = x_{m_1}$ and $ x_{m_1 + 1} = \cdots = x_m$, or some permutation thereof to match the permutation $p$ above.
 
% On the one hand, we know that $r(i,j)$ should be equal to $N$ minus the number of boxes in the first $j$ columns of $\lambda_i$. On the other hand, ES define $r(i,j)$ to be $N$ minus the $i$th chunk of $j$ columns determined by the rank function $r(i)$. Also, we would like for $r(i)$ to determine the shape $\lambda = \lambda' + \lambda''$. Take for example $\lambda' = \lambda'' = (2,1)$. Then $\lambda = (4,2)$ and so $r\{0,1,2,3,4\}=\{6,4,2,1,0\}$ and 
% $$\{a_1,a_2,a_3,a_4\} = \{6-4,4-2,2-1,1-0\}=\{2,2,1,1\}\,.$$

% For another example take $\lambda' = (1)$ and $\lambda'' = (1,1)$. Then $\lambda = (2,1)$ and $r\{0,1,2\} = \{3,1,0\}$ so $\{a_1,a_2\} = \{2,1\}$.

% Again too small. The problem is I don't think that it is in general true that some permutation of the list $r(i-1) - r(i)$ will be the list of lengths of columns of $\lambda'$ followed by the list of lengths of columns of $\lambda''$ which is what we are looking for. For one thing there's in general more than one way to write a partition as a sum of two partitions. Ok, concretely, a third example. Take $\lambda' = (a,b)$ and $\lambda'' = (c,d)$ then $\lambda = (a + c, b + d)$ and 
% $$r\{0,1,\dots,a + c\} = \{N, N-2, \dots, N-2(b+d), N-2(b+d) - 1,\dots, 0\}$$
% so 
% $$\{a_1,a_2,\dots\} = \{2,2,\dots,2,1,1,\dots,1\}$$
% with $b+d$ 2s and $a+c - b - d$ 1s. Wait a minute, nevermind, of course this is true. We have two partitions $\lambda'$ and $\lambda''$ and one way to form the partition $\lambda = \lambda' + \lambda''$ is to break $\lambda_i$ down into columns, order the columns by length, and recombine. Cool. I think it's fine. 
% \acom{That's it for the note.}
\end{comment}

% \section{Exposition}
% \label{s:exposition}
% % 

% \acom{This whole section is a big question mark. The beginning of the rising action section is more expository, developmental, and the climax is in turn more of a rising action. The true climax is probably the fusion section, section 7.}

% \jcom{Yes, I think that this section should be deleted and the content moved into the introduction.}

\section{Rising Action}
\label{s:theproblem}

Throughout this section, we continue our notation of the previous sections. So $ \lambda, \lambda', \lambda''$ denote dominant effective coweights for $ \GL_m$, with $ \lambda' + \lambda'' = \lambda$.  Also $ \mu, \mu', \mu''$ are effective coweights with $ \mu = \mu' + \mu''$ and we assume that $ \mu$ is dominant.

\begin{lemma} 
\label{le:Grl1l2}
    Let $ L \in \Grth^+ $.  Let $ s \in \AA, s \ne 0 $.  The following are equivalent:
    \begin{enumerate}[label=(\roman*)]
        \item \label{it:schub-pos} $ L $ is in the image of the map $ \Gr^{\lambda', \lambda''}_{0,s} \rightarrow \Grth^+$. %\acom{Should we describe this map somewhere? Earlier?}
        \item \label{it:schub-jt} The linear operator $ t $ on $ \CC[t]^m/L$ has Jordan type $((0,\lambda'), (s,\lambda''))$.
        \item \label{it:schub-lat} $ L \in G(\CC[t]) t^{\lambda'} (t-s)^{\lambda''}$.
        % \acom{why no $G(\CC[t])$-coset?}
    \end{enumerate}
\end{lemma}
% 
\begin{proof}
First we recall that for $ L \in \Gr^+$, $ L \in \Gr^{\lambda} = G(\cO)t^\lambda $ if and only if $ t |_{\cO^m/L} $ has Jordan type $ \lambda$. 
% \acom{Change $L_0$}

Now assume that $ (L, s) \in \Gr^{\lambda', \lambda''}_{0,s}$.  By definition, $ L(0) \in \Gr^{\lambda'}$ and $L(s) \in \Gr^{\lambda''} $.  This means that $t $ acting on 
% $ \CC\xt^m / L(0)$ 
$\cO^m/L(0)$ has Jordan type $ \lambda'$ and $ t$ acting on 
% $ \CC\xt[t-s]^m / L(s) $ 
$\cO_s^m/L(s)$ has Jordan type $ \lambda''$.  For $ a = 0, s$,  we see that $$\CC[t]^m/L \otimes_{\CC[t]} \cO_a \cong \cO_a^m / L(a). $$
Thus, Lemma \ref{le:linalg} shows that the map
% $ L_0 / L \rightarrow \CC\xt^m / L(0)$ 
$\CC[t]^m/L\to \cO^m/L(0)$ induces an isomorphism between the $0$-generalized eigenspace of $ t$ and $ \cO^m / L(0)$.   The same thing holds for the $s$-generalized eigenspace of $t $ and $ \cO_s^m/L(s)$. This shows that \cref{it:schub-pos} implies \cref{it:schub-jt} and the logic can be reversed to see that \cref{it:schub-jt} implies \cref{it:schub-pos}. 
% \acom{is this map $v + L \mapsto v + L(0)$?} \jcom{yes} \marginpar[]{*}
% todo 

On the other hand, if $ L = g t^{\lambda'} (t-s)^{\lambda''} \CC[t]^m$ for some $ g \in G(\CC[t])$, then $ L(0) = g t^{\lambda'}\cO^m $ since 
% $ (t-s)^{\lambda''} \in G(\CC\xt)$. 
$ (t-s)^{\lambda''} \in G(\cO)$. In this way, we see that \cref{it:schub-lat} implies \cref{it:schub-jt} and the logic can be reversed to get equivalence.
\end{proof}

\begin{lemma} 
\label{le:linalg} % aka solution 
Let $ V $ be a $ \CC[t]$-module which is finite-dimensional as a complex vector space.  For any  $ a \in \AA$, the map
$$ 
    V  \rightarrow V \otimes_{\CC[t]} \cO_a
$$
restricts to an isomorphism between the generalized $ a $-eigenspace of $ t $ and $ V \otimes_{\CC[t]} \cO_a$
\end{lemma}
% 
\begin{proof}
    For any $ b \in \AA$, let $ E_b $ denote the generalized $b$-eigenspace of $t$.  Then $ V = \oplus_{b \in \CC} E_b$.  Since $ t - b$ is invertible in $ \cO_a$ and $ t -b $ acts nilpotently on $ E_b$, we see that $ E_b \otimes_{\CC[t]} \cO_a = 0 $.
    
    So it suffices to show that $ E_a \rightarrow E_a \otimes_{\CC[t]} \cO_a$ is an isomorphism.  By the classification of modules over $ \CC[t]$, it suffices to check this when  $ E_a = \CC[t]/(t-a)^k$, where it is clearly true.
\end{proof}
% 
\begin{lemma} 
\label{le:Wmu}
Let $ L \in \Grth^+$.  The following are equivalent:
\begin{enumerate}[label=(\roman*)]
    \item \label{it:slice} $ L \in \cW_\mu$.
    \item \label{it:basis} $ L = \Sp_{\CC[t]}(v_1, \dots, v_m)$ for some $ v_i $ of the form $ v_i = t^{\mu_i} e_i + \sum_{j=1}^m p_{ij} e_j $ where $ p_{ij} \in \CC[t] $ has degree less than $ \min(\mu_i, \mu_j)$.
    \item \label{it:t-act} For all $ i $, 
    $$ t^{\mu_i} e_i \in \Sp_\CC(\{t^k e_j : 0 \le k < \min(\mu_i, \mu_j), 1 \le j \le m \}) + L. $$
\end{enumerate}
Moreover, for such $L $, $ \beta_\mu := \{ [t^k e_i] : 0 \le k < \mu_i, 1 \le i \le m\}$ forms a basis for $ \CC[t]^m/L$. 
\end{lemma}
% 
% \jcom{I realized the meaning of the ``extra'' condition from the paper with Sabin and I added it into point 3.}
% \acom{Technically though the extra condition in that paper is weaker? $W_{\mu_i}$ being the span of $e_j,te_j,\dots,t^{\mu_i-1}e_j$ or the complement of $t^{\mu_i}\cO^m$ in $\cO^m$.}
% 
\begin{proof}
    Let $ L \in \cW_\mu$.  Then $ L = \Sp_{\CC[t]}(v_1, \dots, v_m) $ for some $ v_i $ with $ v_i = t^{\mu_i} e_i + \sum_{j=1} q_{ij}t^{\mu_i} e_j $ and $ q_{ij} \in t^{-1} \Oinf$.  Since $ L \in \Grth^+ $, we see that $ v_i \in \CC[t]^m$ which means that $ p_{ij} := q_{ij}t^{\mu_i} $ lies in $ \CC[t]$.  By construction, the polynomial $ p_{ij}$ has degree less than $ \mu_i$.
    
    Fix $ i$ and suppose that for some $ j$, $ \mu_j < \mu_i$.  In this case, we can alter our basis to $ v'_i = v_i - r v_j$ for some polynomial $r \in \CC[t]$.  
    \acom{More like a quotient than a remainder, better $q$ than $r$?}
    This gives us new polynomials $ p'_{ij} = p_{ij} - r (t^{\mu_j} + p_{jj}) $.  In this way, we can ensure that $ p_{ij} $ has degree less than $ \min(\mu_i, \mu_j)$.  
    Thus \cref{it:slice} implies \cref{it:basis}.
    
    Suppose that $ L = \Sp_{\CC[t]}(v_1, \dots, v_m)$ as in \cref{it:basis}.  Then
    $$t^{\mu_i} e_i - v_i \in \Sp_\CC(\{t^k e_j :  k < \min(\mu_i, \mu_j), 1 \le j \le m \})  \,. $$
    Hence \cref{it:basis} implies \cref{it:t-act}.  

    Finally, given \cref{it:t-act}, then we can see $ v_i := t^{\mu_i} e_i - \sum_{j=1}^m p_{ij} e_j \in L $ for some $ p_{ij} \in \CC[t]$ of degree less than $ \min(\mu_i,\mu_j) $.  It is easy to see that $ L = \Sp_\cO(v_1, \dots, v_m) $ and so $ L \in \cW_\mu$.  
    % 
    To show that $ \beta_\mu$ forms a basis for $ \CC[t]^m/L$, it suffices to show that for each $ i$, 
    $$ t^{\mu_i} e_i  \in \Sp_\CC(  t^k e_i : 0 \le k < \mu_i, 1 \le i \le m) + L\,.$$
    % 
    % \rcom{Preimage of $\beta_\mu$}  
    % 
    % \acom{I guess that this is the ``$\mu$-numeration'' of the standard basis of $\CC^N$ that I commented out.}
    % 
    This follows immediately from \cref{it:t-act}.
    % 
\end{proof}
% \acom{note-to-self, skipped this; return to it.}
% 
%\acom{Don't have $P$ notation, replacing (in lemma below) with $\ZZ^m$ for now..}
\begin{lemma}
\label{le:inftyfusiskl} % as in lands in KL slice 
    Under the map $ \Grbd \rightarrow \Grth$ the image of $ S^{\mu', \mu''}_{0,\AA}$ lands in $ \cW_\mu$.
\end{lemma}
%\acom{Probably it is worth writing down the map $ \Grbd \rightarrow \Grth$ just before this first occurence? \textit{is it $(L,s)\mapsto L$?} Update: added this above.}
% Resolved? the map $ \Grbd \rightarrow \Grth$ caused some confusion in my talk as on the left we have a family and on the right we have the thick affine Grassmannian --- Jiuzu kept thinking aloud that we can make $\Grth$ a family too.. Anyway I think that you address this below Joel. 

\begin{proof}
    Let $ L $ 
    % lie in this image.  
    be a lattice in the image of $S^{\mu',\mu''}_{0,\AA}$. Then $ L = g t^{\mu'} (t-s)^{\mu''}\CC[t]^m$ for some $ g \in N_-(\CC[t, t^{-1}, (t-s)^{-1}]) $.  Let $ h =(t-s)^{\mu''} t^{-\mu''}  $.  Note that $ h \in T_1(\Oinf)$. 
    Moreover, $L = h (h^{-1} g h) t^{\mu}\CC[t]^m$. 
    % $$ L = h (h^{-1} g h) t^{\mu}\CC[t]^m\,. $$
    Since 
    % $ h^{-1} g h \in N(\CC\xT[t^{-1}])$ 
    $h^{-1} g h \in N_-(\cK_\infty)$ we can factor $ h^{-1} g h$ as $n_1 n_2$ for some $ n_1 \in {(N_-)}_1(\Oinf), n_2 \in {N_-}(\CC[t]) $. 
    
    As $ \mu $ is dominant, we see that $ t^{-\mu} n_2 t^\mu \in N_-(\CC[t]) $, and so 
     % \CC\xt[t^{-1}]s
    % 
    % \rcom{I think we want $\mu$ antidominant here or should the $N$'s be $N_-$'s?} % 
    % \acom{Si.}
    % 
    $ L = h n_1 t^\mu \CC[t]^m$.  Since $ hn_1 \in G_1(\Oinf)$, the result follows. % \CC\xt[t^{-1}]
\end{proof}
% 
\section{Climax}
\label{s:climax}
Throughout this section, we continue our notation of the previous sections. So $ \lambda, \lambda', \lambda''$ denote dominant effective coweights for $ \GL_m$, with $ \lambda' + \lambda'' = \lambda$.  Also $ \mu, \mu', \mu''$ are effective coweights with $ \mu = \mu' + \mu''$ and we assume that $ \mu$ is dominant.

Given $ A \in \TT_\mu$, recall the definition of $ g(A)$ given in \Cref{eq:mvyofa}.  Note that $g(A)t^{-\mu} \in G_1(\Oinf)$.
% section ??.  
Since $ g(A) \in M_m(\CC[t]) \cap G_1(\Oinf)t^\mu$, we will regard $ g(A)$ as giving an element of $ \Grth^+ \cap \cW_\mu$.  (Alternatively, we can see that $ g(A) \CC[t]^m$ satisfies the condition of \cref{it:basis} from \Cref{le:Wmu}.)

The following result is called the Mirkovic--Vybornov isomorphism \cite{mirkovic2007quiver}.  In the following form, it can be found in \cite[Theorem 3.2]{cautis2018categorical}, except that we have tweaked both maps with a matrix transpose $[?]^\tr$.

% \jcom{I'm not sure which of the Mirkovic--Vybornov papers to cite.} \acom{can say 07, rewritten in 19?}
% 
\begin{theorem} 
\label{th:TmuWmu}
The map $ \TT_\mu \rightarrow \Grth^+ \cap \cW_\mu $ given by $ A \mapsto g(A)\CC[t]^m $ is an isomorphism with inverse given by
$$ 
L \mapsto [t|_{\CC[t]^m/L} ]^{\tr}_{\beta_\mu} \,. 
$$
\end{theorem}
% 
%\acom{Should we say what $^{tr}$ means?}

For the next result, we will consider the ``intersection'' of $ \overline{\Gr}^{\lambda', \lambda''}_{0,\AA} $ with $\cW_\mu$.  
As $  \overline{\Gr}^{\lambda', \lambda''}_{0,\AA} $ is not a subscheme of $ \Grth$, by this intersection, we really mean the preimage of $ \cW_\mu$ under the composition
$$ 
    \overline{\Gr}^{\lambda', \lambda''}_{0,\AA}  \hookrightarrow \Grbd \rightarrow \Grth\,.
$$
This is not a very serious abuse of notation, since the map $ \Grbd \rightarrow \Grth $ is almost injective. 
% Joel: The only non-injectivity comes from the fact that we forget the data
% of s.  So the map is non-injective over the locus where s is not
% actually an eigenvalue (in lattice terms where L(s) is the standard
% lattice).
In a similar way, we will write $ \overline{\OO}^{\lambda', \lambda''}_{0,\AA} \cap \TT_\mu$ using the ``almost injective'' \acom{emphasis is on the almost injectivity/glass half full no?} \jcom{ok, I changed it} map $ \overline{\OO}^{\lambda', \lambda''}_{0,\AA} \rightarrow M_N(\CC)$. 
% (for example the fibre of this map over $ 0 $ is $ \CC $). 
% \acom{Grammar of `write using the map' is iffy. Also, is the fibre over 0 just a copy of the zero matrix in every $s$-fibre?}

The following refinement of the \mvy isomorphism is a special case of \cite[Theorem 5.3]{mirkovic2007quiver}. \acom{Wait isn't 5.3 a special case of this?}  \jcom{No, they deal with the more general setting of more points.}
\begin{theorem} 
\label{th:OGrl}
There is an isomorphism
$$
    \overline{\OO}^{\lambda', \lambda''}_{0,\AA} \cap \TT_\mu \cong \overline\Gr^{\lambda', \lambda''}_{0,\AA} \cap \cW_\mu 
$$
given by $ (A,s) \mapsto (g(A)\CC[t]^m, s)$.
\end{theorem}
% \acom{Joel, you stopped writing $X_{0,\AA}$ in favour of $X_\AA$ --- should we do this everywhere?}
% \jcom{Oops, no I think that we should stick with $ X_{0, \AA}$.}
% TODO: comb the doc at the end for this notation 
\begin{proof}
Since we already have the isomorphism from \Cref{th:TmuWmu}, it suffices to show that for any $ A \in \TT_\mu$, 
$$ 
    (A,s) \in \overline{\OO}^{\lambda', \lambda''}_{0,\AA} \cap \TT_\mu \text{ if and only if } (g(A)\CC[t]^m, s) \in \overline\Gr^{\lambda', \lambda''}_{0,\AA} \cap \cW_\mu \,. 
$$
This follows immediately from \Cref{le:Grl1l2}.
\end{proof}
%
% \acom{We need to assume that $\mu' +\mu''$ is dominant in the theorem below. The assumption for \Cref{th:TmuWmu} is also missing.} 
% 
% \jcom{I added a reminder at the beginning of the section.}
% 
\begin{theorem}
\label{th:OTGrW}
The isomorphism from \Cref{th:OGrl} 
% \acom{should ``Theorem'' etc.\ be capitalized when it appears in the middle of a sentence?} Yup.
restricts to an isomorphism
$$ 
    \overline{\OO}^{\lambda', \lambda''}_{0,\AA} \cap \UU^{\mu', \mu''}_{0,\AA} \cong \overline{\Gr}^{\lambda', \lambda''}_{0,\AA} \cap S^{\mu', \mu''}_{0,\AA}\,.
$$
\end{theorem}
% 
%\jcom{I was thinking about the proof of this result.  It is enough to prove that for $ A \in \OO^{\lambda', \lambda''}_s \cap \TT_\mu $, $g(A) \in S^{\mu', \mu''}_s $ if and only if $ A \in T^+$.  It is easy to show that if $ A \in \UU$, then $ g(A) \in S^{\mu', \mu''}_s $.  But the converse is not so obvious.  (I think Anne's paper/thesis might be incomplete on this point.)  I thought of two approaches: first to write down the lattice interpretation of $S^{\mu', \mu''}$ (similar to what is in my thesis in the Anderson-Kogan comparison section) or think about both $S^{\mu', \mu''}$ and $\UU$ as attracting sets for a $\AA^\times$ action.  Which do you prefer?}
% 
%\acom{Assuming Theorem 2 we think this follows by application of Roger's lemma. Also, I think my thesis is complete on this point.}
% 
%\jcom{I thought about this and I agree with you now.  I will write this up soon.} 
% 
%\acom{But I am also curious about the attracting set approach.}
% 
\begin{proof}
We could prove this by observing the both sides are the attracting locus of an appropriate $ \Cx$ action. However, we will give the following more algebraic proof.

Let $ A \in \TT_\mu$ and $ s \in \CC $. We must show that  $ (A,s) \in \UU^{\mu', \mu''}_{0,\AA} $ if and only if $ (g(A)\CC[t]^m,s) \in S^{\mu', \mu''}_{0,\AA} $. 
%\acom{not $g(A)\CC[t]^m$}

On the one hand, if $ (A,s) \in \UU^{\mu', \mu''}_{0,\AA} $, then $ g(A)$ is lower-triangular with diagonal $ t^{\mu'} (t-s)^{\mu''}$, and so $ g(A) \in N_-[t, t^{-1}, (t-s)^{-1}] t^{\mu'} (t-s)^{\mu''}$. 
% \acom{not $g(A)\CC[t]^m$}
% \jcom{This one isn't a point in $ \Gr$, the others I changed.}

On the other hand, if $ (g(A)\CC[t]^m, s) \in S^{\mu', \mu''}_{0,\AA}$, then we can write 
$$
    g t^\mu r= n t^{\mu'} (t-s)^{\mu''}
$$
for some $ r \in G(\CC[t]), n \in N_-(\CC[t, t^{-1}, (t-s)^{-1}]) $ and $ g = g(A)t^{-\mu}$.  Let $ h = (t-s)^{\mu''} t^{-\mu''}$ which lies in $ T_1(\Oinf) $. % was CC\xt[]
Note that $ h^{-1}n h \in N_-(\Kinf)$, 
% ((t^{-1}))
so we can factor it as $ h^{-1} n h  = n_1 n_2 $, where $ n_1 \in N_{-,1}(\Oinf), n_2 \in N_-(\CC[t])$.  So then after doing a bit of algebra, we reach
$$
    t^\mu r (t^{-\mu} n_2^{-1} t^\mu) t^{-\mu} = g^{-1} h n_1.
$$
Since $ g, h, n_1 \in G_1(\Oinf)$, the right hand side $ g^{-1} h n_1 $ lies in $ G_1(\Oinf) $.  Since $ \mu $ is dominant, $ t^{-\mu} n_2 t^\mu \in N_-(\CC[t])$, and so the left hand side lies in $t^\mu G(\CC[t]) t^{-\mu}$.

Moreover, since $ \mu $ is dominant, we know that 
$$
    t^\mu G(\CC[t]) t^{-\mu} \cap G_1(\Oinf) = N_{-,1}(\Oinf)\,.
$$
% $$t^\mu G(\cO) t^{-\mu} \cap G_1(\CC\xt[t^{-1}]) = N_1(\CC\xt[t^{-1}]\,.$$
Thus, we deduce that $ g^{-1} h n_1 \in N_{-,1}(\Oinf)$ 
% $ g^{-1} h n_1 \in N_1(\CC\xt[t^{-1}])$ 
and hence $ g(A) \in t^{\mu'} (t-s)^{\mu''}N_{-,1}(\Oinf) $.  
% Given that we know that 
Since $ A \in \TT_\mu $, this implies that $ (A,s) \in \UU^{\mu', \mu''}_{0,\AA}$ as desired.
\end{proof}
% 
% \jcom{In this proof, I made some statements about $\mu$ dominant, which are incorrect (as Anne knows). To make them correct we should either switch to having $ \mu$ being antidominant or switch $ N$ to $ N_-$.  In this proof $ g(A)$ generally denotes a group element, rather than an affine Grassmannian element which conflicts a bit with earlier usage.}
% 
%\acom{What was the answer to Roger's question why is $g^{-1}hn_1 \in G_1 (\Oinf)$}
% 
%\rcom{So if we look at $g = g(A)t^{-\mu}$, since $A \in \TT_\mu$, the entries of $g(A)_{ij}$ are polynomials of degree $\min(\mu_i-1,\mu_j-1)$ when $i \neq j$, otherwise of degree $\mu_i$. When we multiply by $t^{-\mu}$, we scale the $i$th column by $t^{-\mu_i}$. So the diagonal entries are $1 + p$ where $p \in t^{-1}\CC[t^{-1}]$ while the off-diagonal entries in column $i$ have highest (in $t$) degree $\min(\mu_i-1, \mu_j-1) - \mu_i < 0$. Hence $g \in G_1(\cO_\infty)$.}
% 

Restricting to the zero fibre and applying $\theta_0$ together with \Cref{prop:adjoint} we recover a result of the second author. 
%itself a corollary of \cite[Theorem~4.4.1(c)]{mirkovic2019comparison}, the ordinary affine Grassmannian version of \Cref{th:OGrl}. 
% 
% \acom{The ordinary Gr should be called static. Really onomotopoeic. In opposition with moving. }
% 
\begin{corollary}
    \label{cor:mvy} (\cite[Corollary~5.2.2]{dthesis})
The map $ A \mapsto g(A)\cO^m$ gives an isomorphism 
$$\overline{\OO}^\lambda \cap \TT_\mu\cap\n \cong\overline\Gr^\lambda\cap S^\mu_-\,.$$
\end{corollary}
% 
%The closures of the irreducible components of the righthand side are \new{MV cycles of type $\lambda$ and weight $\mu$}. By \cite{baumann2019mirkovic} the set of MV cycles of all possible types and weights can be stitched together to form a \new{perfect basis} of $\CC[N]$. 

%\acom{We are ready for applications! One of the motivations for this paper is... Abstractly multiplication is $\ast_s$... To compute we now carry this across \Cref{th:OTGrW}.}

\section{\sout{Falling Action}} % Resolution
\subsection{MV cycles}
Let $Q_+$ denote the $\ZZ_{\ge 0}$-span of the positive coroots. 
Recall the \new{dominance order} on $\ZZ^m$ defined by declaring that $\mu\le\lambda$ if $\lambda - \mu\in Q_+$ for any $\lambda,\mu$. 

Continuing now with the notation of the previous sections we add the assumption that $\mu\le\lambda$ and forget the assumption that $\mu$ is dominant. 
% 
% We need to decide on the order in section 7. How about:
% 
% 1. MV cycles and tableaux (7.1)
% 2. GOVs and relation to MV cycles, including fusion (7.2)
% 3. Stable MV cycles and multiplication  in C[N]
% 
\begin{definition}
An irreducible component of $\overline{\Gr}^\lambda \cap S^\mu$ is called an \new{Mirkovic--Vilonen cycle} in $\overline{\Gr}^\lambda$ of coweight $\mu$. 
\end{definition}


% \jcom{In this section, I think that $ \mu$ is not necessarily dominant.  So I think that we should we recall our previous notation, but say that $ \mu $ might not be dominant here.}
% \acom{Ok.}

By \cite[Theorem~3.2(b)]{mirkovic2007geometric}, each MV cycle in $\overline\Gr^\lambda$ of coweight $\mu$ has dimension $ \rho(\lambda - \mu)$ where $\rho$ is the half sum of positive roots. Normalizing $ \rho = (m, m-1, \dots, 1)$ and identifying $P \cong P^\vee$ the pairing $P\times P^\vee\to\ZZ $ is given by the ordinary dot product. 
We denote by $\cZ(\lambda)$ the collection of all MV cycles in $\overline{\Gr}^\lambda$ of coweight $\mu\le\lambda$. 

% \jcom{We could put some stuff here about stable MV cycles and multiplication, but maybe we can have this in a later section.}

% \acom{With this definition here what do we do about the sentence after \Cref{cor:mvy} above?}
% \jcom{I just cut it.  I think that it was a bit out of place there.}

% \acom{Recall (from optional \Cref{s:exposition}) the question motivating this work --- Roger's thesis, cluster monomials and the MV basis. Clarify that whereas we have so far only seen spaces related to ``ordinary MV cycles'' it is the ``stable MV cycles'' that are used to define the MV basis of $\CC[N]$ that the motivating question is concerned with. This discrepancy is the reason we might want to discuss maps $B(\infty)\to B(\lambda)$.}
% 

In \cite{kamnitzer2010mirkovic}, the third author gave a combinatorial description of MV cycles for any reductive group, using Mirkovic--Vilonen polytopes, or equivalently Lusztig data, which are sequences in $\NN^{\Delta_+}$ that depend on a choice of reduced expression. For $\GL_m$ and the standard reduced word, this description can be reworded in terms of Young tableaux. 
% \jcom{Maybe add something here about Lusztig data and the standard reduced word, $\vi = (1,2,\dots,m-1,\dots,1,2,1)$.}


Denote by $[a,b]$ the interval $\{a,a+1,\dots,b-1,b\}\subset\NN$. 
% 
We begin with the following definitions.
\begin{definition}
Let $ L \subset \cO^m$ be a point in $ \Gr_+$.  We define the relative dimension of $L $ by
$$
\rdim L := \dim_\CC \cO^m/L\,. 
$$
% 
If $ \gamma \subset [1,m]$, we define two lattices $ L^\gamma, L_\gamma $ in $ \cO^\gamma := \Sp_{\cO}(e_i : i \in \gamma) $ by
\begin{gather*}
%    \OO^\gamma := \Sp_{\OO}(e_i : i \in \gamma) \\
L^\gamma:= L \cap \cO^\gamma  \qquad L_\gamma := L / L^{\gamma^c} \subset \cO^m / \cO^{\gamma^c} = \cO^\gamma
\end{gather*}
where $ \gamma^c := [1,m] \setminus \gamma$.
% 
% \acom{I suggest replacing $\mathbb O$ by $R$, and $L/L^{\gamma^c}$ by $(L + R^{\gamma^c})/R^{\gamma^c}$ because that's what we're doing. In a lower triangular $g(A)$ columns ${i+1..m}$ cannot be used to eliminate entries in rows ${i+1..m}$ in the first $i$ columns over $\CC[t]$ or $\CC\xt$.}
% \jcom{If you think that it sounds better with $ \OO $ replaced by $ R$, then I won't object to the change. Note that the first sentence won't quite make sense ``let $ L \subset \OO^m$ be a point in $ \Gr_+$'', we would have to write ``let $ L \subset R^m$ be a lattice''.}
% \jcom{$ L /L^{\gamma^c} $ is the image of $ L $ in $ \OO^m / \OO^{\gamma^c}$ since the kernel of the map $ L \rightarrow \OO^m / \OO^{\gamma^c}$ is precisely $L^{\gamma^c} $, so I don't think that there is any problem here.  Again, if you think that it is better, I won't object to your suggested change.} 
% \jcom{Your question made me wonder about the following: how do we know that $ L_\gamma$ is a lattice?  (or $ L^\gamma$ for that matter)}
\end{definition}
We will also need the analogous definitions when $ \cO$ is replaced by $ \CC[t]$ and $L \in \Grth_+$. 
% 
We record the following easy observations.
\begin{lemma} \label{le:rdimTrans} Let $ L \in \Gr_+$ or $\Grth_+$.
\begin{enumerate}
    \item For any $ 
    \gamma \subset [m] $, we have 
    $$ \rdim L_\gamma + \rdim L^{\gamma^c} = \rdim L \,.$$
    \item For any $ \gamma_1 \subset \gamma_2 \subset [m]$, we have $$ (L_{\gamma_2})_{\gamma_1} = L_{\gamma_1}
$$
\end{enumerate}
\end{lemma}
% \acom{Doesn't the identification $G(K)/G(O) \to G(O)\ G(K)$ coming from $g\mapsto g^{-1}$ give us a minus sign somewhere, since we are sending $S^\mu_w$ to $S^{-\mu}_w$, so $D_{\omega_i}(L) = -\rdim L_{[1,i]}$. Ignoring the minus sign for now, for $j\le i\le m$, and $L_{[1,i]}$ in $S^{\mu(i)}_- \cap S^{\lambda(i)}_+$ we’d like $D_{\omega_j}(L_{[1,i]}) = \rdim (L_{[1,i]})_{[1,j]} = \lambda(i)_j + \cdots + \lambda(i)_i$ whereas the claim $(L_{[1,i]})_{[1,j]} = L_{[1,j]}$ hides that this lattice also depends on $i$? I'm sure I'm missing something here so I will look at it again later. $n_{(a,b)} (L_{[1,i]}) = -D_{[a+1,b]} - D_{[a , b-1]} + D_{[a + 1, b-1]} + D_{[a,b]} = - \rdim L_{[a+1,b]} - \rdim L_{[a,b-1]} + \rdim L_{[a+1,b-1]} + \rdim L_{[a,b]}$}
% \jcom{I warned you when we talked on Tuesday that there might be some problems, but I think that we shouldn't dig any deeper here.} 
% \acom{Well, it's not that deep.. it's just that $(L_{\gamma_1})_{\gamma_2}$ involves taking $\gamma_2^c\subset \gamma_1$ and landing in $\cO^{\gamma_1\cap\gamma_2}$ whereas $L_{\gamma_2}$ involves taking $\gamma_2^c\subset[m]$ and landing in $\cO^{\gamma_2}$ ...so I think the change makes it true.}
% \jcom{But I assumed that $ \gamma_1 \subset \gamma_2$, so I don' think that taking intersection is necessary.}
% \acom{Even so? What was written before was $(L_{\gamma_1})_{\gamma_2} = L_{\gamma_2} $ and if $\gamma_1\subset\gamma_2$ then the intersection is $\gamma_1$. Anyway I don't think we ever use Lem. 6(2), so we can do without it?}
% \jcom{Oh, I guess there was a typo.  I fixed it now.  It is used in the proof of Prop 4, I will add a reference.}

For any $ L \in \Gr_+ $ and $\gamma \subset [m]$, we define $ D_\gamma(L) := \rdim L^\gamma = \rdim L - \rdim L_{\gamma^c}$. (By \cite[Proposition 9.3]{kamnitzer2010mirkovic}, this coincides with the general definition of $ D_\gamma$ given in that paper; in \textit{loc. cit.} these functions are used to compute the hyperplanes of the associated MV polytopes.) 
% \acom{We should introduce $D_\gamma$ briefly.}
% \jcom{I think that this is sufficient, since it doesn't really play any role in our paper.}
% \acom{Ok; I was thinking just another half-sentence, like these are some valuation functions and/or they are used to characterise combinatorially the MV cycles.}

In this section only, \acom{possibly also the next} we will write $ S^\mu_- = N_-(\cK) t^\mu$ (with a subscript), because we will also need the opposite semi-infinite cell $S^\mu_+ := N(\cK)t^\mu$. %\acom{HB, ``..we will write.., because we will need the opposite cell..''}
% \acom{Maybe we shouldn't decorate $S^\mu$ with a subscript $-$ after all since we certainly won't want to add to $S^{\mu',\mu''}_{0,\AA}$ in underscores.}
% \jcom{I agree.  Is the above solution ok?}
% \acom{Sure.}
% 
% \jcom{Actually we will need this notation later when we talk about stable MV cycles.  Maybe we should change $ S^\mu $ to $S^\mu_-$.}
% \acom{For it.}
% \acom{As was checked in \cite{dranowski2020generalized} $S^\mu_w = \{D_{w\omega_i} = \langle \mu , w w_0 \omega_i\rangle \}$ so $S^\mu_+ = \{D_{\omega_i}(L) = \rdim L^{w_0\omega_i} \}$} 
% \jcom{But that was for a different identification of the left and right quotients.  I'm certain that the statements in the Lemma below are correct.}

\begin{lemma} \label{le:Srdim}
    Let $ L \in \Gr_+$.  The following are equivalent:
    \begin{enumerate}
        \item $ L \in S_+^\mu$ \label{Srdim1}
        \item $ \rdim L^{[1,i]} = \mu_1 + \dots + \mu_i$ for all $ i = 1, \dots, m $. \label{Srdim2} % \acom{$\rdim L^{[m-i+1,m]} = \mu_{m-i+1} + \cdots + \mu_m$}
        \item $ \rdim L_{[i+1,m]} = \mu_{i+1} + \dots + \mu_m$ for $ i  = 1, \dots, m$. \label{Srdim3} % \acom{$\rdim L_{[m-i]}=\mu_1 + \cdots + \mu_{m-i}$}
    \end{enumerate}
    Similarly, the following are equivalent:
        \begin{enumerate}[label=\arabic*'.]
        \item $ L \in S_-^\mu$
        \item $ \rdim L^{[i+1,m]} = \mu_{i+1} + \dots + \mu_m$ for all $ i = 1, \dots, m $.
        \item $ \rdim L_{[1,i]} = \mu_{1} + \dots + \mu_i$ for $ i  = 1, \dots, m$.
    \end{enumerate}
\end{lemma}

\begin{proof}
We prove the first statement as the second is similar.  Let $ L = n t^\mu \CC[t]^m$ for $ n \in N_+(\cK)$ and let $ v_1, \dots, v_m $ denote the columns of the matrix $ nt^\mu$.  Then $ L = \Sp_{\cO}(v_1, \dots, v_m)$.  Fix some $ i \le m$.  Then $ L^{[1,i]} = \Sp_{\cO}(w_1, \dots, w_i) $ where $ w_j $ denotes the first $ i $ entries of $ v_j $ (by upper-triangularity, the rest of the entries are 0, in any case).  

Assume that $L \subset \cO^m$.  Then $ L^{[1,i]} \subset \cO^i$ and $ \rdim L^{[1,i]} $ is the valuation of the determinant of the matrix with columns $ w_1, \dots, w_i$.  Since this matrix is upper-triangular with diagonal entries $ t^{\mu_1}, \dots, t^{\mu_i}$, this determinant is $ t^{\mu_1 + \dots + \mu_i} $ and hence $ \rdim L^{[1,i]} = \mu_1 + \dots + \mu_i$.   

Thus \ref{Srdim1} implies \ref{Srdim2}.  The converse follows from the fact that every $ L$ lies in some $ S_+^\nu$ and by the above reasoning, $ \nu$ is determined by the values of $ \dim L^{[1,i]}$.

The equivalence of \ref{Srdim2} and \ref{Srdim3} follows from Lemma \ref{le:rdimTrans}.
\end{proof}
% \jcom{I added a proof.  We can get delete and just put a reference to mvcycle if you prefer.}

% \acom{No no this is good! Thanks for other additions}

We now introduce some notation related to Young tableaux. Denote by $YT(\lambda)$ the set of (possibly semi-standard) Young tableaux of shape $\lambda$ and by $YT(\lambda)_\mu$ the subset of $YT(\lambda)$ of tableaux having weight $\mu$. 
%Here, the weight of a tableau is a sequence $(\mu_1,\mu_2,\dots)$ recording the number of boxes of weight $i = 1,2,\dots$ that the tableau contains, and the weight of a box is just the number that the box contains.
% For the sake of making a definition, we momentarily put some letters of our alphabet in unexpected roles, and ask you to suspend your disbelief. Given an arbitrary tableau $t$ having weight $w$ and shape $s$, we denote by $s(i)$ (resp.\ $w(i)$) the shape (resp.\ the weight) of $t(i)$, the tableau got from $t$ by discarding all boxes of weight exceeding $i$. 

Given $\tau\in YT(\lambda)_\mu$ and $ i \in \{1, \dots m\} $, denote by $\lambda(i)$ (resp.\ $\mu(i)$) the shape (resp.\ the weight) of $\tau(i)$, the tableau got from $\tau$ by discarding all boxes of weight exceeding $i$. (Note that $ \mu(i)$ only depends on $ \mu$, while $ \lambda(i)$ depends on the tableau $ \tau$.)  We will regard $ \lambda(i)$ (resp.\ $\mu(i)$) as an effective dominant coweight (resp.\ effective coweight) for $\GL_i$. 
% 

The Lusztig datum $n_\bullet(\tau)$ of the tableau $\tau$ is a list of $ m(m-1)/2$ non-negative integers defined from its \new{Gelfand--Tsetlin pattern} $\gt(\tau) = (\lambda(i)_j)_{1\le j\le i\le m}$ by the formula 
% \acom{For Joel: weight or filling? See line below.}
$$
\begin{aligned}
% n_\bullet(\tau)_{i,j} &= \lambda(i+1)_j - \lambda(i)_j = \text{ \# of boxes on the $j$th row of $\tau $ filled with $ i+1$}  \\
% (i,j) &=  (1,1),(2,1),\dots,(m-1,1),%\\
% (2,2),\dots,(m-1,2),%\\
% \dots,%\\
% (m-1,m-1)
n_\bullet(\tau)_{(a,b)} &= \lambda(b)_a - \lambda(b-1)_a = \text{ \# of boxes on the $a$th row of $\tau $ filled with/of weight $b$}  \\
% (i,j) &=  (1,1),(2,1),\dots,(m-1,1),%\\
% (2,2),\dots,(m-1,2),%\\
% \dots,%\\
% (m-1,m-1)
(a,b) &=  (1,2),(1,3),\dots,(1,m),%\\
(2,3),\dots,(2,m),%\\
\dots,%\\
(m-1,m)\,. 
\end{aligned}
% (i,j) = \begin{smallmatrix}
% \\
% (1,1) \\
% (2,1) & (2,2) \\
% \vdots & & \ddots \\
% (m-1,1) & (m-1,2) & \dots & (m-1,m-1) 
% \end{smallmatrix}
$$
Note that $ \lambda - \mu = \displaystyle{\sum_{1 \le a < b \le m}n_\bullet(\tau)_{(a,b)} \beta_{a,b}} $ where $ \beta_{a,b} $ denotes the positive root of $ G$ with a $ 1 $ in the $a $ slot and a $-1$ in the $ b $ slot.
% for 
% $(i,j) = (1,1),(2,1),\dots,(m-1,1),(2,2),\dots,(m-1,2),\dots,(m-1,m-1)$. 
% 
The pattern $\gt(\tau)$ is recorded as a lower-triangular matrix (the array of shapes of subtableaux $\tau(i)$) and the datum $n_\bullet(\tau)$ is recorded as a sequence. Below is an example with $\lambda = (4,2)$ and $\mu = (3,2,1)$. \acom{GT patterns were introduced in \cite{berenstein1988tensor} to study branching? In particular \S 4 of that paper introduces the map from tableaux to patterns. Note that the map is not 1-to-1.} 

% \jcom{Something is wrong with the indexing of the Lusztig data, there should only be $ m(m-1)/2 $ entries.}

% \acom{Yes $i = m$ doesn't make sense. Should be $i = 1,\dots,m-1$ and $j = 1\dots i$ or $(1,1),(2,1),\dots,(m-1,1),(2,2),\dots,(m-1,2,\dots,(m-1,m-1)$ which is $(m-1) + (m-1-1) + \cdots + 1$ things. Right?}

% \begin{example}
    \[
        \tau = \young(1112,23) \qquad \gt(\tau) = \begin{matrix}
            3 \\
            4 & 1 \\ 
            4 & 2 & 0 
        \end{matrix} \qquad n_\bullet(\tau) = (1,0,1) %\,. 
    \]
% \end{example}
% For example, if 
% \[
%     \tau = \young(1112,23) 
% \]
% then
% \begin{gather*}
% %    \text{if } \tau = \young(1112,23) \text{ then } 
% \gt(\tau) = \begin{matrix}
%        3 \\
%        4 & 1 \\ 
%        4 & 2 & 0 
%    \end{matrix} \text{ and }
%    n_\bullet(\tau) = (1,0,1)\,. 
% \end{gather*}
% 
%This combinatorics is relevant because by work of the third author the MV cycles are parametrized by Lusztig data. (This holds much more generally than the present scope.)
% 
% \acom{In this case $L = \langle t^3 e_1 - ate_2 - be_3 , t^2 e_2, te_3\rangle$ so $\rdim L^{w_0\omega_i} = \{1,3,6\} = \langle \mu , w_0 \omega_i\rangle = D_{\omega_i}(L)$}

% \jcom{$L \in S_-^{(3,2,1)}$, so $ \rdim L^{[3,3]} = 1 $ in accordance with the lemma above.}

We can associate to $\tau$ the locus 
%  
\begin{equation*}
    \mathring Z(\tau) = 
        \{
            L\in S^\mu_- : L_{[1,i]} \in\Gr^{\lambda(i)}\text{ for } i = 1, \dots m 
        \}\,. 
\end{equation*}
% and $Z(\tau) = \overline{\mathring Z(\tau)}$. 
% 
% \jcom{Maybe use $ [m] $ for $\{1, \dots, m\}$ ?}
% \acom{And $\{1,\dots,i\}$ etc.}

The following result is closely related to  Theorem 5.4.3. from \cite{dthesis}. It is also closely related to the description of MV cycles in terms of Kostant data obtained by Anderson--Kogan \cite{anderson2004mirkovic} (see Section 9 in \cite{kamnitzer2010mirkovic}).  
We remeark that a different map from Young tableaux to MV cycles was obtained by Gaussent--Littelmann--Nguyen \cite[Theorem 2]{gaussent2013knuth}; we are not certain of the relation with our construction. 

\begin{proposition}
    \label{pr:newmvdes}
    $ \mathring Z(\tau)$ has a unique irreducible component of dimension $ \rho(\lambda - \mu)$.  Let $ Z(\tau)$ denote the closure of this component.  Then, 
    $Z(\tau)$ is the MV cycle whose Lusztig datum (with respect to the standard reduced word) is $n_\bullet(\tau)$. 
\end{proposition}
\begin{remark}
We believe that $ \mathring Z(\tau)$ is irreducible so that in fact $ Z(\tau) = \overline{ \mathring Z(\tau)}$.
\end{remark}

\begin{proof}
    The proof of this theorem follows the same strategy as in \cite{dthesis}.
% \jcom{Maybe you would prefer to cite your thesis, Anne, but I think that it is better to cite the paper, since people can access it easier.}    
% \acom{I've been meaning to update the paper. It's peppered with ``typos''.}
% 
First, we consider 
% \acom{add \texttt{mathring}'s to these $Z$'s?} \jcom{Sure.}
\begin{equation*}
\mathring Z(\tau)_1 := \{ L \in S^\mu_- \cap \Gr_+ : L_{[1,i]} \in S_+^{\lambda(i)} \text{ for } i = 1, \dots m\} \,. 
%Z(\tau)_2 := \{ L \in S^\mu : L \cap \cO^i \in S^{\lambda(i)} \cap \Gr^{\lambda(i)} \text{ for } i = 1, \dots m\}
\end{equation*}
% 
Using Lemma \ref{le:rdimTrans}(2) and Lemma \ref{le:Srdim}, we see that
$$
\mathring Z(\tau)_1 = \{ L \in \Gr_+ : \rdim L_{[a,b]} = \lambda(b)_a + \dots + \lambda(b)_b \text{ for all $ 1 \le a \le b \le m $} \}
$$
where note that $ \lambda(b)_a + \dots + \lambda(b)_b$ is the number of boxes on rows $ a, \dots, b$ of weight $ 1, \dots, b $.
% \jcom{We could write that $ \lambda(i)_j + \dots + \lambda(i)_i$ is the number of boxes on rows $ j, \dots, i$ filled with $ 1, \dots, i $.}
% \acom{\emoji{thumbsup}} 

From  the proof of \cite[Proposition 9.6]{kamnitzer2010mirkovic}, we see that $ \mathring Z(\tau)_1$ is equal to $ t^\mu A(n_\bullet(\tau))$, where $ A(n_\bullet)$ is defined in Sect.\ 4.3 of \cite{kamnitzer2010mirkovic}. In particular, it is irreducible. Thus, its closure is the MV cycle whose Lusztig datum is $ n_\bullet(\tau) $. (The reader is warned that in \cite{kamnitzer2010mirkovic} the third author worked with $  G(\cO) \backslash G(\cK)$, which we identify with $ \Gr $ using the map $ G(\cO) g \mapsto g^{-1} G(\cO)$.) 
% \acom{Maybe we should avoid using square brackets as we haven't used them yet?}
% 
Now, by results of \cite{kamnitzer2008hives}, (see especially the proof of Theorem 1.4,) we note that $\mathring Z(\tau)_1\cap \Gr^\lambda$ is dense in $ \mathring Z(\tau)_1$. 
% Explanation: 
% MV polytopes giving tensor product multiplicity of V(\nu) in
% V(\lambda) \otimes V(\mu)
% with
% Hives with bdy \lambda, \mu, \nu.
% 
% If we take \mu and \nu to be sufficiently large compared to \lambda,
% then this becomes a bijection
% MV polytopes for the weight multiplicity V(\lambda)_{\nu - \mu}
% with
% Young tableaux YT(\lambda)_{\nu - \mu}
% 
% Even better, in that paper, I worked geometrically, and I gave a
% bijection from components of the fibre of the convolution morphism to
% hives.  Again, taking \mu, \nu large compared to \lambda, this fibre
% of the convolution morphism becomes Gr^\lambda \cap S^{\nu - \mu}.  So
% that paper actually does give a bijection from components of
% Gr^\lambda \cap S^{\nu - \mu} to tableaux.

Fix $ i \in \{1, \dots, m\}$. If $ L \in S^\mu_-$, then $ L_{[1,i]} \in S^{\mu(i)}_-$ so we get a map 
$$ 
f_i : \mathring Z(\tau)_1 \rightarrow S^{\mu(i)}_- \cap S_+^{\lambda(i)} \,. 
$$
From the definition of $ \mathring Z(\tau)_1 $, we see that $ f_i(\mathring Z(\tau)_1 )= \mathring Z(\tau(i))_1$.  
From above/again $ \Gr^{\lambda(i)} \cap f_i(\mathring Z(\tau(i))_1)$ is a dense constructible subset of $\mathring Z(\tau(i))_1$.  
Since $ \mathring Z(\tau)_1$ is irreducible, this implies that $ f_i^{-1}(S^{\mu(i)}_- \cap S_+^{\lambda(i)} \cap \Gr^{\lambda(i)}) $ 
% \acom{$\cap \mathring Z(\tau)_1$?} \jcom{The domain of $ f_i$ is $ \mathring Z(\tau)_1$, so automatically, these preimages are contained in $ Z(\tau)_1)$.} 
is a dense constructible subset of $ \mathring Z(\tau)_1 $.  

Working with all $ i $ at once, we conclude that
$$ 
\mathring Z(\tau)_2 := \bigcap_{i=1}^m f_i^{-1}(S^{\mu(i)}_- \cap S_+^{\lambda(i)} \cap \Gr^{\lambda(i)}) 
$$
is a dense constructible subset of $\mathring Z(\tau)_1$. 
% \acom{Again are we maybe missing capping with $Z$ in the above $:=$?} 
Thus $\overline{\mathring Z(\tau)_2} = \overline{\mathring Z(\tau)_1}$.

On the other hand, by definition 
$$
\mathring Z(\tau)_2 \subset \mathring Z(\tau). % \{ L \in S^\mu : L_{[i]} \in \Gr^{\lambda(i)} \text{ for } i = 1, \dots, m\}\,.
$$
Since $ \dim \mathring Z(\tau)_2 = \rho(\lambda - \mu)$, we see that $ \mathring Z(\tau) $ must have at least one component of the maximal dimension.  To see that it cannot have any other components of maximal dimension, we note that
$$ \bigsqcup_{\tau \in YT(\lambda)_\mu} \mathring Z(\tau) \subset \Gr^\lambda \cap S_-^\mu$$
and the number of irreducible components of the right hand side 
% \acom{of max dim?} \jcom{it is pure dimensional, as mentioned at the beginning of section 6.1} 
equals $|YT^\lambda_\mu|$, thus on the left hand side, each $ \mathring Z(\tau)$ can only have one irreducible component of dimension $ \rho(\lambda - \mu)$.
% 
%\jcom{Now, we need to show density here.  But maybe that won't be possible and we will need to take the ``top''.}
% 
% See computation 5.3.9 and Lemma 5.4.2 (ignore its proof) of \url{http://www.math.toronto.edu/adranows/athesis.pdf}. 
\end{proof}
% This gives us the dimension of Gr^\lambda \cap Gr_\mu \cap S^\mu.
% Given $(\tau',\tau'')\in YT(\lambda')_{\mu'}\times YT(\lambda'')_{\mu''}$ denote by $\lambda'(i),\lambda''(i)$ (resp.\ $\mu'(i),\mu''(i)$) the shape (resp.\ the weight) of $\tau'(i),\tau''(i)$ where $\tau^?(i)$ denotes the tableau got from $\tau^?$ by discarding all 
% % but its first $i$ boxes
% boxes of weight exceeding $i$. 
% % If the tableau contains repeated entries then first means leftmost.
% 
% \jcom{I don't think that you should mention this partial inverse here.  I think that you should explain here how the generalized orbital varieties are indexed by the tableaux, in other words, how $ X(\tau) $ is defined.}
% \acom{Ok, I moved it.}

% Denote the image of $\tau$ in $\overline{\OO}^\lambda\cap\TT_\mu\cap\n$ by $X(\tau)$ and in $\overline{\Gr}^\lambda\cap S^\mu_-$ by $Z(\tau)$. Thus $Z(\tau) = \phi(X(\tau))$. \acom{Out of place?} 
% \rcom{What is $\phi$?}
% 
% 
% TODO: Not yet, that would be the algo stuff that we are holding off on 
% In this section we explain how to determine the ideal of $Z'\ast_\AA Z''$ from the minimal pair $(\tau',\tau'')$ corresponding to $(n_\bullet(Z'),n_\bullet(Z''))$.
% 
% In particular, we prove that ``the generalized Spaltenstein map'' produces MV cycles. 
% 
% and recall the $\mu$-numeration of the standard basis of $\CC^N$. 
% TODO: can't we do without it^^

% 
% In this section we demonstrate how to put the main results of this paper into practice.
% 
% 
\subsection{Fusion of MVCs via BD MVy}

% \jcom{Anne, can you reorganize this section to start with $ X(\tau) $ and then do the fusion afterwards?}

Given $A \in M_N(\CC)$ we denote by $A\big|_{\CC^p}$ the restriction of $A$ to the subspace spanned by the first $p$ standard basis vectors of $\CC^N$.  If $A\big|_{\CC^p}(\CC^p)\subset\CC^p$ then we identify it with the $p\times p$ upper-left submatrix of $A$. 
% \acom{Change $\CC$'s to $\AA$'s?} No.
% TODO: address 
% \acom{We could also use a more compact notation like $A_{(p)}$}
% \acom{We may want to introduce $\ast_s$ in general. For now we make a definition.} 

Let $\tau\in YT(\lambda)_\mu$ with $\mu$ dominant. 
We define
\[
\mathring X(\tau) = 
% \overline{
    \{
        A \in  \TT_\mu\cap\n : A\big|_{\CC^{|\mu(i)|}} \in \OO^{\lambda(i)} \text{ for each } i = 1,\dots,m
    \}\,.
\]

\begin{lemma}
    \label{lem:XtZt}
    Under the Mirkovi\'c--Vybornov isomorphism $\mathring X(\tau)$ is mapped isomorphically onto $\mathring Z(\tau)$. 
\end{lemma}
% \jcom{We should add a proof here.  It will be very similar to Prop 5 below.} \acom{Ca marche?}
% \jcom{Oui.  J'ai fait des petites revisions.}
\begin{proof}
Fix $A\in\mathring X(\tau)$ and $i\in\{1,\dots,m\}$. Let $\cO^i\subset\cO^m$ denote the submodule generated by the first $i$ standard basis vectors. Let $l = g(A\big|_{\CC^{\lvert\mu(i)\rvert}}) \cO^i$ and $L = g(A) \cO^m$. By definition of the map $A \mapsto g(A)$, since $ A $ is upper-triangular we have that $l = L_{[1,i]}$. 
Moreover, since elements of $\TT_\mu\cap\n$ are upper triangular $A\big|_{\CC^{\lvert\mu(i)\rvert}}\in\TT_{\mu(i)}\cap\n_i$ where $\n_i$ denotes the subalgebra of upper-triangular matrices in $M_{\lvert\mu(i)\rvert}(\CC)$. 
By definition of $\mathring X(\tau)$ this principal submatrix has Jordan type $\lambda(i)$. It follows that $l = L_{[1,i]} \in \Gr^{\lambda(i)} \cap S^{\mu(i)}$ for each $i=1,\dots,m$ so that $L\in\mathring Z(\tau)$. 

Conversely, let $ L \in \mathring Z(\tau) $.  By \Cref{cor:mvy}, $ L = g(A)$ for some $ A \in \TT_\mu \cap \n $.  Running the above argument in reverse, we see that $ A \in \mathring X(\tau)$. 
\end{proof}

By \cite[Prop.\ 4.5.4]{dthesis}, $ \mathring X(\tau) $ has a unique irreducible component of dimension $ \rho(\lambda - \mu)$.  We write $ X(\tau)$ for the closure of this component.  It is an irreducible component of $ \overline{\OO}^\lambda \cap \TT_\mu \cap \n$ and will be called a \new{generalized orbital variety}.
% 
% \jcom{We should give a more specific citation to \cite{dthesis} here and below.  Also, throughout this paper, we should either cite your paper or your thesis, but not both (unless there is a very good reason to do so).  I reorganized this section a bit.  Feel free to add a bit more exposition.}
% \acom{Just posted to arXiv. Will re-ref shortly. Also made citation more specific.}
% 
In fact, these are all the generalized orbital varieties:
\begin{theorem}(\cite[Theorem~4.8.2]{dthesis})
    \label{pr:govsasirrecs}
    $\{{X(\tau)} : \tau\in YT(\lambda)_\mu\}$ is a complete set of irreducible components of $\overline{\OO}^\lambda\cap\TT_\mu\cap\n$. 
\end{theorem}
% 

% \jcom{Please add a reference to your paper here and also a lemma which states that under the Mirkovic-Vybornov isomorphism $ \mathring X(\tau) $ is mapped isomorphically onto $ \mathring Z(\tau) $.}
% 
Our goal is to describe the fusion of two MV cycles using ``fusion'' of generalized orbital varieties, which we will now define. 
% \acom{So we \textit{are} calling this a fusion?} \jcom{I think that you used this word already here.  I just reorganized your sentence.} \acom{I agree, but I thought that you were opposed, Joel.}
% 
Let $\lambda,\lambda',\lambda''$ and $\mu \mu',\mu''$ be as in previous sections, once again assuming that $\mu$ is dominant.
% \jcom{I think that this is can move earlier, with the caveat that I mentioned earlier about $ \mu $ being non-dominant in 6.1 and dominant here.} \acom{Yes.} \acom{But we only start to need the primes now.}

% 
Given $s\in\Ax$ and a pair of tableaux $\tau'\in YT(\lambda')_{\mu'}$ and $\tau''\in YT(\lambda'')_{\mu''}$ we define
% 
\begin{equation*}
    \mathring X(\tau',\tau'')_{0,s} 
    % X(\tau')\ast_s \mathring X(\tau'') 
    = \left\{A\in\UU_{0,s}^{\mu',\mu''} : A \big|_{\CC^{|\mu(i)|}} 
    \text{ has Jordan type } ((\lambda'(i), 0), (\lambda''(i), s))
    % \in \OO_{0,s}^{\lambda'(i),\lambda''(i)} 
    \text{ for } i=1,\dots,N\right\}
\end{equation*}
% 
% \jcom{Maybe instead write ``$A \big|_{\CC^{|\mu(i)|}}$ has Jordan type $ (\lambda'(i), 0), (\lambda''(i), s)$} \acom{Okay. So no need for the first paragraph of this section?}
% 
and
\begin{equation*}
        % X(\tau')\ast_{\AA^\times} X(\tau'') = 
        \mathring X(\tau',\tau'')_{0,\AA^\times} = 
    \left\{
        (A,s)\in M_N(\CC) \times \AA^\times: 
        A \in \mathring X(\tau',\tau'')_{0,s} 
    \right\}\,.
\end{equation*}
% 
Note that elements $A\in\mathring X(\tau',\tau'')$ do not in general correspond to pairs $(A',A'')\in\mathring X(\tau')\times X(\tau'')$ because if $\mu'$ (resp.\ $\mu''$) is not dominant then $X(\tau')$ (resp.\ $X(\tau'')$) is not well-defined. 
% The space we have defined may therefore not be a true fusion in the sense that it may not come from two obvious spaces. \acom{Joel?} 
% \jcom{Even if $ \mu', \mu'$ are dominant, it is not obvious how $ A $ corresponds to a pair $(A', A'')$.  And since I don't think that ``true fusion'' is a well-defined thing, I think that we can delete the last sentence.}
% \acom{Ok. By choosing bases of generalized eigenspaces?}

% 
% and let $Z'\ast_s Z'' = (Z'\ast_\AA Z'')_s$.
% If $s\ne 0$ identify $Z'\ast_s Z''= Z'\times Z''$ via $\Gr_{0,s}\cong \Gr\times\Gr$.
% \acom{or make the identification using the map the map $\tau$ of \Cref{eq:mvitau}. Can similarly identify $X'\ast_s X'' = X'\times X''$ by performing the obvious change of basis and block-diagonalizing. May make sense to introduce $\ast_s$ in greater generality, earlier; or at least on MV cycles earlier, since here I should actually make the definition for $Z(\tau)$'s.. which is ok, as in not a loss of generality. Still..}
% 
% \jcom{Now that we have $ \ast_s$ defined in the fusion section, we can refer to that here.}
%Recall the map $\theta : \Gr_{0, \AA^\times} \rightarrow \Gr \times \Gr$ from \Cref{ss:affgrs}. 
\begin{proposition}
    \label{pr:XttZtt}
    The image of $\mathring X(\tau',\tau'')_{0,\AA^\times}$ under the isomorphism of \Cref{th:OTGrW} is $\mathring Z(\tau')\ast_\Cx \mathring Z(\tau'')$. 
    % \[
    % \overline{\phi(X(\tau',\tau''))} 
    % = Z'\ast_s Z'' \,. 
    % \]
\end{proposition}
% 
% \jcom{Do you want the ``blocky'' or ``boxy'' description here?  I mean, do you want $ i = 1, \dots, N$ or $ i =1, \dots, m$? I'm not so sure that ``boxy'' will work, since with those $s$ in the matrix, it doesn't preserves all the $ \CC^i$.}

% \acom{Fixed.}

%\jcom{We never quite defined $\mathring Z(\tau')\ast_{\AA^\times} \mathring Z(\tau'')$ so maybe we should write this down somewhere.  Once we do this, I'm pretty sure that we will not get ``dense'' but an equality.}

%\acom{Should we just use $\tau^{-1}(\mathring Z(\tau') \times \mathring Z(\tau''))$ instead?} 

%\jcom{Yes, maybe that is a good idea. We should recall $ \tau $, and I suppose since we have two $ \tau$s, we had better change notation.  Maybe we can use a different letter for the $\tau$ used to define fusion and keep $ \tau $ for tableau.}

% \acom{Changed it to $\theta$ \emoji{worried}}
% \jcom{I went ahead and defined $ \ast_\Cx$ in the fusion section so now we can use it.}
% \acom{TYVM}

\begin{proof}
% 
Fix $A\in \mathring X(\tau',\tau'')_{0,s} $ and $i \in \{1,\dots, m\}$. 
% 
Let $\CC[t]^i\subset\CC[t]^m = \CC^m\otimes_\CC\CC[t]$ denote the $\CC[t]$-submodule generated by the first $i$ standard basis vectors.
% \acom{Probably don't need to repeat this.}

The lattices $l=g(A\big|_{\CC^{|\mu(i)|}})\CC[t]^i$ and $L=g(A)\CC[t]^m$ are related by the equation $ l = L_{[1,i]}$ where recall $L_{[1,i]} = (L + \CC[t]^{[i+1,m]}) / \CC[t]^{[i+1,m]}\subset \CC[t]^m/\CC[t]^{[i+1,m]} = \CC[t]^i$. 
    
By definition of $\UU^{\mu',\mu''}_{0,\AA}$ we have $A\big|_{\CC^{|\mu(i)|}}\in\UU^{\mu'(i),\mu''(i)}_{0,s}$ and by definition of $\mathring X(\tau',\tau'')_{0,s}$, the Jordan type of $A\big|_{\CC^{|\mu(i)|}}$ is $((\lambda'(i),0),(\lambda''(i),s))$. So, $l \in\Gr_{0,s}^{\lambda'(i),\lambda''(i)}$ by \Cref{th:OTGrW}. 
On the other hand, 
% also by definition of $\UU^{\mu',\mu''}_{0,\AA}$, we have 
since $L\in S^{\mu',\mu''}_{0,s}$, $l\in S^{\mu'(i),\mu''(i)}_{0,s}$. 

Therefore, as $i$ varies, we see that the pair $(L(0),L(s))\in S^{\mu'}\times S^{\mu''}$ is such that 
$$
(L_{[1,i]}(0),L_{[1,i]}(s))  = (L(0)_{[1,i]},L(s)_{[1,i]}) \in \Gr^{\lambda'(i)}\times\Gr^{\lambda''(i)}
$$ 
and so $(L(0),L(s))\in \mathring Z(\tau')\times \mathring Z(\tau'')$. The argument can be reversed for
$L\in\mathring Z(\tau')\ast_\Cx \mathring Z(\tau'')$.
% \theta^{-1}(\mathring Z(\tau')\times Z(\tau''))$.
% 
% For the converse we use the fact that the map $A\mapsto g(A)$ is an isomorphism of $\overline{\OO}^{\lambda',\lambda''}_{0,\AA}\cap\UU^{\mu',\mu''}_{0,\AA}$ and $\overline{\Gr}^{\lambda',\lambda''}_{0,\AA}\cap S^{\mu',\mu''}_{0,\AA}$ which restricts to an isomorphism of generalized orbital varieties and MV cycles in fibres. 
% \acom{Better way to say?} \jcom{I think that you can just rewrite this first half as if and only if and drop the second half. }
% Given $L\in\mathring Z(\tau') \ast_{\AA^\times}\mathring Z(\tau'')$ let $A$ be such that $L = g(A)\CC[t]^i$. \acom{But, is it clear that $A\in\mathring X(\tau',\tau'')_{0,s}$?} 
% Do we need that there exists $(A',A'')\in M_{N'}\times M_{N''}$ such that $L(0) = g(A')\cO^m$ and $L(s) = g(A'')\cO^m$, and that we could take $A'\oplus A''=A$ up to some conjugation that puts $A'\oplus A''\in\TT_\mu$ which is possible because $\TT_\mu$ intersects $\OO^{\lambda',\lambda''}_{0,\AA}$ transversely? 
\end{proof}
% 

Now, in analogy with the geometric fusion of \Cref{ss:fuscon}
% \acom{add loc cit} \jcom{I think just add a reference our fusion section} \acom{Yeah that's what I meant, taking loc cit literally}
we define $X(\tau', \tau'')_{0,0} $ to be the zero fibre of the Zariski closure of $\mathring X(\tau',\tau'')_{0,\AA^\times}$ in $M_N(\CC)\times\CC$. By \Cref{prop:adjoint} it is contained in $\overline\OO^\lambda\cap\TT_\mu\cap\n$, so by Theorem 4 its irreducible components are generalized orbital varieties. 
% 

\acom{Recalling intersection multiplicity:} 

We have the zero fibre in $\Grbd$ as effective divisor $D$, and the fusion of subscheme $V = X\ast_\AA Y\subset\Grbd$ as a finite-dimensional irreducible variety not contained in the support of $D$, and finally an irreducible component $Z$ of $D\cdot V = X\ast_0 Y$, codimension 1 in $V$. Denote by $\iota(Z,D\cdot V)$ the intersection multiplicity of $Z$. 
\begin{corollary}
\label{cor:iota}
    % The image of $\mathring X(\tau',\tau'')_{0,0}$ in $\mathring Z(\tau')\ast_0 \mathring Z(\tau'')$ is dense. In particular 
    $\iota(X(\tau), X(\tau',\tau'')_{0,0}) = \iota( Z(\tau), Z(\tau')\ast_0 Z(\tau''))\,.$
\end{corollary}
%\acom{Do we need to introduce $X(\tau',\tau'')_{0,0}$ to state the theorem or can we state it on $\mathring X$'s and $\mathring Z$'s again?}
%\jcom{I changed the statement. I will edit the proof later. }
%


\begin{proof}
%[Proof of~\Cref{cor:iota}]
%Since $\mathring X(\tau',\tau'')_{0,0}\subset\overline{\OO}^\lambda\cap\TT_\mu\cap\n$ and $\dim X(\tau',\tau'')_{0,0} = \dim \overline{\OO}^\lambda\cap\TT_\mu\cap\n$ \acom{why?} irreducible components of $\mathring X(\tau',\tau'')_{0,0}$ are generalized orbital varieties. 
We can compute intersection multiplicities by passing to dense constructible subsets.  
By the isomorphisms of \Cref{lem:XtZt} and \Cref{pr:XttZtt}, $X(\tau) $ is a dense constructible subset of $ Z(\tau) $ and $ X(\tau', \tau'')_{0,0} $ is a dense constructible subset of $ Z(\tau') \ast_0 Z(\tau'') $.
%  
% \acom{Hm, I guess you are right, it is easier than what I had, we just need that the arguments on either side match up, and not that the arguments on one side are related. Though do we really not use that $X(\tau)$ may be contained in $X(\tau',\tau'')_{0,0}$ as an irreducible component?}  
\end{proof}
% 
\acom{A tuppence about this conjecture?}
\begin{conjecture}
    % Let $Z_i \subset \overline{S^{\nu_i}\cap S^0_-}$ be an MV cycle of weight $\nu_i$ ($i = 1,2$) and put $\nu = \nu_1 + \nu  _2$. 
    Let $\tau$ be the tableau got by taking the union of the rows of $\tau'$ and $\tau''$ and ordering the entries in each row smallest to largest. 
    % Note that $\tau$ has shape $\lambda$, weight $\mu$, and  Lusztig datum equal to the sum of the Lusztig data of $\tau'$ and $\tau''$. 
    Then 
    \begin{equation}
        \iota(Z(\tau), Z(\tau') \geofu Z(\tau'')) = 1 \,. 
    \end{equation}
\end{conjecture}
% 
% RESOLVED COMMENTS
% \jcom{Rather than adding the Lusztig data, how can you produce $\tau$ directly from $\tau', \tau''$?  I guess you can just add the GT patterns, so for tableaux you just take the union of the rows, is that right?}
% 
% \acom{Pierre said he hasn't thought about this since he last thought about this and remarked that KKKO would distinguish two terms, a leading and a tailing one.} 
% 
\subsection{Representations in $\CC[N]$}
\label{ss:CN}
% 
% \jcom{
% Maybe we need a word about Langlands duality here.  Since we are working with $ GL_m$, it is not really necessary, but it would be nice to point this out.  
% Also a general comment: maybe it would be best to first talk about multiplication in $\CC[N]$ incl. Theorem 7.11 from mvbasis, and then talk about cluster algebras.  Right now, it is a bit confusing, since we go back and forth.  Also some of the motivation stuff about the semicanonical basis, etc, will be moved to the intro.
% }
In this section we will need to recall that representations of the Langlands dual group $G^\vee$ of an arbitrary complex reductive group $G$ can be constructed from the affine Grassmannian of $G$, and studied in $\CC[N^\vee]$ the ring of functions on the maximal unipotent subgroup $N^\vee$ of $G^\vee$. 
% 

We use the convenient fact that $\GL_m^\vee = \GL_m$ and ignore the distinction, referring to points $t^\lambda$ as coweights for $\lambda\in\ZZ^m$ weights. 
% 

\acom{So far we have been saying ``coweight'' $\lambda$, etc. We could say coweight for $t^\lambda$ and weight for $\lambda$ starting now? Also, maybe add a warning that some of the theorems we rely on hold more generally? Like the MV basis theorem..}

Let $N\subset\GL_m$ be the unipotent subgroup of upper-triangular matrices with 1s on the diagonal. In \cite{baumann2019mirkovic} the third author along with Baumann and Knutson show that the MV cycles yield a basis of the coordinate ring $\CC[N]$ called the MV basis. Note that with respect to the action of the maximal torus $T$ of $\GL_m$ by conjugation on $N$, $\CC[N]$ acquires a homogeneous grading by $Q_+$. 
% 
% First note that with respect to the adjoint action of $T$ on $N$, $\CC[N]$ is graded by the set $-Q_+$ of nonpositive integer linear combinations of positive roots. 
% 

Given weights $\mu\le\lambda$ with $\lambda$ dominant, denote by $V(\lambda)$ the irreducible representation of $\GL_m$ of highest weight $\lambda$ and by $V(\lambda)_\mu$ its $\mu$-weight space. 
There is an injective map $ \Psi_\lambda: V(\lambda) \to \CC[N]$ realizing $V(\lambda)$ as a subspace of $\CC[N]$ and sending $v\in V(\lambda)_\mu$ to $\CC[N]_{\mu - \lambda}$. 

The geometric Satake correspondence says that 
% $V(\lambda) = IH(\overline\Gr^\lambda)$ and  
$V(\lambda)_\mu = H_{2\rho(\lambda-\mu)}(\overline{\Gr^\lambda\cap S^\mu_-})$ where $H_d$ denotes $d$-dimensional Borel--Moore homology. In particular, the set $\{[Z] : Z\in\cZ(\lambda)\}$ gives a basis of $V(\lambda)$ with $[Z]$ denoting the class of $Z$ in the appropriate homology group. 

\acom{Warning! Earlier we defined the MV cycles as irreducible components of $\overline{\Gr^\lambda}\cap S^\mu$}
% In particular, the MV cycles in $\overline{\Gr}^\lambda$ of coweight $\mu\le\lambda$ give a basis of $V(\lambda)$. 
% 

The \new{stable} MV cycles of coweight $\nu\in Q_+$ are defined to be irreducible components of $\overline{S^0_+ \cap S^\nu_-}$. By a theorem of Anderson, MV cycles in $\overline{\Gr^\lambda\cap S^{\nu + \lambda}_-}$ are in bijection with stable MV cycles of coweight $\nu$ that are contained in $\overline\Gr^\lambda$ \cite[Proposition~3]{anderson2003polytope}. We denote the set of all stable MV cycles $\cZ(\infty)$. 
% Recall that MV cycles can be described combinatorially by Lusztig data. 
By a theorem of the third author, a stable MV cycle is uniquely determined by its Lusztig datum and the sets $\cZ(\infty)$ and $\NN^{\Delta_+}$ are in bijection. 
% Recall that Lusztig data, like elements of $\CC[N]$, are weighted by $Q_+$. 
With a little bit more work one can string together the maps $\Psi_\lambda$ and the geometric Satake isomoprhisms to show that the stable MV cycles yield a basis of $\CC[N]$.  

\begin{theorem}
    (A special case of \cite[Proposition~6.1]{baumann2019mirkovic})
    For each $Z\in\cZ(\infty)$ there is a unique element $b_Z\in\CC[N]$ such that for any dominant weight $\lambda$, if $t^\lambda Z\in\cZ(\lambda)$ then $\Psi_\lambda([t^\lambda Z]) = b_Z$ and the collection of all such elements is called the \new{MV basis}. 
\end{theorem}
% 
Furthermore, the structure constants of multiplication in $\CC[N]$ with respect to the MV basis are given by intersection multiplicities. 
% 
\begin{theorem}
    (A special case of \cite[Theorem~7.11]{baumann2019mirkovic}) Given $Z',Z''\in\cZ(\infty)$, 
    % of coweight $\nu',\nu''$ respectively 
$$
b_{Z'}\arfu b_{Z''} = \sum_{Z\in\cZ(\infty)} \iota\left(Z, Z' \geofu Z''\right) b_Z 
$$
in $\CC[N]$. \acom{The summation is finite since 7.1?... Don't want to introduce the notation $\cZ(\infty)_\nu$ if we can avoid it.}
Moreover, there exist $\lambda',\lambda''$ dominant effective and a pair of tableaux $(\tau',\tau'')\in YT(\lambda')\times YT(\lambda'')$ such that 
\begin{equation}
    \label{eq:multingovs}
    % b_{Z'} \arfu b_{Z''} = \sum_{Z\in\cZ(\lambda)} \iota (Z, Z(\tau')\geofu Z(\tau''))b_{t^{-\lambda}Z}
    b_{Z'} \arfu b_{Z''} = \sum_{\tau\in YT(\lambda)} \iota (X(\tau), X(\tau',\tau'')_{0,0})b_{t^{-\lambda}Z(\tau)}
\end{equation}
% 
for $\lambda = \lambda' + \lambda''$. 
\end{theorem}
% Given $\epsilon\in\ZZ^m$ denote by $t^\epsilon:V(\lambda) \to V(\lambda + \epsilon)$ the map resulting from multiplication by the coweight $t^\epsilon$ in $\Gr$. By BKK, $\Psi_{\lambda + \epsilon} \circ t^\epsilon - \Psi_\lambda = 0$. 
% 
% Together these facts imply the following commutative square.
% \[
% \begin{tikzcd}
% L(\lambda) \ar[r] & \CC[N] \\
% \Gr^\lambda \cap S^\mu_- \ar[r,"t^{-\lambda}"] \ar[u] & S^0 \cap S^{\mu - \lambda}_-\ar[u]
% \end{tikzcd}
% \]
% \jcom{This paragraph is a bit confusing.  Maybe it would be best to first define $ V(\lambda) \rightarrow \CC[N]$ and then $ H_{top}(\overline{Gr}^\lambda \cap S^\mu) \rightarrow \CC[N]$, rather than doing them in one step.  Then we can draw a commutative square with $ S^0_+ \cap S_-^\nu$ as well. }
% \acom{Not sure which square to draw or if it is necessary. I guess you want something like what's pictured below, where what we're about to describe are the blue arrows. Specifically the rightmost downward pointing blue. Which, by commutativity, will determine the middle downward pointing blue.}
% \jcom{Yes, I like this diagram.  Maybe the two rightward arrow should point leftward, since we did already define $ \tau \mapsto Z(\tau)$.}
% 
In \Cref{s:examples} we will identify elements $b_Z$ with certain \textit{minimal} tableaux (instead of Lusztig data) and view $\CC[N]$ as an algebra in these tableaux, abbreviating \Cref{eq:multingovs} as equation in these tableaux. 

Before we describe how to choose representative generalized orbital varieties in order to expand a product of MV basis elements $b_{Z'}\arfu b_{Z''}$ in $\CC[N]$ we summarize our approach in the following commutative diagram. 
\[
% \begin{tikzcd}
% \CC[N] & \ar[l] \cZ(\infty) \ar[r,"n_\bullet"] \ar[d,bend left,blue] & \NN^{\Delta_+} \ar[l,blue,bend left] \ar[d,bend left,blue]\\ 
% L(\lambda) \ar[u,"\Psi_\lambda"] & \ar[l] \cZ(\lambda) \ar[r] \ar[u,"t^{-\lambda}"] & YT(\lambda) \ar[u,"n_\bullet"] \ar[l,blue,bend left]
% \end{tikzcd}
\begin{tikzcd}
    YT(\lambda) \ar[r] \ar[d,"n_\bullet"] & \cZ(\lambda) \ar[r] \ar[d, "t^{-\lambda}"] & L(\lambda) \ar[d, "\Psi_\lambda"] \\ %  description
    \NN^{\Delta_+} \ar[r] \ar[u,dashed,bend left,"\sigma_\lambda"] & \cZ(\infty) \ar[r] & \CC[N]
\end{tikzcd}
\]
The fibres of $n_\bullet$ \acom{in $\cup YT(\lambda)$} contain tableaux related by padding. 
While $Z(\tau)$ is defined even when $\mu$ is not dominant, $X(\tau)$ is not, and so we need to choose a section $\sigma_\lambda$ of $n_\bullet$ with image in the set of tableaux having dominant weight. 
% 

\acom{Should I adjust the diagram so that its from unions over $\lambda$}

% \jcom{In principle, the notation $ Z' \ast_0 Z''$ has been defined, since we defined the fusion of any two subschemes of $ \Gr$.  We should just note that the fusion of the stable MV cycles matches the fusion of MV cycles after translation by $ t^\lambda$.  I don't think that $ \iota$ has been defined anywhere, has it?}

\begin{lemma}
    \label{lem:mintab}
    Let $n_\bullet$ be a Lusztig datum of coweight $\nu$. There exist $\lambda,\mu$ dominant effective smallest such that $n_\bullet$ is the Lusztig datum of a tableau $\tau\in YT(\lambda)_\mu$. They are determined by the following minimization problem. Regard $n_\bullet$ as a strictly lower triangular matrix with $(r,c)$th entry $n_{r,c}$ is equal to the number of boxes of weight $r$ in row $c$ of $\tau$. Note that since $r > c$ this data does not account for the number of boxes of weight $r$ in row $r$. Let $\mu^0$ be the diagonal matrix whose $(r,r)$th entry $\mu^0_r$ is equal to the number of boxes of weight $r$ in row $r$ of $\tau$. Note that the sum of the rows of $n_\bullet + \mu^0$ is the shape $\lambda$ of $\tau$, and the sum of the columns of $n_\bullet + \mu^0$ is the weight $\mu$ of $\tau$. The solution to the minimization problem 
    \[
        \begin{gathered}
        % 
        \text{minimize }\mu^0\text{ such that} \\
        % \text{the sum of the rows of }n_\bullet + \mu^0\text{ is non-increasing},
        % \text{the sum of the columns of }n_\bullet + \mu^0\text{ is non-increasing}
        \text{both }\lambda,\mu\text{ are non-increasing}
        \end{gathered} 
    \]
    is got recursively from % setting $\mu^0_m = 0$, 
    \[
        \begin{gathered}
            \mu^0_{m} = 0 \\ 
            \mu^0_{m-1} = \max\{0 , \sum n_{m,c} - \sum n_{m-1,c}\} \\ 
            \mu^0_i = \max\{0, \mu^0_{i+1} + \sum n_{i+1,c} - \sum n_{i,c} , \mu_{i+1}^0 + \sum n_{r,i+1} - \sum n_{r,i}\}
        \end{gathered}
    \]
    for $i = 1,\dots,m-2$. 
    In words, given a Luszig datum $n_\bullet$, if we wish to produce a minimal SSYT for it, 
    \begin{itemize}
        \item we can always take the number of $m$'s in row $m$ to be zero; 
        \item we can take the number of $m-1$'s in row $m-1$ to be zero, unless $n_\bullet$ tells us that there are more $m$'s the first $m-1$ rows than there are $m-1$'s in the first $m-2$ rows, and in that case we take $\mu^0_{m-1}$ so that it exactly offsets the difference; 
        \item we can take the number of $m-2$'s in row $m-2$ to be zero, unless $n_\bullet$ tells us there are more $m-1$'s in the first $m-1$ rows (building off the last step) than there are $m-2$'s in the first $m-3$ rows, or, that there are more boxes in row $m-1$ than there are in row $m-2$, and then we take $\mu^0_{m-2}$ to offset the minimum of the two differences; 
        \item induct up to $\mu^0_1$. 
    \end{itemize}
\end{lemma}

\begin{proposition}
    \label{prop:minwts}
    Given two Lusztig data $n_\bullet',n_\bullet''$ there is a smallest choice of effective coweights $\mu',\mu''$ and effective dominant coweights $\lambda',\lambda''$ such that $\mu = \mu' + \mu''$ is effective dominant and $(\tau',\tau'')\in YT(\lambda')_{\mu'}\times YT(\lambda'')_{\mu''}$ are semistandard Young tableaux with the prescribed Lusztig data. They are got by choosing the minimum $\lambda,\mu$ for $n_\bullet = n_\bullet ' + n_\bullet ''$ afforded by \Cref{lem:mintab}, and then breaking off $n_{r,c}'$ boxes of weight $r$ from each row $c<r$ of $\tau$ to form a $\tau'_0$ an intermediate tableau. If $\tau'_0$ is of an acceptable shape then we keep it. If it is not, then we correct it by padding it using some boxes of weight $r$ in row $r$ of what remains of $\tau$.

    \acom{To be completed. We require a notion of ``smallest'' pair of factor tableaux associated to a given tableau --- that is if we care to include our $B(\infty)\to B(\lambda)$ map. 
    As the examples show, there may be more than one way to break up a ``minimal'' tableau for $n_\bullet = n_\bullet ' + n_\bullet ''$ into two tableaux with data $n_\bullet' $ and $n_\bullet''$ resp.\ The practical notion of min is such that the generalized nonzero eigenspace has the smallest possible dimension.}
    \acom{Reference Claxton--Tingley multisegments, Hong--Lee marignally large tableaux for comparison.}
\end{proposition}

\section{Cluster questions}
\label{s:clusterqus}
% 
For initial seeds $(x_1, \dots, x_r)$ obtained from a reduced expression of the longest word (length $r = \#\Delta_+$) in the Weyl group for $G$, each $x_i$ is a generalized minor  \cite{kato2011polytopal}, and hence 
% \acom{by BKK?}\rcom{I reworded it.} 
is in the MV basis. 
% as these correspond to generalized minors \cite{berenstein2005cluster3}\cite{geiss2007initial}. \acom{what's the subscript $r$? also what're the last 2 citations for? Neither BFZ nor GLS link generalized minors and MV cycles}
If the reduced expression satisfies a special condition, then cluster monomials in the initial seed are also in the MV basis \cite{baumann2020bases}.

Conversely, suppose we have a seed $(x_1,\dots,x_r)$ such that each $x_i$ is in the MV basis, i.e.\ for each $i$ there exists a stable MV cycle $Z_i$ such that $x_i = b_{Z_i}\in\CC[N]$. To show that all cluster variables 
% \acom{for this seed?}\rcom{No, all of them.} 
are also in the MV basis it suffices to show that if $x_i$ is mutable then its mutation $x_i^*$ is also in the MV basis. This observation is based on the exchange relation:
\[
    x_i x_i^* = x_+ + x_- 
\]
where $x_+,x_-$ are monomials in $ (x_1, \dots, x_r)\setminus x_i$ determined by the cluster structure on $\CC[N]$. 
% \acom{the structure of interest? or are all cluster structures on this ring the same?} \rcom{The structure is derived from an initial seed coming from a reduced word {\bf i}. Each of these are equivalent to each other.}
So if we can find a stable MV cycle $Z_i^*$ such that $b_{Z_i}b_{Z_i^*} = x_+ + x_-$ for each $i$ then we will have checked the conjecture. 
% \acom{And we do not need to assume the special condition of BGL?}\rcom{They deal with cluster monomials in certain clusters while this deals with all cluster variables, so neither one completely implies the other.}

The following examples give evidence that the mutation $x_i^*$ is in the MV basis. \acom{Roger, reword?}\rcom{Something like this?} \acom{Sure!}
 
% \jcom{We should recall the stable MV cycles and the theorem from mvbasis regarding multiplication in $ \CC[N]$.}
% \acom{Begun}

Before we begin we will need some lemmas, notions and notations. 
\begin{itemize}
    \item we have only seen how to fuse ordinary MV cycles; to mutliply MV basis vectors which are indexed by stable MV cycles we'll therefore need a way to represent stable by ordinary; hence:
    \item a notion/choice of fission 
    \item the fission lemmas 
    \item with lemmas in hand, a proposition: given $Z',Z''$ stable with LD... there exist $\tau',\tau''$ (min) such that $b_{Z'} b_{Z''} = b(\tau')  b(\tau'')$
    \item a shorthand: in examples, instead of writing $Z(\tau)$ for the MV cycle corresponding to the tableau $\tau$ we will only the tableau $\tau$! 
\end{itemize}

% Let's wait for Gerhard before we discuss our computations any further
% \subsection{Pseudocode}
% 
% \section{Cluster Algebras}
% One of the main motivations for this paper is computing certain fusion products that are associated to exchange relations in the cluster algebra structure of $\CC[N]$. 
% 
% A basis of $\CC[N]$, called the dual semicanonical basis, was originally constructed in \cite{lusztig2000semicanonical} while a cluster algebra structure for $\CC[N]$ was shown in \cite{berenstein2005cluster3} and \cite{geiss2007initial}.
% A natural question was whether the cluster monomials were elements of the dual semicanonical basis, proved in the positive in \cite{geiss2006rigid}.

% Another basis for $\CC[N]$ was constructed in \cite{mirkovic2007geometric} called the MV basis. This basis is indexed by the MV cycles and the product of basis elements corresponds to the fusion product of the associated MV cycles. While this basis is different from the dual semicanonical basis, as shown in \cite{baumann2019mirkovic}, they seemed to share a lot of common elements, such as various cluster variables, which led to the following conjecture.

% \begin{conjecture}\label{conj:cluster in MV}
%     The cluster monomials of $\CC[N]$ are elements of the MV basis.
% \end{conjecture}

% Conjecture \ref{conj:cluster in MV} is known for type $A_n$, $n \leq 3$, as in this case, there is a unique biperfect basis for $\CC[N]$ \cite{baumann2019mirkovic}, so the dual semicanonical basis and MV basis are the same.

% It has been shown in \cite{kato2011polytopal} that for initial seeds $(x_1, \dots, x_r)$ obtained from a reduced expression of the longest word in the Weyl group for $G$, each $x_i$ is in the MV basis as these correspond to generalized minors \cite{berenstein2005cluster3}\cite{geiss2007initial}. If the reduced expression satisfies a special condition, then the cluster monomials in the initial seed are also in the MV basis \cite{baumann2020bases}.

% Suppose we have a seed $(x_1, \dots, x_r)$ where each $x_i$ is already in the MV basis. To show all the other cluster variables are in the MV basis, it suffices to show that for a mutable variable $x_i$, its mutation $x_i^*$ is also in the MV basis. The exchange relation corresponding to $x_i$ and $x_i^*$ is of the form
% $$x_ix_i^* = x_+ + x_-$$
% where $x_+$ and $x_-$ are monomials in the $x_j,j\neq i$. Let $Z_i$ be the MV cycle corresponding to $x_i$, so $x_i = b_{Z_i}$. If we are able to find an MV cycle $Z_i^*$ such that
% $$b_{Z_i} b_{Z_i^*} = x_+ + x_-,$$
% then this means $x_i^* = b_{Z_i^*}$ so it is in the MV basis with associated MV cycle $Z_i^*$. In Section \ref{s:denouement}, we present examples showcasing this is indeed true for type $A_3$. 

\section{Examples}
\label{s:examples}

% \acom{Plus fusion product of fake MV cycles for a fourth!}
\acom{TODO: review/rewrite now that we have \S 6.2}
We view MV cycles as semi-standard young tableaux. Suppose we have two tableaux $\tau'$ and $\tau''$, with respective weights $\lambda'$, $\mu'$ and $\lambda''$, $\mu''$, and we wished to take their fusion product. We consider a generic matrix $X \in \UU^{\mu',\mu''}_{0,s}$ and see what relations on the variables in $X$ occur when also asking for it to be in $\OO^{\lambda',\lambda''}_{0,s}$. \acom{Relations dictated by $\tau$. Can mostly refer the reader to the previous section for this background, now.}

Consider the subtableaux $\tau'(i)$ of $\tau'$ and $\tau''(i)$ of $\tau''$ where we take the boxes of $\tau'$ and $\tau''$ containing the numbers $1,\dots,i$. Let $\lambda'(i)$ and $\lambda''(i)$ be the corresponding sizes and $\mu'(i)$ and $\mu'(i)$ be the corresponding weights of the subtableaux. For each $i$, we obtain a corresponding submatrix $X_i \in \UU^{\mu'(i), \mu''(i)}_{0,s}$ of $X$. These subtableaux impose rank conditions, equivalently vanishing minors, on each $X_i$ when asking them to be in $\OO^{\lambda'(i), \lambda''(i)}_{0,s}$, which allows us to deduce relations on the variables in $X$. The relations must also include the new variables in the latest block and cannot have $s$ as a factor.

To find the MV cycles, equivalently tableaux, in the $0$-fibre of the fusion, we consider the ring generated by all the variables of $X$ and quotient out the ideal generated by the relations from the vanishing minors as well as the minimal polynomial of $X$. We then add $s$ into the ideal. Each piece in the primary decomposition of this ideal will correspond to a tableaux, and subsequently a MV cycle.

% \begin{example}
% Let $G = \GL_3$ and consider the tableaux
% $$\tau' = \young(12,3) \hspace{.5cm} \text{ and } \hspace{.5cm} \tau''=\young(13,2).$$

% Lusztig data: $(010)$ for $\tau'$, $(101)$ for $\tau''$

\acom{If we start with $n_\bullet ' = (0,1,0)$ and $n_\bullet'' = (1,0,1)$ then the smallest $\tau$ for $n_\bullet = (1,1,1)$ is $\young(1123,23)$ and hence the smallest $\mu,\lambda$ are $(2,2,2),(4,2,0)$. So far so good. However, the ``smallest'' ``fission'' of $\tau$ is $\young(112,23) , \young(3)$. We could define ``smallest'' to mean minimizing the dimension of the generalized $s$-eigenspace. What do you guys think? If we agree to do this we should amend this example. For Joel: this is an example where our $B(\infty) \to B(\lambda)$ does not match that of Claxton--Tingley (quoted in my thesis). They would get $\lambda = (3,1)$. I think that their map satisfies $\lambda$ dominant and $\mu$ such that each $\mu_i\ge 1$.}

% Dimensions: $(1,0,-1)$ for both.

% The MV cycles corresponding to $\tau'$ and $\tau''$ are both isomorphic to $\PP^2$.
% The weights are $\lambda' = \lambda'' = (2,1,0)$ and $\mu' = \mu'' = (1,1,1)$. Hence the matrix in consideration is 
% \[
% X = \left[\begin{BMAT}(e){cc;cc;cc}{cc;cc;cc}
%     0 & 1 & & & & \\
%      & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 \\
%      & & 0 & 1 & & \\
%      & & & s & A_{23}^1 & A_{23}^2 \\
%      & & & & 0 & 1 \\
%      & & & & & s
% \end{BMAT}
% \right].
% \]

% For the first entry of $\mu'$ and $\mu''$, we have the following subtableaux to consider:
% $$\young(1) \hspace{.5cm} \text{ and } \hspace{.5cm} \young(1).$$
% Let $X_1$ be the top-left $2 \times 2$ submatrix of $X$. The subtableaux imposes the conditions $\dim \ker X_1 = 1$ and $\dim \ker (X_1-s) = 1$. We see that we do not obtain any relations from this.

% For the first two entries of $\mu'$ and $\mu''$, we have the following subtableaux:
% $$\young(12) \hspace{.5cm} \text{ and } \hspace{.5cm} \young(1,2).$$
% Let $X_2$ be the top-left $4 \times 4$ submatrix of $X$. The left subtableau imposes the conditions $\dim \ker X_2 = 1$ and $\dim \ker X_2^2 = 2$ while the right subtableau imposes the condition that $\dim \ker (X_2 -s) = 2$. These conditions force the relation $$A_{12}^1 + sA_{12}^2 = 0.$$

% The original tableaux for $X$ imposes the conditions that $\dim \ker X = 2$, $\dim \ker X^2 = 3$, $\dim \ker (X-s) = 2$, and $\dim \ker (X-s)^2 = 3$. These force the relation $$A_{23}^1 = 0.$$

% Hence we consider the quotient
% $$\frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{13}^2,A_{23}^1,A_{23}^2,s]}{\langle A_{12}^1+sA_{12}^2,A_{23}^1,s \rangle} \cong
% \frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{13}^2,A_{23}^1,A_{23}^2]}{\langle A_{12}^1,A_{23}^1 \rangle}.$$
% We see already that the $0$-fibre is irreducible. The tableau corresponding to the ideal $\langle A_{12}^1,A_{23}^1 \rangle$ is 
% $$\young(1123,23)$$
% which corresponds to the MV cycle that is the product of the MV cycles corresponding to $\tau'$ and $\tau''$.

% Lusztig datum: $(111)$

% Dimension: $(2,0,-2)$
% \end{example}

\subsection{Type $A_2$}

\begin{example}
Let $G = \GL_3$ and consider the tableaux
$$\tau' = \young(12) \hspace{.5cm} \text{ and } \hspace{.5cm} \tau'' = \young(11,23).$$

Lustig data: $(100)$ for $\tau'$, $(001)$ for $\tau''$.

\acom{This time the smallest $\tau$ is actually $\young(12,3)$ and the smallest fission is $\young(1,3),\young(2)$. For Joel: this time the our $\lambda$ matches \cite{claxton2015young}'s.}

Dimensions: $(1,-1,0)$ for $\tau'$, $(0,1,-1)$ for $\tau''$.

The MV cycles corresponding to the above tableaux are each isomorphic to $\PP^1$.
We have the weights to be $\lambda' = (2,0,0)$, $\lambda'' = (2,2,0)$, $\mu' = (1,1,0)$, and $\mu'' = (2,1,1)$. The matrix under consideration is therefore
\[
X = \left[\begin{BMAT}(e){ccc;cc;c}{ccc;cc;c}
    0 & 1 & & & & \\
     & 0 & 1 & & & \\
     & -s^2 & 2s & A_{12}^1 & A_{12}^2 & A_{13}^1 \\
     & & & 0 & 1 & \\
     & & & & s & A_{23}^1 \\
     & & & & & s
\end{BMAT}
\right].
\]
There are no relations from looking at the submatrix $X_1$. From the submatrix $X_2$, we require $$A_{12}^1 + sA_{12}^2 = 0.$$
From $X$, we further obtain the relations $$A_{12}^2A_{23}^1 + sA_{13}^1 = 0, A_{12}^1A_{23}^1 + s^2A_{13}^1 = 0.$$
Then the quotient ring we find is
$$\frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,s]}{\langle A_{12}^1+sA_{12}^2, A_{12}^2A_{23}^1+sA_{13}^1, A_{12}^1A_{23}^1+s^2A_{13}^1, s\rangle} \cong \frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,b_3,s]}{\langle A_{12}^1, A_{12}^2\rangle \cap \langle A_{12}^1, A_{23}^1 \rangle}.$$
% 
\acom{TODO: put ideals of arithmetic fusion and their tableaux into tables; also divide into 2 sections, $\GL_3$ and $\GL_4$; replace $Z_M$ by $Z(\tau)$ and $Z(\tau)$ by $\tau$; and let's use $A$ for matrices instead of $X$ to be consistent with rising action?}
% 
We see that the 0-fibre is reducible with two components. The tableau corresponding to each ideal is
$$\begin{array}{cccc} \vspace{1mm}
    \young(1113,22) & \text{for } \langle A_{12}^1, A_{12}^2 \rangle & \text{Lusztig: }(101) & \dim = (1,0,-1)\\ 
    \young(1112,23) & \text{for } \langle A_{12}^1, A_{23}^1 \rangle & \text{Lusztig: }(010) & \dim = (1,0,-1).
\end{array}$$
Each of these tableaux corresponds to a MV cycle isomorphic to $\PP^2$ so the generic fibre $\PP^1 \times \PP^1$ degenerates to two copies of $\PP^2$.
\end{example}

\begin{comment}
\begin{example}
Let $G = SL_3$ and consider the following tableaux:
$$\tau' = \young(1122) \hspace{.5cm} \text{ and } \hspace{.5cm} \tau'' = \young(1111,2233).$$

Lusztig data: $(200)$ for $\tau'$, $(002)$ for $\tau''$.

Dimensions: $(2,-2,0)$ for $\tau'$, $(0,2,-2)$ for $\tau''$.

The MV cycles corresponding to these tableaux are each isomorphic to $\PP^1 \times \PP^1$. 
The weights are then $\lambda' = (4,0,0)$, $\lambda'' = (4,4,0)$, $\mu' = (2,2,0)$, and $\mu'' = (4,2,2)$.
Then we are considering the following matrix:
\[
X = \left[\begin{BMAT}(e){cccccc;cccc;cc}{cccccc;cccc;cc}
    0 & 1 & & & & & & & & & & \\
     & 0 & 1 & & & & & & & & & \\
     & & 0 & 1 & & & & & & & & \\
     & & & 0 & 1 & & & & & & & \\
     & & & & 0 & 1 & & & & & & \\
     & & -s^4 & 3s^3 & -6s^2 & 4s & A_{12}^1 & A_{12}^2 & A_{12}^3 & A_{12}^4 & A_{13}^1 & A_{13}^2 \\
     & & & & & & 0 & 1 & & & & \\
     & & & & & & & 0 & 1 & & & \\
     & & & & & & & & 0 & 1 & & \\
     & & & & & & & & -s^2 & 2s & A_{23}^1 & A_{23}^2 \\
     & & & & & & & & & & 0 & 1 \\
     & & & & & & & & & & -s^2 & 2s
\end{BMAT}
\right].
\]
By computer, it can be checked that we obtain the following 3 ideals:
$$
\begin{array}{cl}
    I_1 = & \langle A_{12}^1, A_{12}^2, A_{12}^3, A_{12}^4, s \rangle \\
    I_2 = & \langle A_{12}^1, A_{12}^2, A_{23}^1, A_{23}^2, s \rangle \\
    I_3 = & \langle A_{12}^1, A_{12}^2, (A_{23}^1)^2, A_{12}^4A_{23}^1 + A_{12}^3A_{23}^2, A_{12}^3A_{23}^1, (A_{12}^3)^2, s \rangle.
\end{array}
$$
It can be checked that $I_3$ has multiplicity 2 \rcom{Not sure how to make this precise and how to check it.} so the 0-fibre has 4 components, two of which are the same. The tableau corresponding to each ideal is
$$
\begin{array}{cccc}\vspace{1mm}
    \young(11111133,2222) & \text{for } I_1 & \text{Lusztig: }(202) & \dim = (2,0,-2) \\ \vspace{1mm}
    \young(11111122,2233) & \text{for } I_2 & \text{Lusztig: }(020) & \dim = (2,0,-2) \\ \vspace{1mm}
    \young(11111123,2223) & \text{for } I_3 & \text{Lusztig: }(111) & \dim = (2,0,-2).
\end{array}
$$
The MV cycle for each ideal is isomorphic to $\PP^2 \times \PP^2$.
\end{example}
\end{comment}

\begin{example}
    
    \acom{Here the fission is the smallest if we set out to minimize the dimension of the zero eigenspace. For Joel: this $\lambda(n_\bullet)$ again matches that of \cite{claxton2015young}}

Let $G = \GL_3$. Consider the tableaux
$$\tau' = \young(22) \hspace{.5cm} \text{ and } \hspace{.5cm} \tau'' = \young(11,33).$$
Then the weights are $\lambda' = (2,0,0)$, $\lambda'' = (2,2,0)$, $\mu' = (0,2,0)$, and $\mu'' = (2,0,2)$. Our matrix $X$ is now
\[
X = \left[\begin{BMAT}(e){cc;cc;cc}{cc;cc;cc}
    0 & 1 & & & & \\
    -s^2 & 2s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 \\
     & & 0 & 1 & & \\
     & & & 0 & A_{23}^1 & A_{23}^2 \\
     & & & & 0 & 1 \\
     & & & & -s^2 & 2s
\end{BMAT}
\right].
\]
Using a computer, the ideals we get are
$$
\begin{array}{cl}
    I_1 = & \langle A_{12}^1, A_{12}^2 \rangle \\
    I_2 = & \langle A_{23}^1, A_{23}^2 \rangle \\
    I_3 = & \langle (A_{23}^1)^2, A_{12}^2A_{23}^1 + A_{12}^1A_{23}^2, A_{12}^1A_{23}^1, (A_{12}^1)^2 \rangle. 
\end{array}
$$
The tableaux corresponding to each ideal is
$$
\begin{array}{cc}\vspace{1mm}
    \young(1133,22) & \text{for } I_1 \\ \vspace{1mm}
    \young(1122,33) & \text{for } I_2 \\ \vspace{1mm}
    \young(1123,23) & \text{for } I_3
\end{array}
$$
and the MV cycles corresponding to each are isomorphic to $\PP^2 \times \PP^2$.
\end{example}

\subsection{Type $A_3$}

Let $G = \GL_4$. There is a cluster structure on $\CC[N]$ consisting of 12 cluster variables. We will take the initial cluster $(x_1,\dots,x_6)$, with $x_4,x_5,x_6$ being frozen, coming from the reduced word ${\bf i} = (1,2,3,1,2,1)$. We list the corresponding tableaux, coordinate ring of the generalized orbital variety $X(\tau)$, Lusztig-datum, and cluster variable as a Laurent polynomial in the $x_i$ below:

% \acom{Add dominant version column}
% \jcom{This is a nice table.  But these are the coordinate rings of $ X(\tau)$, not of $ Z(\tau) $.}
% \renewcommand{\arraystretch}{1.5}
\begin{table}[ht!]%[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}c<{$}>{$}l<{$}>{$}l<{$}>{$}c<{$}}
  \begin{tabular}{Q} 
    \tau' & \tau = \text{Dominant }\tau' & \text{Coordinate ring of }X(\tau) & \text{Lusztig-datum} & \text{Cluster variable} \\
    \midrule 
\young(2) & \young(12) & \CC[A_{12}^1] & (1,0,0,0,0,0) & x_1 \rule{0pt}{3ex}\\
\young(1,3) & \young(11,23) & \frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{12}^1,A_{13}^1 \rangle} & (0,0,0,1,0,0) & \frac{x_2 + x_3}{x_1} \TS\BS\\
\young(1,2,4) & \young(11,22,34) & \frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1 \rangle} & (0,0,0,0,0,1) & \frac{x_2x_4 + x_3x_6 + x_1x_5}{x_2x_3} \TS\BS\\
\young(3) & \young(13,2) & \frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{12}^1 \rangle} & (1,0,0,1,0,0) & x_2 \TS\BS\\
\young(2,3) & \young(12,3) & \frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{23}^1 \rangle} & (0,1,0,0,0,0) & x_3 \TS\BS\\
\young(1,4) & \young(11,24,3) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1,A_{34}^1 \rangle} & (0,0,0,1,0,1) & \frac{x_1x_5 + x_6(x_2+x_3)}{x_1x_2} \TS\BS\\
\young(1,3,4) & \young(11,23,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{14}^1,A_{34}^1 \rangle} & (0,0,0,0,1,0) & \frac{x_1x_5 + x_4(x_2+x_3)}{x_1x_3}\TS\BS\\
\young(2,4) & \young(112,24,3) & \frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1 \rangle} & (0,1,0,0,0,1) & \frac{x_3x_6+x_1x_5}{x_2} \TS\BS\\
\young(13,2,4) & \young(13,2,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{34}^1,A_{13}^1A_{24}^1-A_{23}^1A_{14}^1 \rangle} & (1,0,0,0,1,0) & \frac{x_2x_4 + x_1x_5}{x_3} \TS\BS\\
\young(2,3,4) & \young(12,3,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{23}^1,A_{24}^1,A_{34}^1 \rangle} & (0,0,1,0,0,0) & x_4 \TS\BS\\
\young(3,4) & \young(13,24) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{34}^1 \rangle} & (0,1,0,0,1,0) & x_5 \TS\BS\\
\young(4) & \young(14,2,3) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1 \rangle} & (1,0,0,1,0,1) & x_6 \TS\BS\\
  \end{tabular}
\end{table}
\acom{Say what $x_i$ are: $\begin{bmatrix}
    1 & x_1 & x_2 & x_3 \\
    & 1 \\
    & & 1 \\
    & & & 1 
\end{bmatrix}$}

% \[
% \begin{array}{ccc} 
% \tau & \text{Coordinate ring of }X(\tau) & \text{Lusztig-datum} \\ \hline
% \young(2) & \CC[A_{12}^1] & (1,0,0,0,0,0) \rule{0pt}{3ex}\\
% \young(1,3) & \frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{12}^1,A_{13}^1 \rangle} & (0,0,0,1,0,0) \TS\BS\\
% \young(1,2,4) & \frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1 \rangle} & (0,0,0,0,0,1) \TS\BS\\
% \young(3) & \frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{12}^1 \rangle} & (1,0,0,1,0,0) \TS\BS\\
% \young(2,3) & \frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{23}^1 \rangle} & (0,1,0,0,0,0) \TS\BS\\
% \young(1,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1,A_{34}^1 \rangle} & (0,0,0,1,0,1) \TS\BS\\
% \young(1,3,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{14}^1,A_{34}^1 \rangle} & (0,0,0,0,1,0) \TS\BS\\
% \young(2,4) & \frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1 \rangle} & (0,1,0,0,0,1) \TS\BS\\
% \young(13,2,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{34}^1,A_{13}^1A_{24}^1-A_{23}^1A_{14}^1 \rangle} & (1,0,0,0,1,0) \TS\BS\\
% \young(2,3,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{23}^1,A_{24}^1,A_{34}^1 \rangle} & (0,0,1,0,0,0) \TS\BS\\
% \young(3,4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{34}^1 \rangle} & (0,1,0,0,1,0) \TS\BS\\
% \young(4) & \frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1 \rangle} & (1,0,0,1,0,1) \TS\BS\\
% \end{array}
% \]

% \begin{table}[]
% \centering
% \begin{tabular}{l|c|c}
% $\tau$ & Coordinate ring of $Z(\tau)$ & Lusztig-datum \\ \hline
% \young(2) & $\CC[A_{12}^1]$ & (1,0,0,0,0,0) \\
% \young(1,3) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{12}^1,A_{13}^1 \rangle}$ & (0,0,0,1,0,0) \\
% \young(1,2,4) & $\frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1 \rangle}$ & (0,0,0,0,0,1) \\
% \young(3) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{12}^1 \rangle}$ & (1,0,0,1,0,0) \\
% \young(2,3) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{23}^1]}{\langle A_{23}^1 \rangle}$ & (0,1,0,0,0,0) \\
% \young(1,4) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1,A_{34}^1 \rangle}$ & (0,0,0,1,0,1) \\
% \young(1,3,4) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{14}^1,A_{34}^1 \rangle}$ & (0,0,0,0,1,0) \\
% \young(2,4) & $\frac{\CC[A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1 \rangle}$ & (0,1,0,0,0,1) \\
% \young(13,2,4) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{34}^1,A_{13}^1A_{24}^1-A_{23}^1A_{14}^1 \rangle}$ & (1,0,0,0,1,0) \\
% \young(2,3,4) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{23}^1,A_{24}^1,A_{34}^1 \rangle}$ & (0,0,1,0,0,0) \\
% \young(3,4) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{34}^1 \rangle}$ & (0,1,0,0,1,0) \\
% \young(4) & $\frac{\CC[A_{12}^1,A_{13}^1,A_{14}^1,A_{23}^1,A_{24}^1,A_{34}^1]}{\langle A_{12}^1,A_{13}^1,A_{23}^1 \rangle}$ & (1,0,0,1,0,1) \\
% \end{tabular}
% \end{table}

% \[\begin{array}{cccccc} \vspace{1mm}
%     Z_1 &\leadsto \young(2) & Z_2 &\leadsto \young(1,3) & Z_3 &\leadsto \young(1,2,4) \\ \vspace{1mm}
%     Z_{1 \leftarrow 2} &\leadsto \young(3) & Z_{1 \rightarrow 2} &\leadsto \young(2,3) & Z_{2 \leftarrow 3} &\leadsto \young(1,4) \\ \vspace{1mm}
%      Z_{2 \rightarrow 3} &\leadsto \young(1,3,4) & Z_{in} &\leadsto \young(2,4) & Z_{out} &\leadsto \young(13,2,4)  \\
%     Z_{P_1} &\leadsto \young(2,3,4) & Z_{P_2} &\leadsto \young(3,4) & Z_{P_3} &\leadsto \young(4)
% \end{array}\]

We show that the cluster relations in $\CC[N]$ are also true for the fusion product of the corresponding MV cycles.

For each of the 15 exchange relations, we state the associated matrix $X$, the relations acquired from each submatrix $X_i$, the ideal generated by said relations, and the corresponding tableaux from the ideal.

Instead of writing the exchange relations in terms of $b_{Z(\tau)}$ or the fusion product in terms of $Z(\tau)$, we will use $\tau$ for both situations.

\jcom{I think that you should clarify what you mean by ``our ideal'' below.  I think that it is the ideal of $ X(\tau', \tau'')_{0,0}$, is that correct?}

\begin{example}
% Consider the product $Z_1 * Z_2$, so the tableaux are
% Consider the product % $Z({{\scriptsize\young(2)}})*Z({\scriptsize\young(1,3)})$
% \[
% \young(2) \text{ and } \young(1,3).
% \]
% $\young(2) * \young(1,3)$.
$\young(2) \cdot \young(1,3) = \young(3) + \young(2,3)$: 
% 
The requirement that 
\[
X = \left[\begin{BMAT}(e){c;c;c}{c;c;c}
    s & A_{12}^1 & A_{13}^1 \\
     & 0 & A_{23}^1 \\
     & & s
\end{BMAT}
\right] \text{ is contained in } \young(2) *_{\AA \setminus \{0\}} \young(1,3) 
% \Rightarrow 
% \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_3 & A_{12}^1A_{23}^1+sA_{13}^1
% \end{tabular}
\]
results in the following relations on submatrices. 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_3 & A_{12}^1A_{23}^1+sA_{13}^1
    \end{tabular}
\end{table}
% \[
% \begin{array}{c|c}
%     \text{Submatrix} & \text{Relations} \\ \hline
%     X_3 & A_{12}^1A_{23}^1+sA_{13}^1
% \end{array}.
% \]
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,s) & \young(13,2) \BS \\ % \equiv \young(3) \\
    ( A_{23}^1,s) & \young(12,3) \TS % \equiv \young(2,3)
    \end{tabular}
\end{table}
% $$\langle A_{12}^1A_{23}^1+sA_{13}^1,s \rangle = 
% \langle A_{12}^1,s \rangle \cap \langle A_{23}^1,s \rangle.$$
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,s \rangle &\leadsto \young(13,2) &\equiv \young(3) &\leadsto {Z_{1 \leftarrow 2}} \\ 
%     \langle A_{23}^1,s \rangle &\leadsto \young(12,3) &\equiv \young(2,3) &\leadsto{Z_{1 \rightarrow 2}}
% \end{array}
% \]
% so $Z_1 * Z_2 = Z_{1 \leftarrow 2} + Z_{1 \rightarrow 2}$.
% \noindent so $\young(2) * \young(1,3) = \young(3) + \young(2,3)$.
\end{example}

\begin{example}
% Consider the product $Z_2 * Z_3$, so the tableaux are 
% \[
% \young(1,3) \text{ and } \young(1,2,4).
% \]
% Our matrix is 
$\young(1,3) \cdot \young(1,2,4) = \young(1,4) + \young(1,3,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;c;c;c}{cc;c;c;c}
    0 & 1 & & & \\
     & s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
     & & s & A_{23}^1 & A_{24}^1 \\
     & & & 0 & A_{34}^1 \\
     & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(1,3) *_{\AA \setminus \{0\}} \young(1,2,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 \\
    X_3 & A_{13}^1 \\
    X_4 & A_{14}^1, A_{23}^1A_{34}^1 + sA_{24}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{13}^1,A_{23}^1,A_{14}^1,s) & \young(11,24,3) \BS \\
    (A_{12}^1,A_{13}^1,A_{14}^1,A_{34}^1,s) & \young(11,23,4) \TS 
    \end{tabular}
\end{table}
% \[
% \begin{array}{c|c}
%     \text{Submatrix} & \text{Relations} \\ \hline
%     X_2 & A_{12}^1 \\
%     X_3 & A_{13}^1 \\
%     X_4 & A_{14}^1, A_{23}^1A_{34}^1 + sA_{24}^1
% \end{array}.
% \]
% 
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{14}^1,s \rangle \cap \langle A_{12}^1,A_{13}^1,A_{14}^1,A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{14}^1,s \rangle &\leadsto \young(11,24,3) &\equiv \young(1,4) &\leadsto Z_{2 \leftarrow 3} \\ 
%     \langle A_{12}^1,A_{13}^1,A_{14}^1,A_{34}^1,s \rangle &\leadsto \young(11,23,4) &\equiv \young(1,3,4) &\leadsto Z_{2 \rightarrow 3}
% \end{array}
% \]
% so $Z_2 * Z_3 = Z_{2 \leftarrow 3} + Z_{2 \rightarrow 3}$.
\end{example}

\begin{example}
$\young(2) \cdot \young(1,3,4) = \young(2,3,4) + \young(13,2,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
    s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
     & 0 & A_{23}^1 & A_{24}^1 \\
     & & s & A_{34}^1 \\
     & & & s
\end{BMAT}
\right] \text{ is contained in } \young(2) *_{\AA \setminus \{0\}} \young(1,3,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_3 & A_{12}^1A_{23}^1 + sA_{13}^1 \\
    X_4 & A_{34}^1, A_{12}^1A_{24}^1 + sA_{14}^1, A_{23}^1A_{14}^1 - A_{13}^1A_{24}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{23}^1,A_{24}^1,A_{34}^1,s) & \young(12,3,4) \BS \\
    (A_{12}^1,A_{34}^1,A_{23}^1A_{14}^1 - A_{13}^1A_{24}^1,s) & \young(13,2,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_1 * Z_{2 \rightarrow 3}$, so the tableaux are 
% \[
% \young(2) \text{ and } \young(1,3,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
%     s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
%      & 0 & A_{23}^1 & A_{24}^1 \\
%      & & s & A_{34}^1 \\
%      & & & s
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_3 & A_{12}^1A_{23}^1 + sA_{13}^1 \\
%     X_4 & A_{34}^1, A_{12}^1A_{24}^1 + sA_{14}^1, A_{23}^1A_{14}^1 - A_{13}^1A_{24}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_3 & A_{12}^1A_{23}^1 + sA_{13}^1 \\
% %     X_4 & A_{34}^1, A_{12}^1A_{24}^1 + sA_{14}^1, A_{23}^1A_{14}^1 - A_{13}^1A_{24}^1
% % \end{array}.
% % \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{23}^1,A_{24}^1,A_{34}^1,s \rangle \cap \langle A_{12}^1,A_{34}^1,A_{23}^1A_{14}^1 - A_{13}^1A_{24}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{23}^1,A_{24}^1,A_{34}^1,s \rangle &\leadsto \young(12,3,4) &\equiv \young(2,3,4) &\leadsto Z_{P_1} \\ 
%     \langle A_{12}^1,A_{34}^1,A_{23}^1A_{14}^1 - A_{13}^1A_{24}^1,s \rangle &\leadsto \young(13,2,4) & &\leadsto Z_{out}
% \end{array}
% \]
% so $Z_1 * Z_{2 \rightarrow 3} = Z_{P_1} + Z_{out}$.
\end{example}

\begin{example}
$\young(2) \cdot \young(11,24,3) = \young(4) + \young(2,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;cc;c;c}{cc;cc;c;c}
    0 & 1 & & & & \\
    -s^2 & 2s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{14}^1 \\
     & & 0 & 1 & & \\
     & & & s & A_{23}^1 & A_{24}^1 \\
     & & & & s & A_{34}^1 \\
     & & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(2) *_{\AA \setminus \{0\}} \young(11,24,3)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 + sA_{12}^2 \\
    X_3 & A_{13}^1, A_{23}^1 \\
    X_4 & A_{12}^2A_{24}^1 + sA_{14}^1, A_{12}^1A_{24}^1 - s^2A_{14}^1 
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,s) & \young(114,22,3) \BS \\
    (A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1,s) & \young(112,24,3) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_1 * Z_{2 \leftarrow 3}$, so the tableaux are 
% \[
% \young(2) \text{ and } \young(1,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(2) \text{ and } \young(11,24,3).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){cc;cc;c;c}{cc;cc;c;c}
%     0 & 1 & & & & \\
%     -s^2 & 2s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{14}^1 \\
%      & & 0 & 1 & & \\
%      & & & s & A_{23}^1 & A_{24}^1 \\
%      & & & & s & A_{34}^1 \\
%      & & & & & s
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1 + sA_{12}^2 \\
%     X_3 & A_{13}^1, A_{23}^1 \\
%     X_4 & A_{12}^2A_{24}^1 + sA_{14}^1, A_{12}^1A_{24}^1 - s^2A_{14}^1 
%     \end{tabular}
% \end{table}
% \[
% \begin{array}{c|c}
%     \text{Submatrix} & \text{Relations} \\ \hline
%     X_2 & A_{12}^1 + sA_{12}^2 \\
%     X_3 & A_{13}^1, A_{23}^1 \\
%     X_4 & A_{12}^2A_{24}^1 + sA_{14}^1, A_{12}^1A_{24}^1 - s^2A_{14}^1 
% \end{array}.
% \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,s \rangle \cap \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,s \rangle &\leadsto \young(114,22,3) &\equiv \young(4) &\leadsto Z_{P_3} \\ 
%     \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1,s \rangle &\leadsto \young(112,24,3) &\equiv \young(2,4) &\leadsto Z_{in}
% \end{array}
% \]
% so $Z_1 * Z_{2 \leftarrow 3} = Z_{P_3} + Z_{in}$.
\end{example}

\begin{example}
$\young(1,2,4) \cdot \young(12,3) = \young(1,4) + \young(1,3,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;cc;c;c}{cc;cc;c;c}
    0 & 1 & & & & \\
     & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{14}^1 \\
     & & 0 & 1 & & \\
     & & & s & A_{23}^1 & A_{24}^1 \\
     & & & & s & A_{34}^1 \\
     & & & & & 0
\end{BMAT}
\right] \text{ is contained in } \young(1,2,4) *_{\AA \setminus \{0\}} \young(12,3)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 \\
    X_3 & A_{23}^1 \\
    X_4 & A_{24}^1, A_{13}^1A_{34}^1 - sA_{14}^1 
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1,s) & \young(112,24,3) \BS \\
    (A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,s) & \young(112,23,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_3 * Z_{1 \rightarrow 2}$, so the tableaux are 
% \[
% \young(1,2,4) \text{ and } \young(2,3).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(1,2,4) \text{ and } \young(12,3).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){cc;cc;c;c}{cc;cc;c;c}
%     0 & 1 & & & & \\
%      & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{14}^1 \\
%      & & 0 & 1 & & \\
%      & & & s & A_{23}^1 & A_{24}^1 \\
%      & & & & s & A_{34}^1 \\
%      & & & & & 0
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1 \\
%     X_3 & A_{23}^1 \\
%     X_4 & A_{24}^1, A_{13}^1A_{34}^1 - sA_{14}^1 
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1 \\
% %     X_3 & A_{23}^1 \\
% %     X_4 & A_{24}^1, A_{13}^1A_{34}^1 - sA_{14}^1 
% % \end{array}.
% % \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1,s \rangle \cap \langle A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{24}^1,s \rangle &\leadsto \young(112,24,3) &\equiv \young(1,4) &\leadsto Z_{in} \\ 
%     \langle A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,s \rangle &\leadsto \young(112,23,4) &\equiv \young(1,3,4) &\leadsto Z_{P_1}
% \end{array}
% \]
% so $Z_3 * Z_{1 \rightarrow 2} = Z_{in} + Z_{P_1}$.
\end{example}

\begin{example}
$\young(1,2,4) \cdot \young(3) = \young(4) + \young(13,2,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
    0 & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
     & 0 & A_{23}^1 & A_{24}^1 \\
     & & s & A_{34}^1 \\
     & & & 0
\end{BMAT}
\right] \text{ is contained in } \young(1,2,4) *_{\AA \setminus \{0\}} \young(3)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 \\
    X_4 & A_{23}^1A_{34}^1 - sA_{24}^1, A_{13}^1A_{34}^1 - sA_{14}^1, A_{13}^1A_{24}^1 - A_{23}^1A_{14}^1 
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{13}^1,A_{23}^1,s) & \young(14,2,3) \BS \\
    (A_{12}^1,A_{34}^1,A_{13}^1A_{24}^1-A_{23}^1A_{14}^1,s) & \young(13,2,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_3 * Z_{1 \leftarrow 2}$, so the tableaux are 
% \[
% \young(1,2,4) \text{ and } \young(3).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
%     0 & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
%      & 0 & A_{23}^1 & A_{24}^1 \\
%      & & s & A_{34}^1 \\
%      & & & 0
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1 \\
%     X_4 & A_{23}^1A_{34}^1 - sA_{24}^1, A_{13}^1A_{34}^1 - sA_{14}^1, A_{13}^1A_{24}^1 - A_{23}^1A_{14}^1 
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1 \\
% %     X_4 & A_{23}^1A_{34}^1 - sA_{24}^1, A_{13}^1A_{34}^1 - sA_{14}^1, A_{13}^1A_{24}^1 - A_{23}^1A_{14}^1 
% % \end{array}.
% % \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{13}^1,A_{23}^1,s \rangle \cap \langle A_{12}^1,A_{34}^1,A_{13}^1A_{24}^1-A_{23}^1A_{14}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{13}^1,A_{23}^1,s \rangle &\leadsto \young(14,2,3) &\equiv \young(4) &\leadsto Z_{P_3} \\ 
%     \langle A_{12}^1,A_{34}^1,A_{13}^1A_{24}^1-A_{23}^1A_{14}^1,s \rangle &\leadsto \young(13,2,4) & &\leadsto Z_{out}
% \end{array}
% \]
% so $Z_3 * Z_{1 \leftarrow 2} = Z_{P_3} + Z_{out}$.
\end{example}

\begin{example}
$\young(13,2) \cdot \young(1,4) = \young(14,3) + \young(3,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;c;c;c}{cc;c;c;c}
    0 & 1 & & & \\
     & s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
     & & 0 & A_{23}^1 & A_{24}^1 \\
     & & & 0 & A_{34}^1 \\
     & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(13,2) *_{\AA \setminus \{0\}} \young(1,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 \\
    X_4 & A_{13}^1A_{34}^1 + sA_{14}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{13}^1,s) & \young(114,23) \BS \\
    (A_{12}^1,A_{34}^1,s) & \young(113,24) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{1 \leftarrow 2} * Z_{2 \leftarrow 3}$, so the tableaux are 
% \[
% \young(3) \text{ and } \young(1,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(13,2) \text{ and } \young(1,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){cc;c;c;c}{cc;c;c;c}
%     0 & 1 & & & \\
%      & s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
%      & & 0 & A_{23}^1 & A_{24}^1 \\
%      & & & 0 & A_{34}^1 \\
%      & & & & s
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1 \\
%     X_4 & A_{13}^1A_{34}^1 + sA_{14}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1 \\
% %     X_4 & A_{13}^1A_{34}^1 + sA_{14}^1
% % \end{array}.
% % \]
% \noindent Hence, our ideal is 
% \[
% \langle A_{12}^1,A_{13}^1A_{34}^1+sA_{14}^1,s \rangle
% = \langle A_{12}^1,A_{13}^1,s \rangle \cap \langle A_{12}^1,A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{13}^1,s \rangle &\leadsto \young(114,23) &\equiv \young(14,3) &\leadsto Z_2 Z_{P_3} \\ 
%     \langle A_{12}^1,A_{34}^1,s \rangle &\leadsto \young(113,24) &\equiv \young(3,4) &\leadsto Z_{P_2}
% \end{array}
% \]
% so $Z_{1 \leftarrow 2} * Z_{2 \leftarrow 3} = Z_2 Z_{P_3} + Z_{P_2}$.
\end{example}

\begin{example}
$\young(12,23) \cdot \young(1,3,4) = \young(3,4) + \young(12,33,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;cc;cc;c}{cc;cc;cc;c}
    0 & 1 & & & & & \\
     & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 \\
     & & 0 & 1 & & & \\
     & & & 0 & A_{23}^1 & A_{23}^2 & A_{24}^1 \\
     & & & & 0 & 1 & \\
     & & & & & s & A_{34}^1 \\
     & & & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(12,23) *_{\AA \setminus \{0\}} \young(1,3,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 \\
    X_3 & A_{23}^1, A_{12}^2A_{23}^2 + A_{13}^1 + sA_{13}^2 \\
    X_4 & A_{34}^1, A_{12}^2A_{24}^1 + sA_{14}^1, sA_{23}^2A_{14}^1 - sA_{13}^2A_{24}^1 - A_{13}^1A_{24}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,s) & \young(113,224,3) \BS \\
    (A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,A_{12}^2A_{23}^2+A_{13}^1,s) & \young(112,233,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{1 \rightarrow 2} * Z_{2 \rightarrow 3}$, so the tableaux are 
% \[
% \young(2,3) \text{ and } \young(1,3,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(12,23) \text{ and } \young(1,3,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){cc;cc;cc;c}{cc;cc;cc;c}
%     0 & 1 & & & & & \\
%      & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 \\
%      & & 0 & 1 & & & \\
%      & & & 0 & A_{23}^1 & A_{23}^2 & A_{24}^1 \\
%      & & & & 0 & 1 & \\
%      & & & & & s & A_{34}^1 \\
%      & & & & & & s
% \end{BMAT}
% \right].
% \]
% % 
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1 \\
%     X_3 & A_{23}^1, A_{12}^2A_{23}^2 + A_{13}^1 + sA_{13}^2 \\
%     X_4 & A_{34}^1, A_{12}^2A_{24}^1 + sA_{14}^1, sA_{23}^2A_{14}^1 - sA_{13}^2A_{24}^1 - A_{13}^1A_{24}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1 \\
% %     X_3 & A_{23}^1, A_{12}^2A_{23}^2 + A_{13}^1 + sA_{13}^2 \\
% %     X_4 & A_{34}^1, A_{12}^2A_{24}^1 + sA_{14}^1, sA_{23}^2A_{14}^1 - sA_{13}^2A_{24}^1 - A_{13}^1A_{24}^1
% % \end{array}.
% % \]
% % 
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,s \rangle \cap \langle A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,A_{12}^2A_{23}^2+A_{13}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,s \rangle &\leadsto \young(113,224,3) &\equiv \young(3,4) &\leadsto Z_{P_2} \\ 
%     \langle A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,A_{12}^2A_{23}^2+A_{13}^1,s \rangle &\leadsto \young(112,233,4) &\equiv \young(12,33,4) &\leadsto Z_2 Z_{P_1}
% \end{array}
% \]
% so $Z_{1 \rightarrow 2} * Z_{2 \rightarrow 3} = Z_{P_2} + Z_2 Z_{P_1}$.
\end{example}

\begin{example}
$\young(11,23) \cdot \young(13,2,4) = \young(3,4) + \young(1,3,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){ccc;cc;cc;c}{ccc;cc;cc;c}
    0 & 1 & & & & & & \\
     & 0 & 1 & & & & & \\
     & & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 \\
     & & & 0 & 1 & & & \\
     & & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 \\
     & & & & & 0 & 1 & \\
     & & & & & & s & A_{34}^1 \\
     & & & & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(11,23) *_{\AA \setminus \{0\}} \young(13,2,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1, A_{12}^2 \\
    X_3 & A_{13}^1 \\
    X_4 & A_{34}^1, A_{23}^1A_{14}^1 + s(A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1) 
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,s) & \young(1113,224,3) \BS \\
    (A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{34}^1,s) & \young(1113,223,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_2 * Z_{out}$, so the tableaux are 
% \[
% \young(1,3) \text{ and } \young(13,2,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(11,23) \text{ and } \young(13,2,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){ccc;cc;cc;c}{ccc;cc;cc;c}
%     0 & 1 & & & & & & \\
%      & 0 & 1 & & & & & \\
%      & & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 \\
%      & & & 0 & 1 & & & \\
%      & & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 \\
%      & & & & & 0 & 1 & \\
%      & & & & & & s & A_{34}^1 \\
%      & & & & & & & s
% \end{BMAT}
% \right]
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1, A_{12}^2 \\
%     X_3 & A_{13}^1 \\
%     X_4 & A_{34}^1, A_{23}^1A_{14}^1 + s(A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1) 
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1, A_{12}^2 \\
% %     X_3 & A_{13}^1 \\
% %     X_4 & A_{34}^1, A_{23}^1A_{14}^1 + s(A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1) 
% % \end{array}.
% % \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,s \rangle \cap \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,s \rangle &\leadsto \young(1113,224,3) &\equiv \young(3,4) &\leadsto Z_{P_2} \\ 
%     \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{14}^1,A_{34}^1,s \rangle &\leadsto \young(1113,223,4) &\equiv \young(1,3,4) &\leadsto Z_{1 \leftarrow 2} Z_{2 \rightarrow 3}
% \end{array}
% \]
% so $Z_2 * Z_{out} = Z_{P_2} + Z_{1 \leftarrow 2} Z_{2 \rightarrow 3}$.
\end{example}

\begin{example}
$\young(1,3) \cdot \young(2,4) = \young(3,4) + \young(12,34):$ The requirement that
\[
X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
    0 & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
     & s & A_{23}^1 & A_{24}^1 \\
     & & 0 & A_{34}^1 \\
     & & & s
\end{BMAT}
\right] \text{ is contained in } \young(1,3) *_{\AA \setminus \{0\}} \young(2,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_3 & A_{12}^1A_{23}^1 - sA_{13}^1 \\
    X_4 & A_{23}^1A_{34}^1 + sA_{24}^1, A_{12}^1A_{24}^1 + A_{13}^1A_{34}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{34}^1,s) & \young(13,24) \BS \\
    (A_{23}^1,A_{12}^1A_{24}^1 + A_{13}^1A_{34}^1,s) & \young(12,34) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_2 * Z_{in}$, so the tableaux are 
% \[
% \young(1,3) \text{ and } \young(2,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
%     0 & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
%      & s & A_{23}^1 & A_{24}^1 \\
%      & & 0 & A_{34}^1 \\
%      & & & s
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_3 & A_{12}^1A_{23}^1 - sA_{13}^1 \\
%     X_4 & A_{23}^1A_{34}^1 + sA_{24}^1, A_{12}^1A_{24}^1 + A_{13}^1A_{34}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_3 & A_{12}^1A_{23}^1 - sA_{13}^1 \\
% %     X_4 & A_{23}^1A_{34}^1 + sA_{24}^1, A_{12}^1A_{24}^1 + A_{13}^1A_{34}^1
% % \end{array}.
% % \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{34}^1,s \rangle \cap \langle A_{23}^1,A_{12}^1A_{24}^1 + A_{13}^1A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{34}^1,s \rangle &\leadsto \young(13,24) &\equiv \young(3,4) &\leadsto Z_{P_2} \\ 
%     \langle A_{23}^1,A_{12}^1A_{24}^1 + A_{13}^1A_{34}^1,s \rangle &\leadsto \young(12,34) & &\leadsto Z_{1 \rightarrow 2} Z_{2 \leftarrow 3}
% \end{array}
% \]
% so $Z_2 * Z_{in} = Z_{P_2} + Z_{1 \rightarrow 2} Z_{2 \leftarrow 3}$.
\end{example}

\begin{example}
$\young(13,2,4) \cdot \young(12,3) = \young(23,4) + \young(23,3,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;cc;cc;c}{cc;cc;cc;c}
    0 & 1 & & & & & \\
     & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 \\
     & & 0 & 1 & & & \\
     & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 \\
     & & & & 0 & 1 & \\
     & & & & & s & A_{34}^1 \\
     & & & & & & 0
\end{BMAT}
\right] \text{ is contained in } \young(13,2,4) *_{\AA \setminus \{0\}} \young(12,3)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1 \\
    X_3 & A_{23}^1 +sA_{23}^2 \\
    X_4 & A_{34}^1, A_{13}^1A_{24}^1 - A_{23}^1A_{14}^1 
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{13}^1,A_{23}^1,A_{34}^1,s) & \young(1123,24,3) \BS \\
    (A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,s) & \young(1123,23,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{out} * Z_{1 \rightarrow 2}$, so the tableaux are 
% \[
% \young(13,2,4) \text{ and } \young(2,3).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(13,2,4) \text{ and } \young(12,3).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){cc;cc;cc;c}{cc;cc;cc;c}
%     0 & 1 & & & & & \\
%      & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 \\
%      & & 0 & 1 & & & \\
%      & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 \\
%      & & & & 0 & 1 & \\
%      & & & & & s & A_{34}^1 \\
%      & & & & & & 0
% \end{BMAT}
% \right]
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1 \\
%     X_3 & A_{23}^1 +sA_{23}^2 \\
%     X_4 & A_{34}^1, A_{13}^1A_{24}^1 - A_{23}^1A_{14}^1 
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1 \\
% %     X_3 & A_{23}^1 +sA_{23}^2 \\
% %     X_4 & A_{34}^1, A_{13}^1A_{24}^1 - A_{23}^1A_{14}^1 
% % \end{array}.
% % \]
% \noindent Hence, our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{34}^1,s \rangle \cap \langle A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{13}^1,A_{23}^1,A_{34}^1,s \rangle &\leadsto \young(1112,24,3) &\equiv \young(23,4) &\leadsto Z_1 Z_{P_2} \\ 
%     \langle A_{12}^1,A_{23}^1,A_{24}^1,A_{34}^1,s \rangle &\leadsto \young(1123,23,4) &\equiv \young(23,3,4) &\leadsto Z_{1 \leftarrow 2} Z_{P_1}
% \end{array}
% \]
% so $Z_{out} * Z_{1 \rightarrow 2} = Z_1 Z_{P_2} + Z_{1 \leftarrow 2} Z_{P_1}$.
\end{example}

\begin{example}
$\young(2,4) \cdot \young(1,3) = \young(24,3) + \young(23,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
     s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
     & 0 & A_{23}^1 & A_{24}^1 \\
     & & s & A_{34}^1 \\
     & & & 0
\end{BMAT}
\right] \text{ is contained in } \young(2,4) *_{\AA \setminus \{0\}} \young(1,3)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
     X_4 & A_{23}^1A_{34}^1 - sA_{24}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{23}^1,s) & \young(124,3) \BS \\
    (A_{34}^1,s) & \young(123,4) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{in} * Z_{1 \leftarrow 2}$, so the tableaux are
% \[
% \young(2,4) \text{ and } \young(3).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(2,4) \text{ and } \young(13).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){c;c;c;c}{c;c;c;c}
%      s & A_{12}^1 & A_{13}^1 & A_{14}^1 \\
%      & 0 & A_{23}^1 & A_{24}^1 \\
%      & & s & A_{34}^1 \\
%      & & & 0
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%      X_4 & A_{23}^1A_{34}^1 - sA_{24}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_4 & A_{23}^1A_{34}^1 - sA_{24}^1
% % \end{array}.
% % \]
% \noindent Hence, our ideal is 
% \[
% \langle A_{23}^1A_{34}^1 - sA_{24}^1,s \rangle
% = \langle A_{23}^1,s \rangle \cap \langle A_{34}^1,s \rangle.
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{23}^1,s \rangle &\leadsto \young(124,3) &\equiv \young(24,3) &\leadsto Z_{1 \rightarrow 2} Z_{P_3} \\ 
%     \langle A_{34}^1,s \rangle &\leadsto \young(123,4) &\equiv \young(23,4) &\leadsto Z_1 Z_{P_2}
% \end{array}
% \]
% so $Z_{in} * Z_{1 \leftarrow 2} = Z_{1 \rightarrow 2} Z_{P_3} + Z_1 Z_{P_2}$.
\end{example}

\begin{example}
$\young(11,24,3) \cdot \young(13,2,4) = \young(14,3,4) + \young(13,24,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){ccc;cc;cc;cc}{ccc;cc;cc;cc}
    0 & 1 & & & & & & & \\
     & 0 & 1 & & & & & & \\
     & & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 & A_{14}^2 \\
     & & & 0 & 1 & & & & \\
     & & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 & A_{24}^2 \\
     & & & & & 0 & 1 & & \\
     & & & & & & s & A_{34}^1 & A_{34}^2 \\
     & & & & & & & 0 & 1 \\
     & & & & & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(11,24,3) *_{\AA \setminus \{0\}} \young(13,2,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
    X_2 & A_{12}^1,A_{12}^2 \\
    X_3 & A_{13}^1, A_{23}^1 \\
    X_4 & A_{13}^2A_{34}^1 - sA_{14}^1, A_{34}^1 + sA_{34}^2, A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1 + s(A_{13}^2A_{24}^2 - A_{23}^2A_{14}^2), \\ 
        & A_{14}^2A_{23}^2A_{34}^1 - A_{14}^1A_{23}^2A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^1A_{24}^2 
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1,A_{12}^2,A_{13}^1,A_{13}^2,A_{23}^1,A_{14}^1,A_{34}^1,s) & \young(1114,223,34) \BS \\
    \begin{array}{c}
     (A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,A_{23}^2A_{34}^2 + A_{24}^1,  \\
     A_{13}^2A_{34}^2+A_{14}^1,A_{13}^2A_{24}^1-A_{23}^2A_{14}^1,s) 
\end{array}& \young(1113,224,34) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{out} * Z_{2 \leftarrow 3}$, so the tableaux are 
% \[
% \young(1,4) \text{ and } \young(13,2,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(11,24,3) \text{ and } \young(13,2,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){ccc;cc;cc;cc}{ccc;cc;cc;cc}
%     0 & 1 & & & & & & & \\
%      & 0 & 1 & & & & & & \\
%      & & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 & A_{14}^2 \\
%      & & & 0 & 1 & & & & \\
%      & & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 & A_{24}^2 \\
%      & & & & & 0 & 1 & & \\
%      & & & & & & s & A_{34}^1 & A_{34}^2 \\
%      & & & & & & & 0 & 1 \\
%      & & & & & & & & s
% \end{BMAT}
% \right]
% \]
% The relations from the submatrices are:
% % 
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%     X_2 & A_{12}^1,A_{12}^2 \\
%     X_3 & A_{13}^1, A_{23}^1 \\
%     X_4 & A_{13}^2A_{34}^1 - sA_{14}^1, A_{34}^1 + sA_{34}^2, A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1 + s(A_{13}^2A_{24}^2 - A_{23}^2A_{14}^2), \\ 
%         & A_{14}^2A_{23}^2A_{34}^1 - A_{14}^1A_{23}^2A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^1A_{24}^2 
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1,A_{12}^2 \\
% %     X_3 & A_{13}^1, A_{23}^1 \\
% %     X_4 & \begin{array}{c}
% %          A_{13}^2A_{34}^1 - sA_{14}^1, A_{34}^1 + sA_{34}^2, A_{13}^2A_{34}^2 + A_{14}^1,  \\
% %          A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1 + s(A_{13}^2A_{24}^2 - A_{23}^2A_{14}^2), \\ 
% %          A_{14}^2A_{23}^2A_{34}^1 - A_{14}^1A_{23}^2A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^1A_{24}^2
% %     \end{array}
% % \end{array}.
% % \]
% Hence our ideal decomposes into 
% \[
% \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{13}^2,A_{23}^1,A_{14}^1,A_{34}^1,s \rangle \cap \begin{array}{c}
%      \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,A_{23}^2A_{34}^2 + A_{24}^1,  \\
%      A_{13}^2A_{34}^2+A_{14}^1,A_{13}^2A_{24}^1-A_{23}^2A_{14}^1,s \rangle. 
% \end{array}
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{13}^2,A_{23}^1,A_{14}^1,A_{34}^1,s \rangle &\leadsto \young(1114,223,34) &\equiv \young(14,3,4) &\leadsto Z_{2 \rightarrow 3} Z_{P_3} \\ 
%     \begin{array}{c}
%      \langle A_{12}^1,A_{12}^2,A_{13}^1,A_{23}^1,A_{34}^1,A_{23}^2A_{34}^2 + A_{24}^1,  \\
%      A_{13}^2A_{34}^2+A_{14}^1,A_{13}^2A_{24}^1-A_{23}^2A_{14}^1,s \rangle. 
% \end{array}&\leadsto \young(1113,224,34) &\equiv \young(13,24,4) &\leadsto Z_3 Z_{P_2}
% \end{array}
% \]
% so $Z_{out} * Z_{2 \leftarrow 3} = Z_{2 \rightarrow 3} Z_{P_3} + Z_3 Z_{P_2}$.
\end{example}

\begin{example}
$\young(12,24,3) \cdot \young(1,3,4) = \young(13,24,4) + \young(12,34,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){cc;cc;cc;cc}{cc;cc;cc;cc}
    0 & 1 & & & & & & \\
     & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 & A_{14}^2 \\
     & & 0 & 1 & & & & \\
     & & & 0 & A_{23}^1 & A_{23}^2 & A_{24}^1 & A_{24}^2 \\
     & & & & 0 & 1 & & \\
     & & & & & s & A_{34}^1 & A_{34}^2 \\
     & & & & & & 0 & 1 \\
     & & & & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(12,24,3) *_{\AA \setminus \{0\}} \young(1,3,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
   X_2 & A_{12}^1 \\
    X_3 & A_{13}^1, A_{23}^1, A_{12}^2A_{23}^2 + sA_{13}^2 \\
    X_4 & 
         A_{23}^2A_{34}^1 - sA_{24}^1, A_{12}^2A_{24}^1 + A_{13}^2A_{34}^1, A_{34}^1 + sA_{34}^2, A_{23}^2A_{34}^2 + A_{24}^1, \\
        & A_{12}^2A_{24}^2 + A_{13}^2A_{34}^2 + A_{14}^1 + sA_{14}^2, A_{23}^2A_{14}^1 - A_{13}^2A_{24}^1 + s(A_{23}^2A_{14}^2 - A_{13}^2A_{24}^2), \\
        & A_{13}^2A_{24}^2A_{34}^1 - A_{13}^2A_{24}^1A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^2A_{24}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    \begin{array}{c}
     (A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{34}^1, A_{23}^2A_{34}^2 + A_{24}^1,  \\
     A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1,s)  
\end{array} & \young(113,224,34) \BS \\
    \begin{array}{c}
      (A_{12}^1, A_{13}^1, A_{23}^1, A_{23}^2, A_{24}^1,  \\
      A_{34}^1, A_{12}^2A_{24}^2 + A_{13}^2A_{34}^2 + A_{14}^1,s) 
 \end{array} & \young(112,234,34) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{in} * Z_{2 \rightarrow 3}$, so the tableaux are 
% \[
% \young(2,4) \text{ and } \young(1,3,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(12,24,3) \text{ and } \young(1,3,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){cc;cc;cc;cc}{cc;cc;cc;cc}
%     0 & 1 & & & & & & \\
%      & s & A_{12}^1 & A_{12}^2 & A_{13}^1 & A_{13}^2 & A_{14}^1 & A_{14}^2 \\
%      & & 0 & 1 & & & & \\
%      & & & 0 & A_{23}^1 & A_{23}^2 & A_{24}^1 & A_{24}^2 \\
%      & & & & 0 & 1 & & \\
%      & & & & & s & A_{34}^1 & A_{34}^2 \\
%      & & & & & & 0 & 1 \\
%      & & & & & & & s
% \end{BMAT}
% \right].
% \]
% The relations from the submatrices are:
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%   X_2 & A_{12}^1 \\
%     X_3 & A_{13}^1, A_{23}^1, A_{12}^2A_{23}^2 + sA_{13}^2 \\
%     X_4 & 
%          A_{23}^2A_{34}^1 - sA_{24}^1, A_{12}^2A_{24}^1 + A_{13}^2A_{34}^1, A_{34}^1 + sA_{34}^2, A_{23}^2A_{34}^2 + A_{24}^1, \\
%         & A_{12}^2A_{24}^2 + A_{13}^2A_{34}^2 + A_{14}^1 + sA_{14}^2, A_{23}^2A_{14}^1 - A_{13}^2A_{24}^1 + s(A_{23}^2A_{14}^2 - A_{13}^2A_{24}^2), \\
%         & A_{13}^2A_{24}^2A_{34}^1 - A_{13}^2A_{24}^1A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^2A_{24}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1 \\
% %     X_3 & A_{13}^1, A_{23}^1, A_{12}^2A_{23}^2 + sA_{13}^2 \\
% %     X_4 & \begin{array}{c}
% %          A_{23}^2A_{34}^1 - sA_{24}^1, A_{12}^2A_{24}^1 + A_{13}^2A_{34}^1, A_{34}^1 + sA_{34}^2, A_{23}^2A_{34}^2 + A_{24}^1, \\
% %          A_{12}^2A_{24}^2 + A_{13}^2A_{34}^2 + A_{14}^1 + sA_{14}^2,  \\
% %          A_{23}^2A_{14}^1 - A_{13}^2A_{24}^1 + s(A_{23}^2A_{14}^2 - A_{13}^2A_{24}^2), \\
% %          A_{13}^2A_{24}^2A_{34}^1 - A_{13}^2A_{24}^1A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^2A_{24}^1 
% %     \end{array} 
% % \end{array}.
% % \]
% Hence our ideal decomposes into 
% \[\begin{array}{c}
%      \langle A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{34}^1, A_{23}^2A_{34}^2 + A_{24}^1,  \\
%      A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1,s \rangle  
% \end{array}
%  \cap \begin{array}{c}
%       \langle A_{12}^1, A_{13}^1, A_{23}^1, A_{23}^2, A_{24}^1,  \\
%       A_{34}^1, A_{12}^2A_{24}^2 + A_{13}^2A_{34}^2 + A_{14}^1,s \rangle. 
%  \end{array} 
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \begin{array}{c}
%      \langle A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{34}^1, A_{23}^2A_{34}^2 + A_{24}^1,  \\
%      A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1,s \rangle  
% \end{array} &\leadsto \young(113,224,34) &\equiv \young(13,24,4) &\leadsto Z_3 Z_{P_2} \\ 
%     \begin{array}{c}
%       \langle A_{12}^1, A_{13}^1, A_{23}^1, A_{23}^2, A_{24}^1,  \\
%       A_{34}^1, A_{12}^2A_{24}^2 + A_{13}^2A_{34}^2 + A_{14}^1,s \rangle. 
%  \end{array} &\leadsto \young(112,234,34) &\equiv \young(12,34,4) &\leadsto Z_{2 \leftarrow 3} Z_{P_1}
% \end{array}
% \]
% so $Z_{in} * Z_{2 \rightarrow 3} = Z_3 Z_{P_2} + Z_{2 \leftarrow 3} Z_{P_1}$.
\end{example}

\begin{example}
$\young(112,24,3) \cdot \young(13,2,4) = \young(24,3,4) + \young(123,24,4):$ The requirement that
\[
X = \left[\begin{BMAT}(e){ccc;ccc;cc;cc}{ccc;ccc;cc;cc}
    0 & 1 & & & & & & & & \\
     & 0 & 1 & & & & & & & \\
     & & s & A_{12}^1 & A_{12}^2 & A_{12}^3 & A_{13}^1 & A_{13}^2 & A_{14}^1 & A_{14}^2 \\
     & & & 0 & 1 & & & & & \\
     & & & & 0 & 1 & & & & \\
     & & & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 & A_{24}^2 \\
     & & & & & & 0 & 1 & & \\
     & & & & & & & s & A_{34}^1 & A_{34}^2 \\
     & & & & & & & & 0 & 1 \\
     & & & & & & & & & s
\end{BMAT}
\right] \text{ is contained in } \young(112,24,3) *_{\AA \setminus \{0\}} \young(13,2,4)
\]
results in the following relations on submatrices:
% 
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    \text{Submatrix} & \text{Relations} \\
    \midrule 
   X_2 & A_{12}^1, A_{12}^2+sA_{12}^3 \\
    X_3 & A_{13}^1,A_{23}^1 \\
    X_4 & A_{23}^2A_{34}^1 - sA_{24}^1, A_{34}^1 + sA_{34}^2, A_{23}^2A_{34}^2 + A_{24}^1, \\
        & A_{12}^3A_{34}^1 - A_{12}^2A_{34}^2, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1 + s(A_{13}^2A_{24}^2 - A_{23}^2A_{14}^2), \\
        & A_{13}^2A_{24}^2A_{34}^1 - A_{13}^2A_{24}^1A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^2A_{24}^1, \\
        & A_{12}^3A_{23}^2A_{14}^1 - A_{12}^2A_{23}^2A_{14}^2 - A_{12}^3A_{13}^2A_{24}^1 + A_{12}^2A_{13}^2A_{24}^2,  \\
        & A_{12}^3A_{13}^2A_{24}^1A_{34}^2 - A_{12}^2A_{13}^2A_{24}^2A_{34}^2 + A_{12}^3A_{14}^1A_{24}^1 - A_{12}^2A_{14}^2A_{24}^1
    \end{tabular}
\end{table}
\noindent At $s = 0$ the ideal generated by the above relations decomposes as a union of the following GOVs.
\begin{table}[H]
  \centering
  \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
  \begin{tabular}{Q} 
    % \text{Ideal} & \text{Tableau} \\
    \text{Ideal of } X(\tau) & \tau \\ 
    \midrule 
    (A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{23}^2, A_{24}^1, A_{34}^1,s) & \young(11124,223,34) \BS \\
    \begin{array}{c}
     (A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{34}^1, A_{23}^2A_{34}^2 + A_{24}^1,  \\
     A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1, s). 
\end{array} & \young(11123,224,34) \TS
    \end{tabular}
\end{table}
% Consider the product $Z_{in} * Z_{out}$, so the tableaux are 
% \[
% \young(2,4) \text{ and } \young(13,2,4).
% \]
% As the sum of the weights is not dominant, we will instead be using the tableaux
% \[
% \young(112,24,3) \text{ and } \young(13,2,4).
% \]
% Our matrix is 
% \[
% X = \left[\begin{BMAT}(e){ccc;ccc;cc;cc}{ccc;ccc;cc;cc}
%     0 & 1 & & & & & & & & \\
%      & 0 & 1 & & & & & & & \\
%      & & s & A_{12}^1 & A_{12}^2 & A_{12}^3 & A_{13}^1 & A_{13}^2 & A_{14}^1 & A_{14}^2 \\
%      & & & 0 & 1 & & & & & \\
%      & & & & 0 & 1 & & & & \\
%      & & & & & s & A_{23}^1 & A_{23}^2 & A_{24}^1 & A_{24}^2 \\
%      & & & & & & 0 & 1 & & \\
%      & & & & & & & s & A_{34}^1 & A_{34}^2 \\
%      & & & & & & & & 0 & 1 \\
%      & & & & & & & & & s
% \end{BMAT}
% \right]
% \]
% The relations from the submatrices are:
% \begin{table}[H]
%   \centering
%   \newcolumntype{Q}{>{$}l<{$}>{$}l<{$}}
%   \begin{tabular}{Q} 
%     \text{Submatrix} & \text{Relations} \\
%     \midrule 
%   X_2 & A_{12}^1, A_{12}^2+sA_{12}^3 \\
%     X_3 & A_{13}^1,A_{23}^1 \\
%     X_4 & A_{23}^2A_{34}^1 - sA_{24}^1, A_{34}^1 + sA_{34}^2, A_{23}^2A_{34}^2 + A_{24}^1, \\
%         & A_{12}^3A_{34}^1 - A_{12}^2A_{34}^2, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1 + s(A_{13}^2A_{24}^2 - A_{23}^2A_{14}^2), \\
%         & A_{13}^2A_{24}^2A_{34}^1 - A_{13}^2A_{24}^1A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^2A_{24}^1, \\
%         & A_{12}^3A_{23}^2A_{14}^1 - A_{12}^2A_{23}^2A_{14}^2 - A_{12}^3A_{13}^2A_{24}^1 + A_{12}^2A_{13}^2A_{24}^2,  \\
%         & A_{12}^3A_{13}^2A_{24}^1A_{34}^2 - A_{12}^2A_{13}^2A_{24}^2A_{34}^2 + A_{12}^3A_{14}^1A_{24}^1 - A_{12}^2A_{14}^2A_{24}^1
%     \end{tabular}
% \end{table}
% % \[
% % \begin{array}{c|c}
% %     \text{Submatrix} & \text{Relations} \\ \hline
% %     X_2 & A_{12}^1, A_{12}^2+sA_{12}^3 \\
% %     X_3 & A_{13}^1,A_{23}^1 \\
% %     X_4 & \begin{array}{c}
% %          A_{23}^2A_{34}^1 - sA_{24}^1, A_{34}^1 + sA_{34}^2, A_{23}^2A_{34}^2 + A_{24}^1, \\
% %          A_{12}^3A_{34}^1 - A_{12}^2A_{34}^2, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1 + s(A_{13}^2A_{24}^2 - A_{23}^2A_{14}^2), \\
% %          A_{13}^2A_{24}^2A_{34}^1 - A_{13}^2A_{24}^1A_{34}^2 - A_{14}^1A_{24}^1 - sA_{14}^2A_{24}^1, \\
% %          A_{12}^3A_{23}^2A_{14}^1 - A_{12}^2A_{23}^2A_{14}^2 - A_{12}^3A_{13}^2A_{24}^1 + A_{12}^2A_{13}^2A_{24}^2,  \\
% %          A_{12}^3A_{13}^2A_{24}^1A_{34}^2 - A_{12}^2A_{13}^2A_{24}^2A_{34}^2 + A_{12}^3A_{14}^1A_{24}^1 - A_{12}^2A_{14}^2A_{24}^1
% %     \end{array} 
% % \end{array}.
% % \]
% Hence our ideal decomposes into \acom{formatting funny; can just list irrecs?}
% \[
% \langle A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{23}^2, A_{24}^1, A_{34}^1,s \rangle
% \cap \begin{array}{c}
%      \langle A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{34}^1, A_{23}^2A_{34}^2 + A_{24}^1,  \\
%      A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1, s \rangle. 
% \end{array} 
% \]
% The tableau for each ideal is
% \[\begin{array}{cccc}\vspace{1mm}
%     \langle A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{23}^2, A_{24}^1, A_{34}^1,s \rangle &\leadsto \young(11124,223,34) &\equiv \young(24,3,4) &\leadsto Z_{P_1} Z_{P_3} \\ 
%     \begin{array}{c}
%      \langle A_{12}^1, A_{12}^2, A_{13}^1, A_{23}^1, A_{34}^1, A_{23}^2A_{34}^2 + A_{24}^1,  \\
%      A_{13}^2A_{34}^2 + A_{14}^1, A_{13}^2A_{24}^1 - A_{23}^2A_{14}^1, s \rangle. 
% \end{array} &\leadsto \young(11123,224,34) &\equiv \young(123,24,4) &\leadsto Z_1 Z_3 Z_{P_2}
% \end{array}
% \]
% so $Z_{in} * Z_{out} = Z_{P_1} Z_{P_3} + Z_1 Z_3 Z_{P_2}$.
\end{example}

\bibliographystyle{alpha}
\bibliography{mvybd}

\end{document}